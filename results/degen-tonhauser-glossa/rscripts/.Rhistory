library('brms')
data('kidney', package = 'brms')
head(kidney, n = 3)
fit1 <- brm(formula =  time | cens(censored) ~ age * sex + disease + (1 * age | patient),
data = kidney, family = lognormal(), prior = c(set_prior("normal(0.5)", class = "b"),
set_prior("cauchy(0,2)", class = "sd"),
set_prior("lkj(2)", class = "cor")),
warmup = 1000, iter = 2000, chains = 4)
View(kidney)
fit1 <- brm(formula =  time | cens(censored) ~ age * sex + disease + (1 * age | patient),
data = kidney, family = lognormal(), prior = c(set_prior("normal(0.5)", class = "b"),
set_prior("cauchy(0,2)", class = "sd"),
set_prior("lkj(2)", class = "cor")),
warmup = 1000, iter = 2000, chains = 4)
fit1 <- brm(formula =  time | cens(censored) ~ age * sex + disease + (1 * age | patient),
data = kidney, family = lognormal(), prior = c(set_prior("normal(0.5)", class = "b"),
set_prior("cauchy(0,2)", class = "sd")),
warmup = 1000, iter = 2000, chains = 4)
fit1 <- brm(formula =  time | cens(censored) ~ age * sex + disease + (1 * age | patient),
data = kidney, family = lognormal(),
warmup = 1000, iter = 2000, chains = 4)
View(kidney)
View(kidney)
View(kidney)
fit1 <- brm(formula =  censored ~ age * sex + disease + (1 * age | patient),
data = kidney, family = bernoulli(link = logit),
warmup = 1000, iter = 2000, chains = 4)
)
fit1 <- brm(formula =  censored ~ age * sex + disease + (1 * age | patient),
data = kidney, family = bernoulli(link = logit),
warmup = 1000, iter = 2000, chains = 4)
library('brms')
data('kidney', package = 'brms')
head(kidney, n = 3)
fit1 <- brm(formula =  censored ~ age * sex + disease + (1 * age | patient),
data = kidney, family = bernoulli(link = logit),
warmup = 1000, iter = 2000, chains = 4)
# Sample sizes
var_size <- 10000
sim_size <- 100000
sample_size <- 100
# multinomial parameters
k <- 5
ratings1 <- rmultinom(var_size, k)
# Set parameters to generate log-normally distributed variables
muX <- 0
sdX <- 1
muY <- 0
sdY <- 0.25
muZ <- 0
sdZ <- 0.5
# Sample sizes
var_size <- 10000
sim_size <- 100000
sample_size <- 100
# Simulate random variables
X <- exp(rnorm(var_size,muX,sdX))
Y <- exp(rnorm(var_size,muY,sdY))
Z <- exp(rnorm(var_size,muZ,sdZ))
# Plot pdf for three different parameters
hist(X, breaks = var_size/50)
hist(Y, breaks = var_size/50)
hist(Z, breaks = var_size/50)
# Plot pdf for three different parameters
hist(X, breaks = var_size/50)
hist(Y, breaks = var_size/50)
# Plot pdf for three different parameters
hist(X, breaks = var_size/50)
hist(Y, breaks = var_size/50)
hist(Z, breaks = var_size/50)
# Set parameters to generate log-normally distributed variables
muX <- 0
sdX <- 1
muY <- 1.2
sdY <- 0.25
muZ <- 3
sdZ <- 0.5
# Sample sizes
var_size <- 10000
sim_size <- 100000
sample_size <- 100
# Simulate random variables
X <- exp(rnorm(var_size,muX,sdX))
Y <- exp(rnorm(var_size,muY,sdY))
Z <- exp(rnorm(var_size,muZ,sdZ))
# Plot pdf for three different parameters
hist(X, breaks = var_size/50)
hist(Y, breaks = var_size/50)
hist(Z, breaks = var_size/50)
muA <- 2.5
sdA <- 0.6
A <- exp(rnorm(var_size,muA,sdA))
hist(A, breaks = var_size/50)
sample(X, size=sample_size, replace=TRUE) -> rt.sample
sample(X, size=sample_size, replace=TRUE) -> sampleX
hist(sampleX, breaks = var_size/50)
sampleX
# Simulate random variables
X <- rmultinom(var_size,5,c(1/5,1/5,1/5,1/5,1/5))
install.packages(c("bayesplot", "bayestestR", "BH", "blob", "brms", "Brobdingnag", "broom", "bslib", "callr", "checkmate", "class", "cli", "clipr", "cluster", "colorspace", "commonmark", "crayon", "datawizard", "DBI", "dbplyr", "desc", "dfidx", "distributional", "dplyr", "DT", "dtplyr", "estimability", "evaluate", "fansi", "farver", "fontawesome", "forcats", "foreign", "future", "generics", "ggdist", "ggplot2", "globals", "glue", "googlesheets4", "gplots", "gtable", "gtools", "haven", "hms", "htmltools", "httpuv", "httr", "igraph", "insight", "jsonlite", "knitr", "lme4", "lmtest", "loo", "magrittr", "MASS", "Matrix", "matrixStats", "mgcv", "mnormt", "modelr", "nleqslv", "nlme", "nloptr", "nnet", "openssl", "optimx", "packrat", "parallelly", "pillar", "pkgbuild", "plyr", "posterior", "processx", "projpred", "ps", "psych", "rbibutils", "RColorBrewer", "Rcpp", "RcppArmadillo", "RcppEigen", "RcppParallel", "Rdpack", "readr", "readxl", "reprex", "rjags", "rlang", "rmarkdown", "Rmisc", "rpart", "rprojroot", "rsconnect", "rstan", "rstanarm", "rstantools", "rstudioapi", "rvest", "sass", "scales", "shiny", "shinyjs", "shinystan", "spatial", "statmod", "stringi", "stringr", "survival", "tibble", "tidybayes", "tidyr", "tidyselect", "tidyverse", "tinytex", "tzdb", "uuid", "V8", "vctrs", "viridisLite", "withr", "xfun", "yaml", "zoo"))
version
install.packages("lme4")
install.packages("brms")
# load required packages
library(tidyverse)
library(tidybayes)
library(brms)
library(emmeans)
library(lme4)
library(lmerTest)
library(xtable)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
# load helper functions
source('../../helpers.R')
# load cleaned data
d = read_csv("../data/cd.csv")
nrow(d)
length(unique(d$participantID)) #71 participants
# exclude controls
t = d %>%
filter(!(expression == "controlBad" | expression == "controlGood"))
table(t$expression)
# set reference level
t = t %>%
mutate(expression = fct_relevel(expression, "be right"))
levels(t$expression)
# response distribution before transformation
summary(t$response)
# first, because response assumes values of 0 and 1, which beta regression cannot handle, transform: (Smithson & Verkuilen 2006)
# y_new = (y_old * (n−1) + 0.5) / n (where n is the sample size)
# note: first rescaling of y'=(y-a)/(b-a) not necessary because highest and lowest value are 0 and 1 already
t$betaresponse = (t$response*(nrow(t)-1) + .5)/nrow(t)
summary(t$betaresponse)
# fit the model
prior = get_prior(betaresponse ~ expression + (1|participantID) + (1|cc),family = Beta(),data=t)
prior
# set priors
priors = c(set_prior("cauchy(0, .001)", class = "b"))
betamodel = bf(betaresponse ~ expression + (1|participantID) + (1|cc),
phi ~ expression, # beta distribution's precision
family = Beta(),
center = FALSE)
m.b = brm(formula = betamodel,
family=Beta(),
data=t,
prior = priors,
cores = 4, iter = 3000, warmup = 500,
control = list(adapt_delta = .95, max_treedepth=15))
m.b = brm(formula = betamodel,
family=Beta(),
data=t,
# prior = priors,
cores = 4, iter = 3000, warmup = 500,
control = list(adapt_delta = .95, max_treedepth=15))
betamodel = bf(betaresponse ~ expression + (1|participantID) + (1|cc),
phi ~ expression, # beta distribution's precision
family = Beta(),
center = FALSE)
m.b = brm(formula = betamodel,
family=Beta(),
data=t,
# prior = priors,
cores = 4, iter = 3000, warmup = 500,
control = list(adapt_delta = .95, max_treedepth=15))
betamodel = bf(betaresponse ~ expression + (1|participantID) + (1|cc),
# phi ~ expression, # beta distribution's precision
family = Beta(),
center = FALSE)
m.b = brm(formula = betamodel,
family=Beta(),
data=t,
# prior = priors,
cores = 4, iter = 3000, warmup = 500,
control = list(adapt_delta = .95, max_treedepth=15))
# set priors
priors = c(set_prior("cauchy(0, .001)", class = "b"),
set_prior("gamma(0.01, 0.01)", class = "phi"))
betamodel = bf(betaresponse ~ expression + (1|participantID) + (1|cc),
phi ~ expression, # beta distribution's precision
family = Beta(),
center = FALSE)
m.b = brm(formula = betamodel,
family=Beta(),
data=t,
# prior = priors,
cores = 4, iter = 3000, warmup = 500,
control = list(adapt_delta = .95, max_treedepth=15))
m.b = brm(formula = betamodel,
family=Beta(),
data=t,
prior = priors,
cores = 4, iter = 3000, warmup = 500,
control = list(adapt_delta = .95, max_treedepth=15))
betamodel = bf(betaresponse ~ expression + (1|participantID) + (1|cc),
phi ~ expression + (1|participantID) + (1|cc), # beta distribution's precision
family = Beta(),
center = FALSE)
m.b = brm(formula = betamodel,
family=Beta(),
data=t,
prior = priors,
cores = 4, iter = 3000, warmup = 500,
control = list(adapt_delta = .95, max_treedepth=15))
# fit the model
prior = get_prior(betaresponse ~ expression + (1|participantID) + (1|cc),family = Beta(),data=t)
prior
# set priors
priors = c(set_prior("cauchy(0, .001)", class = "b"))
betamodel = bf(betaresponse ~ expression + (1|participantID) + (1|cc),
phi ~ expression + (1|participantID) + (1|cc), # beta distribution's precision
family = Beta(),
center = FALSE)
m.b = brm(formula = betamodel,
family=Beta(),
data=t,
prior = priors,
cores = 4, iter = 3000, warmup = 500,
control = list(adapt_delta = .95, max_treedepth=15))
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
# load packages / options
library(readr)
library(tidyverse)
library(rstan)
options(mc.cores=parallel::detectCores())
rstan_options(auto_write=TRUE)
library(brms)
library(bayesplot)
library(hypr)
# read data
d = read_csv("../data/excluded2.csv")
# make sure data types makes sense
d$response <- as.numeric(d$response)
summary(d$response)
d$condition <- as.factor(d$condition)
levels(d$condition)
d <- d %>% mutate(condition = fct_reorder(condition, response, .fun = mean))
contrasts(d$condition)
d$tag <- as.factor(d$tag)
levels(d$tag)
d$tag <- relevel(d$tag, ref="whynot")
contrasts(d$tag)
d$participant <- as.factor(d$participant)
levels(d$participant)
d$item <- as.factor(d$item)
levels(d$item)
# scaling transform from closed unit interval [0,1], to  open unit interval (0,1), excluding boundaries
# using method used in Degen \& Tonhauser (2022), from Smithson \& Verkuilen (2006)
#  y' = (y · (n − 1) + 0.5)/n
d$betaresponse <- (d$response*(nrow(d)-1) + .5)/nrow(d)
d$betaresponse <- as.numeric(d$betaresponse)
summary(d$betaresponse)
# comparing conditions to pos baseline, all data
bm <- brm(formula = bf(betaresponse ~ condition + (1 | participant) + (1 + condition | item),
phi ~ condition + (1 | participant) + (1 + condition | item),
family = Beta()),
family = Beta(),
data = d,
iter=10000, warmup=2000,chains=6,
control = list(adapt_delta = .95,max_treedepth=15))
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
# load required packages
library(tidyverse)
# color-blind-friendly palette
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_bw())
# load helper functions
source('../../../helpers.R')
# load cleaned data
d = read_csv("../data/cd.csv")
length(unique(d$participantID)) #69 participants
# exclude controls
t = d %>%
filter(!(expression == "AI MC" | expression == "NAI MC"))
table(t$expression)
# mean rating by expression
means = t %>%
group_by(expression) %>%
summarize(Mean = mean(response), CILow = ci.low(response), CIHigh = ci.high(response)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(expression),Mean))
means
# range
min(means$Mean)
max(means$Mean)
max(means$Mean) - min(means$Mean)
# plot
ggplot(data=means, aes(x=expression, y=Mean)) +
geom_violin(data=t, aes(x=expression, y=response), scale="width", fill = "grey", linewidth=0, alpha=.4) +
geom_point(size=2.5,color="black") +
geom_errorbar(aes(ymin=YMin,ymax=YMax),width=0.1,color="black") +
scale_y_continuous(limits = c(0,1),breaks = c(0,0.2,0.4,0.6,0.8,1.0)) +
theme(text = element_text(size=12), axis.text.x = element_text(size = 12, angle = 45, hjust = 1)) +
theme(legend.position="none") +
theme(panel.grid.major.x = element_blank()) +
ylab("Mean naturalness ratings \n (higher rating = more not-at-issue)") +
xlab("Expression")
# mean rating by expression
means = t %>%
group_by(expression) %>%
summarize(Mean = mean(response), CILow = ci.low(response), CIHigh = ci.high(response)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(expression),Mean))
# load helper functions
source('../../../helpers.R')
# load helper functions
source('../../helpers.R')
# load cleaned data
d = read_csv("../data/cd.csv")
length(unique(d$participantID)) #69 participants
# exclude controls
t = d %>%
filter(!(expression == "AI MC" | expression == "NAI MC"))
table(t$expression)
# mean rating by expression
means = t %>%
group_by(expression) %>%
summarize(Mean = mean(response), CILow = ci.low(response), CIHigh = ci.high(response)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, expression = fct_reorder(as.factor(expression),Mean))
means
# range
min(means$Mean)
max(means$Mean)
max(means$Mean) - min(means$Mean)
# plot
ggplot(data=means, aes(x=expression, y=Mean)) +
geom_violin(data=t, aes(x=expression, y=response), scale="width", fill = "grey", linewidth=0, alpha=.4) +
geom_point(size=2.5,color="black") +
geom_errorbar(aes(ymin=YMin,ymax=YMax),width=0.1,color="black") +
scale_y_continuous(limits = c(0,1),breaks = c(0,0.2,0.4,0.6,0.8,1.0)) +
theme(text = element_text(size=12), axis.text.x = element_text(size = 12, angle = 45, hjust = 1)) +
theme(legend.position="none") +
theme(panel.grid.major.x = element_blank()) +
ylab("Mean naturalness ratings \n (higher rating = more not-at-issue)") +
xlab("Expression")
ggsave("../graphs/mean-ratings.pdf",height=4.5,width=7)
ggsave("../graphs/mean-ratings.pdf",height=4.5,width=7)
# load required packages
library(tidyverse)
library(ggrepel)
library(dichromat)
library(forcats)
library(RColorBrewer)
library(curl) # to read data from github repo
library(gridExtra)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
theme_set(theme_bw())
source('../../../helpers.R')
# color-blind-friendly palette
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
d <- read_csv("https://raw.githubusercontent.com/judith-tonhauser/projection-interactions/refs/heads/main/results/exp1/data/d.csv")
nrow(d) #10100
# load required packages
library(tidyverse)
library(ggrepel)
library(dichromat)
library(forcats)
library(RColorBrewer)
library(curl) # to read data from github repo
library(gridExtra)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
theme_set(theme_bw())
source('../../../helpers.R')
# color-blind-friendly palette
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
d <- read_csv("https://raw.githubusercontent.com/judith-tonhauser/projection-interactions/refs/heads/main/results/exp1/data/d.csv")
nrow(d) #10100
# sort predicates by not-at-issueness mean
nai.means = d %>%
group_by(short_trigger) %>%
summarize(Mean_nai = mean(ai), CILow=ci.low(ai),CIHigh=ci.high(ai)) %>%
mutate(YMin=Mean_nai-CILow,YMax=Mean_nai+CIHigh) %>%
select(!c(CILow,CIHigh)) %>%
mutate(short_trigger = fct_reorder(as.factor(short_trigger),Mean_nai))
nai.means
source('../../helpers.R')
# color-blind-friendly palette
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
d <- read_csv("https://raw.githubusercontent.com/judith-tonhauser/projection-interactions/refs/heads/main/results/exp1/data/d.csv")
nrow(d) #10100
# sort predicates by not-at-issueness mean
nai.means = d %>%
group_by(short_trigger) %>%
summarize(Mean_nai = mean(ai), CILow=ci.low(ai),CIHigh=ci.high(ai)) %>%
mutate(YMin=Mean_nai-CILow,YMax=Mean_nai+CIHigh) %>%
select(!c(CILow,CIHigh)) %>%
mutate(short_trigger = fct_reorder(as.factor(short_trigger),Mean_nai))
nai.means
d = d %>%
mutate(short_trigger = fct_relevel(short_trigger,levels(nai.means$short_trigger)))
levels(d$short_trigger)
ggplot(means, aes(x=verb, y=Mean, fill=VeridicalityGroup)) +
geom_violin(data=subjmeans,scale="width",linewidth = 0, alpha = .4)
# plot
ggplot() +
geom_violin(data=d,aes(x=short_trigger, y=ai), scale="width",linewidth = .1, fill = "black", alpha = .2) +
geom_point(data=nai.means, aes(x=short_trigger, y=Mean_nai), stroke=.5,size=2.5,color="black") +
geom_errorbar(data=nai.means, aes(x=short_trigger, ymin=YMin,ymax=YMax), width=0.1,color="black") +
scale_y_continuous(limits = c(0,1),breaks = c(0,0.2,0.4,0.6,0.8,1.0)) +
theme(text = element_text(size=12), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
theme(legend.position="bottom") +
theme(panel.grid.major.x = element_blank()) +
ylab("Mean 'asking whether' rating \n (higher rating indicates more not-at-issue)") +
xlab("Predicate")
ggsave("../graphs/mean-asking-whether-ratings.pdf",height=4.5,width=7)
ggplot(d, aes(x=short_trigger, y=ai)) +
geom_point(size=1, alpha=.1) +
geom_point(data=nai.means, aes(x=short_trigger,y=Mean_nai), size=3) +
#scale_color_manual(values=c("#E69F00","#999999")) +
#scale_fill_manual(values=c("#E69F00","#999999")) +
#guides(color = "none", fill = "none") +
ylab("Asking-whether ratings (not-at-issueness) \n (higher rating indicates more not-at-issue)") +
#ylab("Certainty ratings (projection) \n (higher rating indicates more projection)") +
#scale_x_continuous(breaks=c(0,.5,1),labels=c("0",".5","1"), limits = c(0,1)) +
scale_y_continuous(breaks=c(0,.5,1),labels=c("0",".5","1"), limits = c(0,1)) +
theme(panel.spacing.x = unit(4, "mm"))
ggsave(f="../graphs/projection-by-ai.pdf",height=5,width=5)
# load required packages
library(tidyverse)
library(ggrepel)
library(dichromat)
library(forcats)
library(RColorBrewer)
library(curl) # to read data from github repo
library(gridExtra)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
theme_set(theme_bw())
source('../../helpers.R')
# color-blind-friendly palette
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
d <- read_csv("https://raw.githubusercontent.com/judith-tonhauser/projection-interactions/refs/heads/main/results/exp1/data/d.csv")
# load required packages
library(tidyverse)
s.R
# load required packages
library(tidyverse)
library(ggrepel)
library(dichromat)
library(forcats)
library(RColorBrewer)
library(curl) # to read data from github repo
library(gridExtra)
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
theme_set(theme_bw())
source('../../helpers.R')
# color-blind-friendly palette
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
d <- read_csv("https://raw.githubusercontent.com/judith-tonhauser/projection-interactions/refs/heads/main/results/exp1/data/d.csv")
nrow(d) #10100
# sort predicates by not-at-issueness mean
nai.means = d %>%
group_by(short_trigger) %>%
summarize(Mean_nai = mean(ai), CILow=ci.low(ai),CIHigh=ci.high(ai)) %>%
mutate(YMin=Mean_nai-CILow,YMax=Mean_nai+CIHigh) %>%
select(!c(CILow,CIHigh)) %>%
mutate(short_trigger = fct_reorder(as.factor(short_trigger),Mean_nai))
nai.means
d = d %>%
mutate(short_trigger = fct_relevel(short_trigger,levels(nai.means$short_trigger)))
levels(d$short_trigger)
ggplot(means, aes(x=verb, y=Mean, fill=VeridicalityGroup)) +
geom_violin(data=subjmeans,scale="width",linewidth = 0, alpha = .4)
ggplot(means, aes(x=verb, y=Mean, fill=VeridicalityGroup)) +
geom_violin(data=subjmeans,scale="width",linewidth = 0, alpha = .4)
d <- read_csv("https://raw.githubusercontent.com/judith-tonhauser/projection-interactions/refs/heads/main/results/exp1/data/d.csv")
nrow(d) #10100
# sort predicates by not-at-issueness mean
nai.means = d %>%
group_by(short_trigger) %>%
summarize(Mean_nai = mean(ai), CILow=ci.low(ai),CIHigh=ci.high(ai)) %>%
mutate(YMin=Mean_nai-CILow,YMax=Mean_nai+CIHigh) %>%
select(!c(CILow,CIHigh)) %>%
mutate(short_trigger = fct_reorder(as.factor(short_trigger),Mean_nai))
nai.means
d = d %>%
mutate(short_trigger = fct_relevel(short_trigger,levels(nai.means$short_trigger)))
levels(d$short_trigger)
ggplot(means, aes(x=verb, y=Mean, fill=VeridicalityGroup)) +
geom_violin(data=subjmeans,scale="width",linewidth = 0, alpha = .4)
# plot
ggplot() +
geom_violin(data=d,aes(x=short_trigger, y=ai), scale="width",linewidth = .1, fill = "black", alpha = .2) +
geom_point(data=nai.means, aes(x=short_trigger, y=Mean_nai), stroke=.5,size=2.5,color="black") +
geom_errorbar(data=nai.means, aes(x=short_trigger, ymin=YMin,ymax=YMax), width=0.1,color="black") +
scale_y_continuous(limits = c(0,1),breaks = c(0,0.2,0.4,0.6,0.8,1.0)) +
theme(text = element_text(size=12), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
theme(legend.position="bottom") +
theme(panel.grid.major.x = element_blank()) +
ylab("Mean 'asking whether' rating \n (higher rating indicates more not-at-issue)") +
xlab("Predicate")
ggsave("../graphs/mean-asking-whether-ratings.pdf",height=4.5,width=7)
