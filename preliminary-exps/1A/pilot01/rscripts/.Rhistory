#filter(voice == "active") %>%
group_by(predicateType,voice) %>%
summarize(Mean.Proj = mean(veridicality_num), CILow = ci.low(veridicality_num), CIHigh = ci.high(veridicality_num)) %>%
mutate(YMin.Proj = Mean.Proj - CILow, YMax.Proj = Mean.Proj + CIHigh, predicateType = fct_reorder(as.factor(predicateType),Mean.Proj))
mean.proj
nrow(mean.proj) #10
levels(mean.proj$predicateType)
ggplot(mean.proj, aes(x=predicateType, y=Mean.Proj, color = voice)) +
geom_point() +
geom_errorbar(aes(ymin=YMin.Proj,ymax=YMax.Proj),width=0) +
geom_hline(yintercept=0) +
theme(legend.position="top",
axis.ticks.x=element_blank(),
axis.text.x = element_text(size=10,angle = 75, hjust = 1)) +
scale_y_continuous(limits = c(-1,1),breaks = c(-1,0,1)) +
ylab("Mean projection rating") +
xlab("Predicate")
# calculate by-predicate projection means
mean.proj = d.proj %>%
group_by(verb_renamed) %>%
summarize(Mean.Proj = mean(veridicality_num), CILow = ci.low(veridicality_num), CIHigh = ci.high(veridicality_num)) %>%
mutate(YMin.Proj = Mean.Proj - CILow, YMax.Proj = Mean.Proj + CIHigh, verb_renamed = fct_reorder(as.factor(verb_renamed),Mean.Proj))
mean.proj
nrow(mean.proj) #544
levels(mean.proj$verb_renamed)
# add predicateType, verb and voice to the means
tmp = d.proj %>%
#filter(voice == "active") %>%
select(c(verb,verb_renamed,voice,predicateType)) %>%
distinct(verb,verb_renamed,voice,predicateType)
nrow(tmp) #544
mean.proj = left_join(mean.proj, tmp, by = c("verb_renamed")) %>%
distinct() %>%
mutate(verb_renamed = fct_reorder(as.factor(verb_renamed),Mean.Proj))
nrow(mean.proj) #544
cols$verb_renamed = factor(cols$verb_renamed, levels = mean.proj$verb_renamed[order(mean.proj$Mean.Proj)], ordered = TRUE)
# remove "other" and "comPriv" predicates
mean.proj = mean.proj %>%
filter(predicateType != "other" & predicateType != "comPriv")
nrow(mean.proj) #525
ggplot(mean.proj, aes(x=verb_renamed, y=Mean.Proj, fill = predicateType, color = predicateType)) +
geom_point() +
#geom_errorbar(aes(ymin=YMin.Proj,ymax=YMax.Proj),width=0) +
geom_hline(yintercept=0) +
theme(legend.position="top",
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
panel.grid.major.x = element_blank()) +
#theme(axis.text.x = element_text(color=cols$Colors,size=10,angle = 75, hjust = 1)) +
scale_y_continuous(limits = c(-1,1),breaks = c(-1,0,1)) +
ylab("Mean projection rating") +
xlab("Predicate")
ggplot(mean.proj, aes(x=verb_renamed, y=Mean.Proj, fill = predicateType, color = predicateType)) +
geom_point() +
#geom_errorbar(aes(ymin=YMin.Proj,ymax=YMax.Proj),width=0) +
geom_hline(yintercept=0) +
theme(legend.position="top",
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
panel.grid.major.x = element_blank()) +
#theme(axis.text.x = element_text(color=cols$Colors,size=10,angle = 75, hjust = 1)) +
scale_y_continuous(limits = c(-1,1),breaks = c(-1,0,1)) +
facet_grid(. ~ predicateType) +
ylab("Mean projection rating") +
xlab("Predicate")
ggplot(mean.proj, aes(x = verb_renamed, y = Mean.Proj, colour = voice)) +
geom_point() +
geom_hline(yintercept = 0) +
scale_colour_discrete(name = element_blank(),
labels = c("verbal predicate", "adjectival predicate")) +
theme(legend.position = "top",
axis.text.x = element_blank(),
axis.ticks.x = element_blank(),
panel.grid.major.x = element_blank()) +
scale_y_continuous(limits = c(-1,1), breaks = c(-1,0,1)) +
ylab("Mean projection rating") +
xlab("Emotive predicate")
ggplot(mean.proj, aes(x=verb_renamed, y=Mean.Proj, fill = predicateType, color = predicateType)) +
geom_point() +
#geom_errorbar(aes(ymin=YMin.Proj,ymax=YMax.Proj),width=0) +
geom_hline(yintercept=0) +
theme(legend.position="top",
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
panel.grid.major.x = element_blank()) +
#theme(axis.text.x = element_text(color=cols$Colors,size=10,angle = 75, hjust = 1)) +
scale_y_continuous(limits = c(-1,1),breaks = c(-1,0,1)) +
facet_grid(. ~ predicateType) +
ylab("Mean projection rating") +
xlab("Predicate")
ggplot(mean.proj, aes(x=predicateType, y=Mean.Proj, color = voice)) +
geom_point() +
geom_errorbar(aes(ymin=YMin.Proj,ymax=YMax.Proj),width=0) +
geom_hline(yintercept=0) +
theme(legend.position="top",
axis.ticks.x=element_blank(),
axis.text.x = element_text(size=10,angle = 75, hjust = 1)) +
scale_y_continuous(limits = c(-1,1),breaks = c(-1,0,1)) +
ylab("Mean projection rating") +
xlab("Predicate")
# calculate by-predicateType means
mean.proj = d.proj %>%
#filter(voice == "active") %>%
group_by(predicateType) %>%
summarize(Mean.Proj = mean(veridicality_num), CILow = ci.low(veridicality_num), CIHigh = ci.high(veridicality_num)) %>%
mutate(YMin.Proj = Mean.Proj - CILow, YMax.Proj = Mean.Proj + CIHigh, predicateType = fct_reorder(as.factor(predicateType),Mean.Proj))
ggplot(mean.proj, aes(x=predicateType, y=Mean.Proj)) +
geom_point() +
geom_errorbar(aes(ymin=YMin.Proj,ymax=YMax.Proj),width=0) +
geom_hline(yintercept=0) +
theme(legend.position="top",
axis.ticks.x=element_blank(),
axis.text.x = element_text(size=10,angle = 75, hjust = 1)) +
scale_y_continuous(limits = c(-1,1),breaks = c(-1,0,1)) +
ylab("Mean projection rating") +
xlab("Predicate")
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source('../../../helpers.R')
# load required packages for pre-processing data
library(tidyverse)
library(readr)
theme_set(theme_bw())
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
source('../../../helpers.R')
# load required packages for pre-processing data
library(tidyverse)
library(readr)
theme_set(theme_bw())
# read in the raw data
d = read_tsv("../data/combined.tsv")
# remove instructions rows
d = d %>%
filter(trial_index != "0")
# replace participant_id by random number
length(unique(d$participant_id)) #
d$participantID <- match(d$participant_id, unique(sort(d$participant_id)))
# select needed columns
d = d %>%
select(c(stimulus, response, trial_index, participantID))
# unpack demographics info
dg <- d %>%
filter(trial_index == "11") %>%
select(c(participantID,response))
table(dg$response)
# age
dg$age = as.numeric(gsub("\\D", "", dg$response))
table(dg$age)
# gender
dg$gender = case_when(grepl("female", dg$response) ~ "female",
grepl("male", dg$response) ~ "male",
grepl("non-binary", dg$response) ~ "non-binary",
TRUE ~ "preferNoToSay")
table(dg$gender)
# language
dg$language = case_when(grepl("language\"\":\"\"yes", dg$response) ~ "English",
TRUE ~ "notSpeakerOfEnglish")
table(dg$language)
# American English
dg$amE = case_when(grepl("amE\"\":\"\"yes", dg$response) ~ "AmE",
TRUE ~ "notAmE")
table(dg$amE)
# comments
dg$comments = gsub(".*comments", "", dg$response)
table(dg$comments)
# remove response column from demographics data
dg = dg %>%
select(-c(response))
summary(dg)
# add demographics data back to data
d = left_join(d, dg, by = "participantID")
# remove demographics rows
d = d %>%
filter(trial_index != 11)
# make response a numeric column, with values between 0 and 1
summary(d$response)
d$response <- as.numeric(d$response)
d$response <- d$response/100
table(d$response)
# create useful columns from "stimulus" column
table(d$stimulus)
# target vs control
d$target = case_when(grepl("Ann, who",d$stimulus) ~ "goodControl1",
grepl("Samantha, who",d$stimulus) ~ "goodControl2",
grepl("John's kids",d$stimulus) ~ "badControl1",
grepl("blueberries",d$stimulus) ~ "badControl2",
TRUE ~ "target")
table(d$target)
# predicate
d$predicate = case_when(grepl("is right that", d$stimulus) ~ "be right",
grepl("knows that", d$stimulus) ~ "know",
grepl("said", d$stimulus) ~ "say",
grepl("discovered", d$stimulus) ~ "discover",
grepl("thinks", d$stimulus) ~ "think",
grepl("confessed",d$stimulus) ~ "confess",
TRUE ~ "control")
table(d$predicate)
# CC
d$cc = case_when(grepl("studied", d$stimulus) ~ "Emma studied on Saturday morning",
grepl("had a drink", d$stimulus) ~ "Tony had a drink last night",
grepl("cupcake", d$stimulus) ~ "Danny ate the last cupcake",
grepl("cocktails", d$stimulus) ~ "Mia drank two cocktails last night",
grepl("miles", d$stimulus) ~ "Jackson ran 10 miles",
grepl("tattoo",d$stimulus) ~ "Sophia got a tattoo",
TRUE ~ "control")
table(d$cc)
view(d)
# what is at-issue?
# "why"-question: main clause at-issue
# "what"-question: cc at-issue, but some controls also have "what"-question
d$ai = case_when(grepl("Why", d$stimulus) ~ "mc",
grepl("blueberries", d$stimulus) ~ "control",
grepl("Ann", d$stimulus) ~ "control",
grepl("Samantha", d$stimulus) ~ "control",
grepl("garage", d$stimulus) ~ "control",
TRUE ~ "cc")
table(d$ai)
# remove stimulus column now that everything has been extracted from it
d = d %>%
select(-c(stimulus))
# check that all predicates and all contents are being presented to participants
table(d$predicate) #6 predicates
table(d$cc) # 6 contents
table(d$predicate, d$cc)
# did every participant see both cc and mc at-issueness?
count = d %>%
filter(target == "target") %>%
group_by(participantID, ai) %>%
summarize(count = n())
count
# participant info
table(d$age) #xx-xx
length(which(is.na(d$age))) # 0 missing values
d %>%
select(gender, participantID) %>%
unique() %>%
group_by(gender) %>%
summarize(count=n())
### exclude non-English speakers and non-American English speakers
# exclude non-English speakers
length(which(is.na(d$language))) #no missing responses
table(d$language)
d <- d %>%
filter(language != "notSpeakerOfEnglish") %>%  droplevels()
length(unique(d$participantID)) #
# exclude non-American English speakers
length(which(is.na(d$amE))) #0 (everybody responded)
table(d$amE)
d <- d %>%
filter(amE != "notAmE") %>%  droplevels()
length(unique(d$participantID)) #
# change response from character to numeric
d$response <- as.numeric(d$response)
str(d$response)
# exclude participants based on controls
table(d$predicate)
# good controls
controls.good = d %>%
filter(target == "goodControl1" | target == "goodControl2")
table(controls.good$target)
# plot responses by good controls, to see if they worked as expected
good.means = controls.good %>%
group_by(target) %>%
summarize(Mean = mean(response),CI.Low = ci.low(response), CI.High=ci.high(response)) %>%
ungroup() %>%
mutate(YMin = Mean-CI.Low, YMax = Mean+CI.High)
good.means
ggplot(good.means, aes(x=target,y=Mean)) +
geom_point() +
geom_errorbar(aes(ymin=YMin, ymax=YMax))+
ylab("Mean response")
# plot responses by participant
good.means.p = controls.good %>%
group_by(participantID) %>%
summarize(Mean = mean(response),CI.Low = ci.low(response), CI.High=ci.high(response)) %>%
ungroup() %>%
mutate(YMin = Mean-CI.Low, YMax = Mean+CI.High)
good.means.p
# mean response across good controls
round(mean(good.means.p$Mean),2) #.xx
ggplot(good.means.p, aes(x=participantID,y=Mean)) +
geom_point() +
geom_errorbar(aes(ymin=YMin, ymax=YMax))+
#geom_text(aes(label=participantID), vjust = 1, cex= 5)+
ylab("Mean response")
# get the participants whose response to the good controls is more than 2 sd below group mean
tmp.good <- good.means.p[good.means.p$Mean < (mean(good.means.p$Mean) - 2*sd(good.means.p$Mean)),]
tmp.good
length(unique(tmp.good$participantID)) #xx participants
# bad controls
controls.bad = d %>%
filter(target == "badControl1" | target == "badControl2")
table(controls.bad$target)
# plot responses by good controls, to see if they worked as expected
bad.means = controls.bad %>%
group_by(target) %>%
summarize(Mean = mean(response),CI.Low = ci.low(response), CI.High=ci.high(response)) %>%
ungroup() %>%
mutate(YMin = Mean-CI.Low, YMax = Mean+CI.High)
bad.means
ggplot(bad.means, aes(x=target,y=Mean)) +
geom_point() +
geom_errorbar(aes(ymin=YMin, ymax=YMax))+
ylab("Mean response")
# plot responses by participant
bad.means.p = controls.bad %>%
group_by(participantID) %>%
summarize(Mean = mean(response),CI.Low = ci.low(response), CI.High=ci.high(response)) %>%
ungroup() %>%
mutate(YMin = Mean-CI.Low, YMax = Mean+CI.High)
bad.means.p
# mean response across bad controls
round(mean(bad.means.p$Mean),2) #.xx
ggplot(bad.means.p, aes(x=participantID,y=Mean)) +
geom_point() +
geom_errorbar(aes(ymin=YMin, ymax=YMax))+
#geom_text(aes(label=participantID), vjust = 1, cex= 5)+
ylab("Mean response")
# get the participants whose response to the bad controls is more than 2 sd above group mean
tmp.bad <- bad.means.p[bad.means.p$Mean < (mean(bad.means.p$Mean) - 2*sd(bad.means.p$Mean)),]
tmp.bad
length(unique(tmp.bad$participantID)) #xx participants
# exclude all participants identified above
d <- d %>%
filter(!(participantID %in% tmp.good$participantID)) %>%
filter(!(participantID %in% tmp.bad$participantID)) %>%
droplevels()
length(unique(d$participantID)) #370, so 23 participants excluded
# exclude participants who always clicked on roughly the same point on the scale
# on the target trials
variances = d %>%
filter(target == "target") %>%
group_by(participantID) %>%
summarize(Variance = var(response)) %>%
mutate(TooSmall = Variance < mean(Variance) - 2*sd(Variance))
variances
lowvarworkers = as.character(variances[variances$TooSmall,]$participantID)
summary(variances)
lowvarworkers # 0 participants consistently clicked on roughly the same point on the scale
# age and gender of remaining participants
table(d$age) #19-80
length(which(is.na(d$age))) # 0 missing values
d %>%
select(gender, participantID) %>%
unique() %>%
group_by(gender) %>%
summarize(count=n())
write_tsv(d, file="../data/d.tsv")
# set working directory to directory of script
this.dir <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(this.dir)
# load required packages
library(tidyverse)
library(ggrepel)
library(dichromat)
library(forcats)
library(ggrepel)
# color-blind-friendly palette
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_bw())
# load helper functions
source('../../../helpers.R')
# load cleaned data
d = read_tsv("../data/d.tsv")
length(unique(d$participantID)) #xx participants
# reduce to target data
t = d %>%
filter(target == "target")
table(t$predicate)
table(t$ai)
# calculate mean naturalness rating by condition and predicate
nat.means = t %>%
group_by(predicate,ai) %>%
summarize(Mean = mean(response), CILow = ci.low(response), CIHigh = ci.high(response)) %>%
#mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, predicate = fct_reorder(as.factor(predicate),Mean))
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh)
nat.means
# order predicates by mean ai in mc condition
tmp = t %>%
filter(ai == "mc") %>%
group_by(predicate) %>%
summarize(Mean = mean(response))
tmp
nat.means$predicate = factor(t$predicate, levels = tmp$predicate[order(tmp$Mean)], ordered = TRUE)
levels(nat.means$predicate)
t$predicate = factor(t$predicate, levels = tmp$predicate[order(tmp$Mean)], ordered = TRUE)
levels(t$predicate)
# plot of naturalness means, with participants' individual responses
ggplot(nat.means, aes(x=ai, y=Mean)) +
geom_point(shape=21,stroke=.5,size=3, color="black", fill = "black") +
geom_errorbar(aes(ymin=YMin,ymax=YMax),width=0.1,color="black") +
geom_violin(data=t,aes(x=ai, y=response),scale="width",color="gray80", fill = "gray80", alpha = .3) +
scale_y_continuous(limits = c(0,1),breaks = c(0,0.2,0.4,0.6,0.8,1.0), labels = c("0",".2",".4",".6",".8","1")) +
guides(fill=FALSE) +
theme(legend.position="top") +
ylab("Mean naturalness rating") +
xlab("At-issueness") +
facet_wrap(. ~ predicate)
ggsave("../graphs/naturalness-by-condition-and-predicate.pdf",height=3,width=7)
# color-blind-friendly palette
cbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
theme_set(theme_bw())
# load helper functions
source('../../../helpers.R')
# load cleaned data
d = read_tsv("../data/d.tsv")
length(unique(d$participantID)) #xx participants
# reduce to target data
t = d %>%
filter(target == "target")
table(t$predicate)
table(t$ai)
# calculate mean naturalness rating by condition and predicate
nat.means = t %>%
group_by(predicate,ai) %>%
summarize(Mean = mean(response), CILow = ci.low(response), CIHigh = ci.high(response)) %>%
#mutate(YMin = Mean - CILow, YMax = Mean + CIHigh, predicate = fct_reorder(as.factor(predicate),Mean))
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh)
nat.means
# order predicates by mean ai in mc condition
tmp = t %>%
filter(ai == "mc") %>%
group_by(predicate) %>%
summarize(Mean = mean(response))
tmp
nat.means$predicate = factor(t$predicate, levels = tmp$predicate[order(tmp$Mean)], ordered = TRUE)
levels(nat.means$predicate)
t$predicate = factor(t$predicate, levels = tmp$predicate[order(tmp$Mean)], ordered = TRUE)
levels(t$predicate)
nat.means$predicate = factor(t$predicate, levels = tmp$predicate[order(tmp$Mean)], ordered = TRUE)
nat.means
# order predicates by mean ai in mc condition
tmp = t %>%
filter(ai == "mc") %>%
group_by(predicate) %>%
summarize(Mean = mean(response))
tmp
nat.means$predicate = factor(t$predicate, levels = tmp$predicate[order(tmp$Mean)], ordered = TRUE)
t$predicate = factor(t$predicate, levels = tmp$predicate[order(tmp$Mean)], ordered = TRUE)
levels(t$predicate)
nat.means
nat.means$predicate = factor(nat.means$predicate, levels = tmp$predicate[order(tmp$Mean)], ordered = TRUE)
levels(nat.means$predicate)
t$predicate = factor(t$predicate, levels = tmp$predicate[order(tmp$Mean)], ordered = TRUE)
levels(t$predicate)
# plot of naturalness means, with participants' individual responses
ggplot(nat.means, aes(x=ai, y=Mean)) +
geom_point(shape=21,stroke=.5,size=3, color="black", fill = "black") +
geom_errorbar(aes(ymin=YMin,ymax=YMax),width=0.1,color="black") +
geom_violin(data=t,aes(x=ai, y=response),scale="width",color="gray80", fill = "gray80", alpha = .3) +
scale_y_continuous(limits = c(0,1),breaks = c(0,0.2,0.4,0.6,0.8,1.0), labels = c("0",".2",".4",".6",".8","1")) +
guides(fill=FALSE) +
theme(legend.position="top") +
ylab("Mean naturalness rating") +
xlab("At-issueness") +
facet_wrap(. ~ predicate)
nat.means
# import asking-whether ratings from this repo, where the ai means were calculated over Exps 1 and 2
# for the Glossa Psycholinguistics paper
tmp <- read_csv("https://raw.githubusercontent.com/judith-tonhauser/attitude_preds_projection/master/results/expsDT12/data/ai.means.csv")
summary(tmp)
# calculate ai means by predicate (short_trigger) and reduce to the six predicates
# the subscript _AW identifies these data as the "asking whether" data
ai.means = tmp %>%
filter(short_trigger == "be right" | short_trigger == "think" | short_trigger == "know" |
short_trigger == "confess" | short_trigger =="say" | short_trigger == "discover") %>%
group_by(short_trigger) %>%
summarize(Mean_AW = mean(Mean_ai), CILow = ci.low(Mean_ai), CIHigh = ci.high(Mean_ai)) %>%
mutate(YMin_AW = Mean_AW - CILow, YMax_AW = Mean_AW + CIHigh) %>%
select(-c(CILow, CIHigh)) %>%
rename("predicate" = "short_trigger")
ai.means
# calculate mean responses from target data, reduce to ai = cc data, and bind with "asking whether" data
t.means = t %>%
group_by(predicate,ai) %>%
summarize(Mean = mean(response), CILow = ci.low(response), CIHigh = ci.high(response)) %>%
mutate(YMin = Mean - CILow, YMax = Mean + CIHigh) %>%
select(-c(CILow, CIHigh)) %>%
left_join(., ai.means, by = "predicate")
t.means
# plot with CC at-issue
ggplot(t.means[t.means$ai == "cc",], aes(x = Mean, y = Mean_AW),label = predicate) +
geom_point(stroke=.5,size=2.5,color="black") +
geom_errorbar(aes(ymin=YMin_AW,ymax=YMax_AW),width=.01,color="black") +
geom_errorbarh(aes(xmin=YMin,xmax=YMax),height=.01,color="black") +
geom_text_repel(aes(label = predicate),
#box.padding   = 0.35,
point.padding = 0.5,
segment.color = 'grey50') +
scale_x_continuous(limits = c(0,1),breaks = c(0,0.2,0.4,0.6,0.8,1.0), labels= c("0",".2",".4",".6",".8","1")) +
scale_y_continuous(limits = c(0,1),breaks = c(0,0.2,0.4,0.6,0.8,1.0), labels= c("0",".2",".4",".6",".8","1")) +
geom_abline(intercept=1,slope=-1,color="gray70",linetype="dashed") +
xlab("Mean naturalness rating (when CC is at-issue)") +
ylab("Mean asking-whether rating") +
theme(panel.spacing.x = unit(4, "mm")) +
coord_fixed(ratio = 1)
ggsave("../graphs/comparison-1A-CC-at-issue-asking-whether.pdf",height=4,width=4)
# compare using means and violin plots
ggplot(t.means, aes(x=predicate, y=Mean, group = ai)) +
geom_point(shape=21,stroke=.5,size=3, aes(color = ai, fill=ai)) +
geom_point(data=t.means, aes(x=predicate, y=Mean_AW), color = "green", size=3) +
#geom_errorbar(aes(ymin=YMin,ymax=YMax),width=0.1,color="black") +
#geom_errorbar(data=t.means,aes(ymin=YMin_AW,ymax=YMax_AW),width=0.1,color="red") +
#geom_violin(data=t,aes(x=predicateAI, y=response),scale="width",color="gray80", fill = "gray80", alpha = .3) +
scale_y_continuous(limits = c(0,1),breaks = c(0,0.2,0.4,0.6,0.8,1.0), labels = c("0",".2",".4",".6",".8","1")) +
guides(fill=FALSE) +
theme(legend.position="top") +
ylab("Mean naturalness rating") +
xlab("Predicate")
