% !TEX TS-program = lualatexmk
% glossa-template.tex
% Copyright 2016 Guido Vanden Wyngaerd
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
% 
% The Current Maintainer of this work is 
% Guido Vanden Wyngaerd (guido.vandenwyngaerd@kuleuven.be).
%
% This work consists of the files 
% glossa.cls
% glossa.bst
% gl-authoryear-comp.cbx
% biblatex-gl.bbx
% glossa-template.tex
% glossa.png
%
% The files of the work are derived from the Semantics & Pragmatics style files
% by Kai von Fintel, Christopher Potts, and Chung-chieh Shan
% All changes are documented on the github repository 
% https://github.com/guidovw/Glossalatex.

\PassOptionsToPackage{table}{xcolor}
\documentclass[times,linguex,xcolor]{glossa}
\usepackage{rotating}
\usepackage{tablefootnote}
\usepackage{colortbl}
\usepackage{color}
\usepackage{multicol}
\usepackage{booktabs}

\usepackage{adjustbox}
\usepackage{array}

\newcolumntype{R}[2]{%
    >{\adjustbox{angle=#1,lap=\width-(#2)}\bgroup}%
    l%
    <{\egroup}%
}

\newcommand*\rots{\multicolumn{1}{R{90}{.7em}}}% no optional argument here, please!
%\usepackage{xcolor}

% possible options:
% [times] for Times font (default if no option is chosen)
% [cm] for Computer Modern font
% [lucida] for Lucida font (not freely available)
% [brill] open type font, freely downloadable for non-commercial use from http://www.brill.com/about/brill-fonts; requires xetex
% [charis] for CharisSIL font, freely downloadable from http://software.sil.org/charis/
% for the Brill an CharisSIL fonts, you have to use the XeLatex typesetting engine (not pdfLatex)
% for headings, tables, captions, etc., Fira Sans is used: https://www.fontsquirrel.com/fonts/fira-sans
% [biblatex] for using biblatex (the default is natbib, do not load the natbib package in this file, it is loaded automatically via the document class glossa.cls)
% [linguex] loads the linguex example package
% !! a note on the use of linguex: in glossed examples, the third line of the example (the translation) needs to be prefixed with \glt. This is to allow a first line with the name of the language and the source of the example. See example (2) in the text for an illustration.
% !! a note on the use of bibtex: for PhD dissertations to typeset correctly in the references list, the Address field needs to contain the city (for US cities in the format "Santa Cruz, CA")

%\addbibresource{sample.bib}
% the above line is for use with biblatex
% replace this by the name of your bib-file (extension .bib is required)
% comment out if you use natbib/bibtex

\let\B\relax %to resolve a conflict in the definition of these commands between xyling and xunicode (the latter called by fontspec, called by charis)
\let\T\relax
\usepackage{xyling} %for trees; the use of xyling with the CharisSIL font produces poor results in the branches. This problem does not arise with the packages qtree or forest.
%\usepackage[linguistics]{forest} %for nice trees!


% \pdf* commands provide metadata for the PDF output. ASCII characters only!
\pdfauthor{}
\pdftitle{What is at-issueness?}
\pdfkeywords{}

\title[What is at-issueness?]{What is at-issueness? An experimental comparison of diagnostics\\ 
  % \bigskip \large Word count: 4720
  }
% Optional short title inside square brackets, for the running headers.

\author[]% short form of the author names for the running header. If no short author is given, no authors print in the headers.
{%as many authors as you like, each separated by \AND.
  % \spauthor{Waltraud Paul\\
  % \institute{CRLAO, CNRS-EHESS-INALCO}\\
  % \small{%105, Bd. Raspail, 75005 Paris\\
  % waltraud.paul@ehess.fr}
  % }
  % \AND
  % \spauthor{Guido Vanden Wyngaerd \\
  % \institute{KU Leuven}\\
  % \small{%Warmoesberg 26, 1000 Brussel\\
  % guido.vandenwyngaerd@kuleuven.be}
  % }%
}

\input{author-added}

% positive coefficients/difference
\definecolor{red}{RGB}{178,24,43}

% negative coefficients/difference
\definecolor{blue}{RGB}{33,102,172}

% comments by JT
\newcommand{\jt}[1]{\textbf{\color{orange}JT: #1}}

\begin{document}


\maketitle


\begin{abstract}
  at-issueness is a key concept in theoretical semantics/pragmatics, but there is no consensus about how it is defined or diagnosed (e.g., \citealt{tonhauser_diagnosing_2012,tonhauser_how_2018,koev_notions_2018}). We present experimental data investigating whether four widely used diagnostics for at-issueness yield consistent results. Our findings reveal significant differences across diagnostics, indicating they are not interchangeable. Since the diagnostics target distinct theoretical conceptions of at-issueness, these differences offer insight into their comparability.

\end{abstract}

% \begin{keywords}
%   at-issueness, experimental pragmatics, discourse interpretation
% \end{keywords}

\section{Introduction \label{sec:1_introduction}}
  
  At-issueness is a key concept in theoretical semantics and pragmatics, distinguishing propositions that constitute the main point of an utterance (at-issue content) from those expressing background information (non-at-issue content; \jt{I prefer not-at-issue, and i'd like to be consistent with my previous publications, if possible} e.g., \citealt{karttunen_conventional_1979,horton_presuppositions_1988,abbott_presuppositions_2000,faller_semantics_2003,potts_logic_2005,tonhauser_diagnosing_2012}). Despite its importance, the concept lacks a unified definition.\jt{I'd rather say more explicitly here that there are multiple definitions and multiple diagnostics, and that it's an open question of whether they are all about the same concept.} Instead, various theoretical notions coexist (\citealt{koev_notions_2018,tonhauser_how_2018}) alongside multiple empirical diagnostics (e.g., \citealt{tonhauser_diagnosing_2012}). \jt{before saying what the paper investigates, we should give uninitiated readers more insight into the current state of the field. we should then say what the larger questions are, and how are investigation is a first step towards investigating these larger questions}
  %
  This paper investigates whether four widely €used diagnostics for at-issueness yield consistent results when testing the same stimuli. Our findings reveal significant differences across diagnostics, indicating they are not interchangeable. Since the diagnostics target distinct theoretical conceptions of at-issueness, the differences offer insight into the comparability of these conceptions.

  The four diagnostics under consideration are illustrated in (\pref{qud}--\pref{aw}) for sentence-medial appositive non-restrictive relative clauses (NRRCs), which are usually taken to contribute non-at-issue content (\citealt{potts_logic_2005}). \jt{Our introduction also needs to address the question of whether at-issueness is gradient or categorical so that we can introduce the diagnostics appropriately.} Therefore, participants are expected to: Give low naturalness ratings under the QUD diagnostic \ref{qud} and the direct dissent diagnostic \ref{dd}; prefer a \emph{yes}-response under the `yes, but' diagnostic in \ref{yesbut}; and not interpret the speaker to be asking about the content under the `asking-whether' diagnostic in \ref{aw}.

  \ex. \label{qud}%
    QUD diagnostic (e.g., \citealt{tonhauser_diagnosing_2012,chen_presuppositions_2024})
    \a.[A:] \emph{What did Greg buy?}
    \b.[B:] \emph{Greg, who bought a new car, is envied by his neighbor.}
    \z.
    Question to participants: How well does B's response fit A's question?
  \z.

  \ex. \label{dd} Direct dissent diagnostic (e.g., \citealt{tonhauser_diagnosing_2012,syrett_experimental_2015})
    \a.[A:] \emph{Greg, who bought a new car, is envied by his neighbor.}
    \b.[B:]\emph{No, that's not true, he didn't buy a new car.}
    \z.
  Question to participants: How natural is B's rejection of A's utterance?
  \z.

  \ex. \label{yesbut}%
    `yes, but' diagnostic (e.g., \citealt{xue_correlation_2011,destruel_cross-linguistic_2015})
    \a.[A:] \emph{Greg, who bought a new car, is envied by his neighbor.}
    \b.[B:] \emph{Yes, but he didn't buy a new car.} /
    \b.[] \emph{Yes, and he didn't buy a new car.} /
    \b.[] \emph{No, he didn't buy a new car.}
    \z.
    Task for participants: Choose the response that sounds best.
  \z.

  \ex. \label{aw}%
    `asking whether' diagnostic (e.g., \citealt{tonhauser_how_2018,solstad_cataphoric_2024})\smallskip\\
      \emph{Is Greg, who bought a new car, envied by his neighbor?}\smallskip
  \\ Question to participants: Is the speaker asking whether Greg bought a new car?
  \z.

  \citealt{koev_notions_2018} argues that these diagnostics reflect distinct theoretical conceptions of at-issueness: The QUD diagnostic \ref{qud} aligns with Q(uestion)-at-issueness (\citealt{simons_what_2010}), which conceptualizes at-issue content as addressing a question under discussion (QUD; \citealt{roberts_information_1996,ginzburg_interrogatives_1996}) established in prior discourse (\citealt{amaral_review_2007}).
  %
  The direct dissent \ref{dd} and `yes, but' diagnostics \ref{yesbut}, in contrast, reflect P(roposal)-at-issueness (\citealt{koev_apposition_2013}), characterizing at-issue content as the main assertion of an utterance. This is understood as a proposal to update the common ground, which can be directly affirmed or denied using default discourse moves that include polar response particles (PRPs; e.g., English \emph{yes/no}; \citealt{farkas_reacting_2010}). Conversely, non-at-issue content is either presupposed (already entailed in the common ground; \citealt{stalnaker_presuppositions_1973,stalnaker_common_2002}), or newly imposed on the common ground (\citealt{murray_varieties_2014,anderbois_at-issue_2015}), and requires special moves for disagreement, like revision, correction, or negotiation (\citealt{potts_logic_2005}).
  %
  Finally, the `asking whether' diagnostic (\citealt{tonhauser_how_2018}) assums tht the at-issue content of questions explicitly raises a QUD, whereas their non-at-issue content does not contribute to what the QUD is (following \citealt{roberts_information_1996}). While closely related to Q-at-issueness, this diagnostic does not fully align with Koevâ€™s Q/P distinction, a point we revisit in the discussion (\Cref{sec:discussion}).

  Prior studies reach diverging conclusions about the at-issueness of certain types of content, potentially arising from diagnostic differences: Studies examining appositives (summarized in \Cref{tab:appositive-previous-findings}) and complements of epistemic predicates such as \emph{know} and \emph{discover} (\Cref{tab:embedding-previous-findings}) provide inconsistent classifications depending on the diagnostic employed.

  \begin{table}[ht]
    \caption{Overview of empirical findings about appositives}
    \label{tab:appositive-previous-findings}
    \centering
    \resizebox{.9\linewidth}{!}{
    \begin{tabular}{l c c}\toprule
                                    & medial         & final        \\
                                    & appositives    & appositives    \\\midrule\midrule

      \citealt{tonhauser_diagnosing_2012}, direct dissent/assent diagnostic     & \multirow{2}{*}{NAI}
                                                    & \multirow{2}{*}{--} \\ 
      \scriptsize Paraguayan GuaranÃ­, fieldwork elicitation  &  \\ \midrule

      \citealt{syrett_experimental_2015}, direct dissent     & \multirow{2}{*}{NAI}
                                                    & \multirow{2}{*}{AI} \\ 
      \scriptsize English, forced-choice continuation  &  \\ \midrule

      \citealt{anderbois_at-issue_2015}, direct assent     & \multirow{2}{*}{NAI}
                                                    & \multirow{2}{*}{AI} \\ 
      \scriptsize English, corpus examples and impressionistic judgments   &  \\ \midrule

      \citealt{koev_notions_2018}, direct dissent     & \multirow{2}{*}{NAI}
                                                    & \multirow{2}{*}{--} \\ 
      \scriptsize English, impressionistic judgments  &  \\ \midrule

      \citealt{destruel_cross-linguistic_2015}, `yes but'     & \multirow{2}{*}{NAI}
                                                    & \multirow{2}{*}{--} \\ 
      \scriptsize German, forced-choice continuation  &  \\ \midrule\midrule

      \citealt{koev_notions_2018}, QUD 
                                    & \multirow{2}{*}{AI}
                                                    & \multirow{2}{*}{--} \\ 
      \scriptsize English, impressionistic judgments  &  \\ \midrule

      \citealt{tonhauser_diagnosing_2012}, QUD     & \multirow{2}{*}{?}
                                                    & \multirow{2}{*}{--} \\ 
      \scriptsize Paraguayan GuaranÃ­, fieldwork elicitation  &  \\ \midrule

      \citealt{chen_presuppositions_2024}, QUD     & \multirow{2}{*}{NAI}
                                                    & \multirow{2}{*}{--} \\ 
      \scriptsize German, 5-point rating  &  \\ \midrule\midrule

      \citealt{tonhauser_how_2018}, `asking whether'    & \multirow{2}{*}{NAI}
                                                    & \multirow{2}{*}{--} \\ 
      \scriptsize English, forced-choice continuation  &  \\ \bottomrule

  \end{tabular}}
  \end{table}

  The often reported observation that sentence-medial appositives contribute non-at-issue content is supported by several empirical studies, but findings differ by diagnostic. Using the direct-dissent diagnostic, medial appositives consistently behave as non-at-issue across multiple languages and methods, including fieldwork elicitation for Paraguayan GuaranÃ­ (\citealt{tonhauser_diagnosing_2012}), a forced-choice continuation task in English (\citealt{syrett_experimental_2015}), and impressionistic judgments in English (\citealt{potts_logic_2005,amaral_review_2007}). The same conclusion emerges for German medial appositives with the `yes, but' diagnostic in a forced-choice continuation task (\citealt{destruel_cross-linguistic_2015}), and the `asking whether' diagnostic concurs by classifying English medial appositives as clearly non-at-issue (\citealt{tonhauser_how_2018,solstad_cataphoric_2024}).\jt{this reads as if at-issueness is categorical. i think we need to be a bit more nuanced.}

  \citealt{koev_notions_2018} suggests that English medial appositive NRRCs, though non-at-issue under the direct-dissent test, can behave as at-issue under the QUD diagnostic. This is in line with \citepos{tonhauser_diagnosing_2012} findings for Paraguayan GuaranÃ­ medial appositive DPs: These are not-at-issue on most diagnostics tested there (including direct dissent, and `yes, but'), but yielded mixed results with the QUD-diagnostic. Not in line with Koev's suggestion are low QUD match ratings for German medial appositives found by \citet{chen_presuppositions_2024}, suggesting a clear preference for a non-at-issue interpretation; however, these clauses contained the discourse marker \emph{Ã¼brigens} (â€˜by the wayâ€™), which, Chen suggests, supports a non-at-issue interpretation. These diverging findings give rise to our first question: (i) can we replicate a systematic difference between the QUD-diagnostic and direct dissent, â€˜yes, butâ€™, and `asking whether' for sentence-medial appositives?

  In contrast, it has been argued that sentence-final appositives can be interpreted as at-issue for the direct-dissent diagnostic, for instance, based on English corpus examples in \citealt{anderbois_at-issue_2015}, and notably \citepos{syrett_experimental_2015} forced-choice continuation task experiment.\jt{Table 1 suggests that they are AI, but the discussion here is more nuanced ``can be at-issue''.} \citealt{koev_notions_2018} makes a similar point for English sentence-final slifting parentheticals (e.g., \emph{Ellen is a passionate cook, her fiancÃ© claimed;} p. 11): these behave as at-issue based on the direct-dissent but not the QUD diagnostic. These results prompt an additional question: (ii) Can the contrast between medial and final appositives be replicated with direct dissent, and will any of the other three diagnostics reveal a similar difference?

  In the literature testing the at-issueness of the embedded content of clause embedding predicates, findings (summarized in \Cref{tab:embedding-previous-findings}) are mixed as well. 

\jt{Table 2 has a lot of -- because many of the studies did not investigate the five predicates summarized here. I am not happy with the binary classification superimposed on the results of the experiments...}

  \begin{table}[ht]
    \caption{Overview of empirical findings about clause-embedding predicates}
    \label{tab:embedding-previous-findings}
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{l c c c cc c c c}\toprule
        & \emph{know} 
          & \emph{discover}
            & \emph{confess}
              & \emph{confirm}
                & \emph{be right}
                  % & \emph{find out}
                    \\\midrule\midrule

    \citealt{tonhauser_how_2018}, `asking whether'
        & \multirow{2}{*}{NAI}
          & \multirow{2}{*}{NAI}
            & \multirow{2}{*}{NAI}
              & \multirow{2}{*}{--}
                & \multirow{2}{*}{--}
                  % & \multirow{2}{*}{--}
                    \\ 
    \scriptsize English, slider rating  &  \\ \midrule

    \citealt{solstad_cataphoric_2024}, `asking whether'
        & \multirow{2}{*}{NAI}
          & \multirow{2}{*}{NAI}
            & \multirow{2}{*}{--}
              & \multirow{2}{*}{--}
                & \multirow{2}{*}{--}
                  % & \multirow{2}{*}{--}
                    \\ 
    \scriptsize German, slider rating  &  \\ \midrule

    \citealt{degen-tonhauser-glossa}, `asking whether'
        & \multirow{2}{*}{NAI}
          & \multirow{2}{*}{?}
            & \multirow{2}{*}{?}
              & \multirow{2}{*}{AI}
                & \multirow{2}{*}{AI}
                  % & \multirow{2}{*}{--}
                    \\ 
    \scriptsize English, slider rating  &  \\ \midrule \midrule

    \citealt{tonhauser_diagnosing_2012}, direct dissent/assent
        & \multirow{2}{*}{NAI}
          & \multirow{2}{*}{--}
            & \multirow{2}{*}{--}
              & \multirow{2}{*}{--}
                & \multirow{2}{*}{--}
                  % & \multirow{2}{*}{--}
                    \\ 
    \scriptsize Paraguayan GuaranÃ­, fieldwork elicitation  &  \\ \midrule \midrule

    \citealt{tonhauser_diagnosing_2012}, QUD, `yes, but' 
        & \multirow{2}{*}{AI}
          & \multirow{2}{*}{--}
            & \multirow{2}{*}{--}
              & \multirow{2}{*}{--}
                & \multirow{2}{*}{--}
                  % & \multirow{2}{*}{--}
                    \\
    \scriptsize Paraguayan GuaranÃ­, fieldwork elicitation  &  \\ \midrule

    \citealt{chen_presuppositions_2024}, QUD
        & \multirow{2}{*}{--}
          & \multirow{2}{*}{AI}
            & \multirow{2}{*}{--}
              & \multirow{2}{*}{--}
                & \multirow{2}{*}{--}
                  % & \multirow{2}{*}{--}
                    \\ 
    \scriptsize German, 5-point rating  &  \\ \midrule

    \citealt{xue_correlation_2011}, `yes, but'
        & \multirow{2}{*}{AI}
          & \multirow{2}{*}{--}
            & \multirow{2}{*}{--}
              & \multirow{2}{*}{--}
                & \multirow{2}{*}{--}
                  % & \multirow{2}{*}{?}
                    \\ 
    \scriptsize German, forced-choice continuation  &  \\ \midrule

    \end{tabular}}
  \end{table}

  The `asking whether' diagnostic consistently characterizes complements of epistemic predicates (like English \emph{know}) as non-at-issue: Using a slider reponse task, \citealt{tonhauser_how_2018} found that clauses embedded under \emph{know} and \emph{discover} are clearly non-at-issue,\jt{really? i mean, we didn't run stats but looking at the figure and the means, is this really so clear? the CC of discover is less not-at-issue than the content of NRRCs. i'd like to move away from a binary talk about at-issueness.} and those under \emph{confess} only slightly less so. Using the same method, \citealt{degen-tonhauser-glossa} found fine-grained lexical differences for the at-issueness of the embedded content of 20 English clause-embedding predicates: \Cref{fig:dtglossa} shows the distribution of `asking whether' ratings by predicate with means and 95\% bootstrapped confidence intervals. Their results again place the complement of \emph{know} solidly in the non-at-issue range,\jt{this sounds like there's a not-at-issue range and an at-issue range?} while \emph{discover} and \emph{confess}, with mean ratings around $0.6$ on the 0--1 scale, show only a weak preference towards a non-at-issue interpretation.

  Findings for epistemic complements vary by diagnostic: In Paraguayan GuaranÃ­, clauses embedded under \emph{(oi)kuaa} `know' behaves as at-issue regarding the `yes but' and QUD diagnostic, but as not-at-issue regarding the direct dissent(/assent) test (\citealt{tonhauser_diagnosing_2012}). Similarly, \citepos{chen_presuppositions_2024} 5-point rating experiment using the QUD-diagnostic found that the embedded content of German \emph{wissen} `know' shows a preference for an at-issue interpretation;\jt{which experiment in her thesis is this? i can't figure out what this claim is based on.} and a forced-choice continuation task using the `yes but' test in German (\citealt{sue_correlation_2011}) found the same for \jt{know?} and \emph{entdecken} `discover'.\jt{only 50\% for entdecken}
  %
  These findings could suggest cross-linguistic differences, so that the embedded content of English \emph{know} and \emph{discover} is less at-issue than that of Paraguayan GuaranÃ­ \emph{(oi)kuaa} and German \emph{wissen} `know' and \emph{entdecken} `discover'.  However, \citealt{solstad_cataphoric_2024} finds that the embedded contents of German \emph{wissen} `know' and \emph{entdecken} `discover' are interpreted as not-at-issue, using `asking whether' diagnostic and the same methodology as \citealt{tonhauser_how_2018,degen-tonhauser-glossa}. The differences therefore appear to arise from diagnostic differences rather than cross-linguistic differences. The findings summarized here thus motivate another key question for the present study: (iii) Will we find a difference for \emph{know} between the asking-whether diagnostic and the other three? \jt{ok, interesting, you made the RQs about whether our experiments will show differences between diagnostics that were in prior literature whereas I had been thinking about whether our experiments will show differences between contents revealed in previous experiments/diagnostics}
  
  \begin{figure}[h!]
  \centering

  \includegraphics[width=0.7\textwidth]{../../results/degen-tonhauser-glossa/graphs/mean-asking-whether-ratings.pdf}

  \caption{Mean `asking whether' ratings for the contents of the clausal complements of 20 clause-embedding predicates, from \citealt{degen-tonhauser-glossa}.}
  \label{fig:dtglossa}
  \end{figure}
  

  In summary, we will investigate the questions developed above, and repeated here: \jt{these questions are very differentiated. and aren't we, as linguists, more interested in the relative at-issueness of the contents than whether we can replicate differences between diagnostics?}
    \begin{enumerate}
      \item Can we replicate a systematic difference between the QUD-diagnostic and direct dissent, â€˜yes, butâ€™, and `asking whether' for sentence-medial appositives? \jt{i don't understand this question: what are we comparing sentence-medial appositives to?}
      \item Can the contrast between medial and final appositives be replicated with direct dissent, and will any of the other three diagnostics reveal a similar difference?
      \item Will we find a difference for \emph{know} between the asking-whether diagnostic and the other three? \jt{same question here: what are we comparing know to? i don't want to have to compare numbers across diagnostics, e.g., if one diagnostics gives a mean of .9 for know and the other one a mean of .85, then what? these numbers don't mean anything unless we compare know to other contents}
    \end{enumerate}

  In addition, to systematically assess differences between the diagnostics, we follow \citealt{tonhauser_how_2018}, which includes a brief comparison of the `asking whether' diagnostic and another diagnostic used there, the `are you sure' diagnostic\footnote{say something about this?}. 

  \begin{itemize}
    \item compare where they distinguish between the tested expressions, and where they dont
    \item the relative order between these items
    \item the spread and variation between the ratings for the items
    \item the spread and variation within the ratings for the items
  \end{itemize}

  The paper will proceed as follows:
  \begin{itemize}
    \item \Cref{sec:2_experiments}: exps 1--4
    \item \Cref{sec:3_more-experiments}: exps 5 and 6
    \item \Cref{sec:4_discussion}: General discussion
    \item \Cref{sec:5_conclusion}: Conclusion

  \end{itemize}
  
\newpage

\section*{Intro reconceived}

\begin{itemize}[leftmargin=12pt]

\item At-issueness is a key concept in experimental and theoretical semantics and pragmatics, relied on in the analysis of a broad range of phenomena (give examples). 

\item But what is at-issueness? There are multiple definitions and multiple diagnostics that make different assumptions about how at-issue content differs from not-at-issue content (give details on definitions and diagnostics, these could be the diagnostics we will eventually use).

\item So, we're currently in a state where there is no agreed on definition of at-issueness and multiple diagnostics. This raises the question of whether the currently available definitions define the same underlying concept and whether the diagnostics yield the same result. These are pressing questions for research on at-issueness (see, e.g., Tonhauser et al 2018, Koev 2018, who else?)

\item Some research has suggested that the answers to both of these questions is ``no'':

\begin{itemize}

\item On the theory-side, Snider: suggests that q-at-issueness and p-at-issueness differ (Korotkova?)

\item On the diagnostics-side, NRRCs: some research assumes that the content of medial and final ones is not-at-issue but Syrett/Koev results suggest that medial ones are more not-at-issue than final ones

\item On the diagnostics-side, Tonhauser et al 2018: comparison of asking-whether and are you sure diagnostic suggests some differences (p.526ff)

\item On the diagnostics-side, Tonhauser et al 2018 asking whether didn't find difference in exp 1a between know and discover (see also Solstad/Bott) but Xue/Onea found difference between wissen and entdecken

\item On the diagnostics-side, Degen/Tonhauser 2025 found fine-grained differences between CCs of clause-embedding predicates using the asking-whether diagnostic, where Hooper 1975 distinguished weak assertive (e.g., think, acknowledge), strong assertive (e.g., say, suggest), semi-factive (assertive; e.g., see, discover, know) and factive (nonassertive; e.g., be annoyed).


\end{itemize}

\item To date, there has not been a systematic comparison of diagnostics to understand whether different diagnostics yield the same results.

\item This paper takes a first step towards addressing the important questions pointed out above. Specifically, we compare the results of diagnostics to identify whether diagnostics yield the same results. As these diagnostics also differ in their underlying assumptions about at-issueness, the results of our experiments also bear on the question of whether currently available definitions define the same underlying concept.

\item The way we do this is by investigating the at-issueness of the same contents with several different diagnostics. 

\begin{itemize}

\item Exps 1-4:  

\begin{itemize}

\item Contents: Sentence-medial and -final NRRCs because one diagnostic found a difference, CCs of clause-embedding predicates because another diagnostic found fine-grained differences

\item Are these differences between contents replicated by the use of other diagnostics?

\end{itemize}

\item Exps 5-6:

\begin{itemize}

\item Contents: CCs of clause-embedding predicates because one diagnostic found fine-grained differences

\item Are these differences between contents replicated by the use of other diagnostics?

\end{itemize}

\end{itemize}

\item A note on terminology before we get started:

\begin{itemize}

\item The theoretical concept of at-issueness may be a categorical notion or a gradient one (see, e.g., Tonhauser et al 2018, Ebert/xx 2024), we remain agnostic here.

\begin{itemize}

\item Categorical: e.g., content is at-issue iff it addresses the QUD, not-at-issue otherwise; gradient mean ratings could be attributed to uncertainty about what the QUD is

\item Gradient: e.g., the extent to which content is at-issue is the extent to which it is relevant to the QUD; gradient mean ratings may be taken to reflect gradient relevance.

\end{itemize}

\item We will continue talking about the diagnostics as diagnostics for at-issueness, even if they may ultimately turn out to not be diagnosing the same underlying concept.

\item For each diagnostic, we will collect ratings: e.g., under the `asking-whether' diagnostic we collect asking-whether ratings, under the QUD diagnostic we collect naturalness ratings. We compare the mean ratings of the contents under each diagnostic; given that we are aggregating over multiple items and participants (and ratings on a scale for some), we may say that the mean rating for one content is higher/lower than that of another, or that they do not differ. 

\item We will take these results to suggest that, given a particular diagnostic, one content is more/less at-issue than another or that the two contents don't differ in at-issueness. We will do this even though the diagnostics may ultimately diagnose different concepts. Also, this does not commit us to a categorical or gradient theoretical notion of at-issueness (see above).

\end{itemize}

\end{itemize}  

\bigskip

\noindent
{\bf Bigger story of the paper}

\begin{itemize}[leftmargin=12pt]

\item Exps 1-4 suggest than none of the diagnostics as implemented distinguish between sentence-medial and -final NRRCs, not even the `direct dissent' diagnostic of Exp 3, contra Syrett/Koev. 

\item This suggests that even small changes like the response task might matter and also that the diagnostics differ in whether they predict a differences in at-issueness between sentence-medial and -final NRRCs.

\item Of Exps 1-4, only Exp 2 (asking whether) comes close to suggesting the difference in the CCs of the clause-embedding predicates observed in Degen/Tonhauser 2025. This suggests that the diagnostics differ in whether they predict a differences in at-issueness between the CCs of clause-embedding predicates.

\item Overall, Exps 1-4 suggest that at-issueness diagnostics are not interchangeable as they differ in the relative differentiation of the seven contents investigated. 

\item Given that the diagnostics pertain to different definitions of at-issueness, this also suggests that those definitions may define different concepts; as suggested in Snider.

\item {\bf Discussion section Exps1-4:} The asking-whether diagnostic shows the greatest differentiation between the contents.  It is the only diagnostic where the contents to be diagnosed are in polar interrogatives and the diagnostic relies on the assumption that at-issue content partitions the context set denoted by the polar interrogative.

\item Question: Is the differentiation due to the content being embedded in an interrogative or due to the response task (which is about which content partitions the context set)?

\item Exps 5-6: We investigate the aforementioned question by comparing asking whether diagnostic (Exp 5) to direct assent diagnostic where content is embedded in interrogative (Exp 5)

\item We find high correlation (Spearman rank), so this suggests that the high differentiation may be due to interrogative embedding and not the response task (partition of context set by at-issue content). 

\item {\bf General discussion:} 

\begin{itemize}

\item diagnostics give different results; some of these differences may be due to response tasks, others may be due to different underlying concepts

\item interrogative embedding seems to matter, so speech acts also need to be taken into consideration when considering what at-issueness is and how it is diagnosed

\item future research will need to make sure that results may only be due to particular response task used, empirical investigations should continue path of using multiple diagnostics 

\end{itemize}

\end{itemize}

  
\newpage


\section{Experiments 1-4 \label{sec:2_experiments}}

  To compare the results of at-issueness diagnostics, we conducted four experiments that each measured at-issueness with a different diagnostic, namely the QUD diagnostic (Exp.~1), the `asking whether' diagnostic (Exp.~2), the direct dissent diagnostic (Exp.~3) and the `yes, but' diagnostic (Exp.~4).\footnote{The experiments, data and R code for generating the figures and analyses of the experiments reported in this paper are available at INSERT URL TO ANONYMOUS GITHUB REPO BEFORE SUBMISSION. All experiments were conducted with approval from the ethics review committee of [university name redacted for review].} To be able to compare the results of the diagnostics, the same seven contents, shown in \ref{stims}, were investigated under the four diagnostics: the contents of sentence-medial and sentence-final NRRCs \ref{stims.a}-\ref{stims.b}, as well as the contents of the clausal complements of \emph{know, discover, confess, confirm} and \emph{be right} \ref{stims.c}-\ref{stims.g}. These seven contents were instantiated by the same items across the four experiments.

  \ex.\label{stims}
    \a.\label{stims.a} Content of sentence-medial NRRC \\
      \emph{Lucy, who broke the plate, apologised.} $\leadsto$ Lucy broke the plate
    \b.\label{stims.b} Content of sentence-final NRRC \\
    \emph{The police found Jack, who saw the murder.} $\leadsto$ Jack saw the murder
    \b.\label{stims.c} Content of the clausal complement of \emph{know} \\
    \emph{Ann knows that Raul cheated on his wife.} $\leadsto$ Raul cheated on his wife
    \b.\label{stims.d} Content of the clausal complement of \emph{discover} \\
    \emph{Mary discovered that Denny ate the last cupcake.} $\leadsto$ Denny ate the last cupcake
    \b.\label{stims.e} Content of the clausal complement of \emph{be right} \\
    \emph{Tom is right that Ann stole the money.} $\leadsto$ Ann stole the money
    \b.\label{stims.f} Content of the clausal complement of \emph{confirm} \\
    \emph{Harry confirmed that Greg bought a new car.} $\leadsto$ Greg bought a new car
    \b.\label{stims.g} Content of the clausal complement of \emph{confess}  \\
    \emph{Lucy confessed that Dustin lost his key.} $\leadsto$ Dustin lost his keys
    \z.
  \z.
  
  These seven contents were chosen because prior literature observed differences in at-issueness between two or more of these contents using a particular diagnostic for at-issueness.  Specifically, as discussed in section \S1, \citealt{syrett_experimental_2015} observed differences between sentence-medial and -final NRRCs using a variant of the direct dissent diagnostic, \citealt{tonhauser_how_2018} observed differences between sentence-final NRRCs and the contents of the complements of \emph{know, discover} and \emph{confess} using the `asking whether' diagnostic, and \citealt{degen-tonhauser-glossa} observed differences between \emph{know, discover, confess, confirm} and \emph{be right}, also using the `asking whether' diagnostic. Thus, comparing these seven contents across the four diagnostics in Exps.~1-4 will allow us to assess whether the differences that emerge from one diagnostic also emerge from others. 

  In each experiment, participants read the stimuli and gave ratings corresponding to the diagnostics.

  \subsection{Methods}
    
  \subsubsection{Participants}

  For each of the four experiments, we recruited unique 80 participants on Prolific. These participants had registered on the platform as living in the USA and as having English as their primary language. They had at least 50 previous submissions and an approval rate of at least 97\%.  Table \ref{t:recruited} shows the age and gender distributions of the recruited participants.

  \begin{table}[h!]
  \centering
  \begin{tabular}{l | c | r r r }
              & recruited & ages (mean age) & f/m/nb/dnd \\ \hline
  Exp.~1 (QUD) & 80 & 18-81 (43.8) & 42/37/0/1  \\
  Exp.~2 (asking whether) & 80 & 20-74 (38.5)  & 48/30/1/1  \\
  Exp.~3 (direct dissent) & 80 & 18-77 (39.1) & 50/28/1/1  \\
  Exp.~4 (yes, but) &80 & 19-67 (38.0)  & 48/30/2/0 &  \\
  \hline
  \end{tabular}

  \caption{Information about the participants recruited in Exps.~1-4 (f = female, m = male, nb = nonbinary, dnd = did not disclose).}\label{t:recruited}
  \end{table}

  \subsubsection{Materials and procedure}
  
  The four experiments measured the at-issueness of the seven contents in \ref{stims} with a different at-issueness diagnostic, namely the QUD diagnostic (Exp.~1), the `asking whether' diagnostic (Exp.~2), the direct dissent diagnostic (Exp.~3) and the `yes, but' diagnostic (Exp.~4). The examples in \ref{diag} illustrate how each diagnostic was implemented using the content of sentence-medial NRRCs (with the item `Lucy broke the plate'). In Exp.~1 (QUD diagnostic, \ref{diag.a}), participants read a dialogue between two named speakers, where the first utters an interrogative sentence (the presumed QUD) that is about the content to be diagnosed and the second responds with a declarative sentence that contributes the content to be diagnosed. In Exp.~2 (`asking whether' diagnostic, \ref{diag.b}), participants read an interrogative sentence uttered by a named speaker, where the interrogative sentence contributes the content to be diagnosed. In Exp.~3 (`direct dissent' diagnostic, \ref{diag.c}), participants read a dialogue between two named speakers, where the first utters a declarative sentence with the content to be diagnosed and the second directly dissents with the content to be diagnosed. Finally, in Exp.~4 (`yes, but' diagnostic, \ref{diag.d}), participants read a dialogue between two named speakers where the first utters a declarative sentence that contributes the content to be diagnosed and the second responds with one of two indirect dissent variants (\emph{yes, but..}, \emph{yes, and...}) or with a direct dissent.

  \ex.\label{diag} Implementations of the diagnostics in Exps.~1-4
  \a.\label{diag.a} Exp.~1 (QUD diagnostic)
  \\ {\bf Nora:} \emph{What did Lucy break?}
  \\ {\bf Leo:} \emph{Lucy, who broke the plate, apologized.}
  \b.\label{diag.b} Exp.~2 (`asking whether' diagnostic )
  \\ {\bf Nora:} \emph{Did Lucy, who broke the plate, apologize?}
  \c.\label{diag.c} Exp.~3 (`direct dissent' diagnostic)
  \\ {\bf Nora:} \emph{Lucy, who broke the plate, apologized.}
  \\ {\bf Leo:} \emph{No, she didn't break the plate.}
  \d.\label{diag.d} Exp.~4 (`yes, but' diagnostic)
  \\ {\bf Nora:} \emph{Lucy, who broke the plate, apologized.}
  \\ {\bf Nina:} \emph{Yes, but she didn't break the plate.}
  \\ \hspace*{1cm} \emph{Yes, and she didn't break the plate.}
  \\ \hspace*{1cm} \emph{No, she didn't break the plate.}

  As shown in Fig.~\ref{fig:trials}, the response options in each of the four experiments differed depending on the diagnostic. In Exp.~1 (QUD diagnostic, panel (a)), participants were asked how well the response fits the question and they gave their response on a slider marked `totally doesn't fit' on one end (coded 0) and `totally fits' on the other end (coded as 1). In Exp.~2 (`asking whether' diagnostic, panel (b)), participants were asked whether the question is about the content to be diagnosed and they gave their response on a slider marked `no' on one end (coded as 1) and `yes' on the other (coded as 0). In Exp.~3 (direct dissent diagnostic, panel (c)), participants were asked how natural the direct dissent and participants gave their response on a slider marked `totally unnatural' (coded as 0) on one end and `totally natural' on the other (coded as 1). Finally, in Exp.~4 (`yes, but' diagnostic, panel (d)), participants were asked to choose the response that sounded best; the two indirect dissents were coded as 1 and the direct one as 0. Across the four experiments, the responses were coded as 0 or 1 in such a way that 0 meant that the content to be diagnosed was rated as at-issue and 1 meant that the content was rated as not-at-issue.


 \begin{figure}[h!]
  \centering
  % Top row
  \subfigure[Exp.~1: QUD diagnostic]{%
    \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp1}}%
    \label{fig:trialExp1}
  }
  \hfill
  \subfigure[Exp.~2: `asking whether' diagnostic]{%
    \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp2}}%
    \label{fig:trialExp2}
  }

  \vspace{1em}

  % Bottom row
  \subfigure[Exp.~3: `direct dissent' diagnostic]{%
    \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp3}}%
    \label{fig:trialExp3}
  }
  \hfill
  \subfigure[Exp.~4: `yes, but' diagnostic]{%
    \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp4}}%
    \label{fig:trialExp4}
  }

  \caption{Sample trials in (a) Exp.~1, (b) Exp.~2, (c) Exp.~3, and (d) Exp.~4.}
  \label{fig:trials}
  \end{figure}
  
  Each of the seven contents in \ref{stims} was instantiated by one of the seven items shown in \ref{items} in each of the four experiments.
 
 \ex.\label{items}
 \a. Jack saw the murder.
 \b. Raul cheated on his wife.
 \c. Ann stole the money.
 \d. Danny ate the last cupcake.
 \b. Lucy broke the plate.
 \b. Dustin lost his key.
 \b. Greg bought a new car.
 \z.
 
 Each experiment also included two control stimuli, which functioned as attention checks: one stimulus was expected to receive a response at one end of the slider (Exps.~1-3) or a `no' response (Exp.~4); the other control stimulus was expected tor receive a response at the other end of the slider (Exps.~1-3) or a `yes' response (Exp.~4). See Supplement \ref{supp:stims} for the control stimuli used in Exps.~1-4.
 
 In each of the four experiments, each participant's set of items was generated by randomly combining each of the seven contents in \ref{stims} with a unique content in \ref{items}. Participants completed a total of 9 trials, namely 7 target trials and the same 2 control trials. Trial order was randomized.
 
  After completing the experiment, participants filled out a short optional demographic survey. To encourage truthful responses, participants were told that they would be paid no matter what answers they gave in the survey. 

  \subsubsection{Data exclusion}
    
  We excluded the data of participants who did not self-identify as native speakers of
  American English and of participants whose responses to either one of the two control trials was more than 2 sd away from the group mean (Exps.~1-3) or whose responses to either one of the two control trials was wrong (Exp.~4).   Table \ref{t:excluded} shows how many participants were excluded in each experiment, the properties of the remaining participants, and the number of data points that entered into the analyses.

  \begin{table}[h!]
  \centering
  \begin{tabular}{l | r r | r r  | r }
               & \multicolumn{2}{c|}{\bf exclusion criterion} & \multicolumn{2}{c|}{\bf remaining participants} & data \\ 
              & language & fillers & ages (mean age) & f/m/nb/dnd &  points \\ \hline
  Exp.~1 (QUD   & 1 &  10 &  18-81 (41.1) & 36/32/0/1 & 621 \\ 
  Exp.~2 (asking whether) &  2 &  4 & 22-74 (38.7) & 45/27/1/1 & 666 \\ 
  Exp.~3  (direct dissent) &  2 &  7 & 18-77 (39.5) & 44/25/1/1  & 639 \\ 
  Exp.~4  (yes, but) & 4 & 4 & 19-67 (38.5)  & 43/27/2/0 & 648 \\ 
  \hline
  \end{tabular}
  \caption{Information from Exps.~1-4 about the number of participants whose data was excluded based on their self-declared language (variety) and the fillers, about the remaining participants, and about the number of data points that entered into the analysis.}\label{t:excluded}
  \end{table}

  \subsection{Results}
  
  Fig.~\ref{fig:results} plots the results of the four experiments by the expression that is associated with the seven target contents: panel (a) shows the mean naturalness ratings in Exp.~1 (QUD diagnostic), panel (b) the mean `asking whether' ratings in Exp.~2 (`asking whether' diagnostic), panel (c) the mean naturalness ratings in Exp.~3 (`direct dissent' diagnostic) and panel (d) the proportion of `no' choices in Exp.~4 (`yes, but' diagnostic).  We observe that the results of the four experiments differ in the range of the (mean or proportion of) ratings, that is, the difference between the largest and smallest ratings. {\bf JT: redo, now that plots different} The range is largest in Exp.~2 (`asking whether' diagnostic), at .74 (.01 to .83) and smallest in Exp.~3 (`direct dissent' diagnostic), at .13 (.64 to .78). The results of Exp.~1 (QUD diagnostic, with a range of .27 (.51 to .77) and Exp.~4 (`yes, but' diagnostic), with a range of .46 (.5 to .96), fall in-between. This result suggests that the four diagnostics that were implemented in Exps.~1-4 differ in how much they differentiate between the seven contents investigated, with the `asking whether' diagnostic showing the most differentiation and the `direct dissent' and the QUD diagnostic showing the least differentiation.
  
  We also observe that the results of the four experiments differ in the relative ratings that the seven contents received. The only two contents that received consistent relative ratings across all four experiments are the contents of the complement of \emph{discover} and \emph{confess}: The content of the complement of \emph{discover} received higher ratings (at least numerically) across all four experiments than that of \emph{confess}. There is no other pair of expressions for which that is the case. For instance, whereas the content of the complement of \emph{confirm} received (numerically) higher ratings than that of \emph{know} in Exps.~1 and 2, the opposite pattern is observed in Exps.~3 and 4. This difference between the results of the experiments is quantified in the Spearman rank correlations  {\bf JT: redo} in Table \ref{t:spearman}.\footnote{The Spearman rank correlation coefficient, a value between -1 and 1, is a nonparametric measure of rank correlation: the higher the coefficient, the more the relation between the the two variables can be described using a monotonic function. If the coefficient is positive, the value of one variable tends to increase with an increase in the other. In the case of our experiments, a coefficient of 1 for two experiments would mean that there is a perfectly monotone increasing relation between the mean ratings of the seven contents in the two experiments: for any two contents c1 and c2, if c1 ranks below c2 in one experiment (that is, the mean rating of c1 is lower than that of c2), then that ranking is preserved in the other experiment.} The rank correlations are particularly low for for Exp.~1 compared to the other three experiments, which is due at least in part to the fact that the content of the complement of \emph{be right} is the most not-at-issue content of the seven contents in Exp.~1, but among the least not-at-issue in the other three experiments. These results suggests that the four diagnostics as implemented in Exps.~1-4 interact differently with the seven contents investigated.
   
  
   \begin{table}[ht!]
   \centering
   \begin{tabular}{l | c c c c}
   & Exp.~1 & Exp.~2 & Exp.~3 & Exp.~4 \\ \hline
   Exp.~1 (QUD diagnostic) & \cellcolor{lightgray} & .11 & -.29 & -.18 \\
   Exp.~2 (`asking whether' diagnostic) & \cellcolor{lightgray} & \cellcolor{lightgray} & .64 &.79 \\
   Exp.~3 (`direct dissent' diagnostic) & \cellcolor{lightgray}& \cellcolor{lightgray} & \cellcolor{lightgray} & .79  \\
   \hline
  % Exp.~4 (`yes, but' diagnostic) & & & & \cellcolor{lightgray} \\ \hline
   \end{tabular}
   \caption{Spearman rank correlations between the results of Exps.~1-4.}\label{t:spearman}
   \end{table}
  
 
  \begin{figure}[h!]
    \centering

    % Top row
    \subfigure[Exp.~1 (QUD diagnostic)]{%
      \includegraphics[width=0.48\linewidth]{../../results/exp1/graphs/mean-ratings.pdf}%
      \label{fig:qud}
    }
    \hfill
    \subfigure[Exp.~2 (`asking whether' diagnostic)]{%
      \includegraphics[width=0.48\linewidth]{../../results/exp2/graphs/mean-ratings.pdf}%
      \label{fig:AK}
    }

  % \vspace{1em}

    % Bottom row
    \subfigure[Exp.~3 (`direct dissent' diagnostic)]{%
      \includegraphics[width=0.48\textwidth]{../../results/exp3/graphs/mean-ratings.pdf}%
      \label{fig:dd}
    }
    \hfill
    \subfigure[Exp.~4 (`yes, but' diagnostic)]{%
      \includegraphics[width=0.48\textwidth]{../../results/exp4/graphs/mean-ratings.pdf}%
      \label{fig:yb}
    }

    \caption{Results of Exps.~1--4. Panels (a)--(c) show the mean responses by expression for (a) Exp.~1 (QUD diagnostic),  (b) Exp.~2 (`asking whether' diagnostic), and (c) Exp.~3 (`direct dissent' diagnostic); panel (d) shows the proportion of `no' choices by expression in Exp.~4 (`yes, but' diagnostic). Error bars indicate 95\% bootstrapped confidence intervals. Violin plots in panels (a)-(c) show the kernel probability density of individual participants' ratings. Gray dots in panel (d) represent individual participant responses (`no' vs.\ `yes', jittered vertically and horizontally for legibility).}
    \label{fig:results}
  \end{figure}
  
  Finally, the results of the experiments differ with respect to whether distinctions between contents from prior literature are observed. Fig.~\ref{fig:pairwise} presents the results of posthoc pairwise comparisons of the estimated means/proportions for each content using the `emmeans' package (\citealt{emmeans}) in R (\citealt{r}). The input to the pairwise comparisons were mixed-effects beta regression models (Exps.~1-3) or a mixed-effects logistic regression model (Exp.~4) with weakly informative priors that were fit using the `brms' package (\citealt{buerkner2017}). The models predicted the  ratings\footnote{To model the ratings in Exps.~1-3 using a beta regression, the ratings were first transformed from the interval [0,1] to the interval (0,1) using the method proposed in \citealt{smithson-verkuilen2006}.} from a fixed effect of expression (with treatment coding and `be right' as reference level) and included random by-participant and by-item intercepts. The output of the pairwise comparison were 95\% highest density intervals (HDIs) of estimated marginal mean differences between each of the expressions. We assume that two contents differ if their HDI does not include 0.\footnote{The full model outputs are available in the folder {\bf where?} in the repository linked in footnote \ref{f:github}.} 

  Recall that \citealt{syrett_experimental_2015}, using a variant of the direct dissent diagnostic, found that sentence-medial NRRCs are more not-at-issue than sentence-final ones. As shown in Figs.~\ref{fig:results} and \ref{fig:pairwise}, no difference is observed in Exps.~1-3; in Exp.~4 (`yes, but' diagnostic), sentence-final NRRCs are more not-at-issue than sentence-medial ones.  This result suggests that none of the diagnostics as implemented in Exps.~1-4 predict that sentence-medial NRRCs are more not-at-issue than sentence-final ones, contrary to \citeposs{syrett_experimental_2015} result.
  
  Recall also that \citealt{tonhauser_how_2018} and \citealt{degen-tonhauser-glossa}, using the `asking whether' diagnostic, observed that the content of the clausal complement of \emph{know} was more not-at-issue than that of \emph{discover}, which in turn was more not-at-issue than that of \emph{confess}, which in turn was more not-at-issue than that of \emph{confirm}, which in turn was more not-at-issue than that of \emph{be right}.  As shown in Figs.~\ref{fig:results} and \ref{fig:pairwise}, these differences are replicated in Exp.~2 (`asking whether' diagnostic), except for the contents of the complement of \emph{confess} and \emph{discover}. In Exp.~1 (QUD diagnostic), the content of the complement of \emph{confirm} is less not-at-issue than that of \emph{confess} and \emph{know}, but the only other difference that is observed is that the content of the complement of \emph{be right} is less at-issue than those of the other predicates -- the direction of this difference is the opposite from that observed in prior literature and the other experiments. In Exp.~3..., Finally, in Exp.~4, the content of the complement of \emph{be right} is more at-issue than those of \emph{confirm, confess} and \emph{know}, that of \emph{confirm} is more at-issue than that of \emph{confess}, and that of \emph{discover} is more at-issue than that of \emph{confess}. These results suggest that the diagnostics, as implemented in Exps.~1-4, differ in whether they predict differences in at-issueness between the contents of the complements of the five clause-embedding predicates included in the experiments.
   
  %Exp 1
  %min: 0.5055072
  %max: 0.7713043
  %range: 0.2657971

  %Exp 2
  %min: 0.09364865
  %max: 0.8332432
  %range: 0.7395946

  %Exp 3
  %min: 0.6443662
  %max: 0.7752113
  %range: 0.1308451

  %Exp 4
  %min: .5
  %max: 0.958
  %range: 0.458
 
  \addtolength{\tabcolsep}{-.19em}

  \begin{figure}[!h]
  \centering

  \subfigure[Exp.~1 (QUD diagnostic)]{%
  \begin{tabular}{r | ccccccc}
  & \rots{be right} & \rots{confirm} & \rots{discover} & \rots{confess} & \rots{know} & \rots{final NRRC} & \rots{medial NRRC} \\
 \hline
  \input{../../results/exp1/models/table1}
 \hline
  \end{tabular}}
  \hfill
  \subfigure[Exp.~2 (`asking whether' diagnostic)]{%
  \begin{tabular}{r | ccccccc}
  & \rots{be right} & \rots{confirm} & \rots{discover} & \rots{confess} & \rots{know} & \rots{final NRRC} & \rots{medial NRRC} \\
\hline
  \input{../../results/exp2/models/table1}
 \hline
  \end{tabular}}

  \subfigure[Exp.~3 (`direct dissent' diagnostic)]{%
  \begin{tabular}{r | ccccccc}
  & \rots{be right} & \rots{confirm} & \rots{discover} & \rots{confess} & \rots{know} & \rots{final NRRC} & \rots{medial NRRC} \\
\hline
  \input{../../results/exp4/models/table1}
\hline
  \end{tabular}}
\hfill
  \subfigure[Exp.~4 (`yes, but' diagnostic)]{%
  \begin{tabular}{r | ccccccc}
  & \rots{be right} & \rots{confirm} & \rots{discover} & \rots{confess} & \rots{know} & \rots{final NRRC} & \rots{medial NRRC} \\
\hline
  \input{../../results/exp4/models/table1}
\hline
  \end{tabular}}

  \caption{Pairwise differences between expressions, ordered from top to bottom and left to right by increasing mean in Exp.~2 (`asking whether' diagnostic). A white cell means that the 95\% HDI of the pair of the row expression and the column expression includes 0, a red cell means that the 95\% HDI does not include 0 and that the coefficient is positive (the row expression received a higher rating than the column expression), and a blue cell means that the 95\% HDI does not include 0 and the coefficient is negative (the row expression received a lower rating than the column expression).}\label{fig:pairwise}
  \end{figure}

  \newpage

  bla

  \newpage

  \subsection{Discussion}

  Exps.~1-4 were designed to compared the results of four different diagnostics of at-issueness that have been used in prior literature. The results of the experiments suggest that the diagnostics, in the particular way in which they were implemented in the experiments, differ on several dimensions. First, they differ in the extent to which they differentiate between the seven contents investigated, with the `asking whether' diagnostic of Exp.~2 showing the most differentiation and the `direct dissent' diagnostic of Exp.~3 showing the least. Second, the diagnostics as implemented differ in the way in which they interact with the seven contents. In particular, while the results of none of the experiments differentiated between sentence-medial and -final NRRCs, the results of Exp.~2 (`asking whether' diagnostic) distinguished between most of the contents of the complements of the five clause-embedding predicates, whereas the results of Exp.~xx (`' diagnostic) distinguished between the least of these contents.

  One of the most striking differences between the results of the experiments concerns the content of the complement of \emph{be right} in Exp.~1 (QUD diagnostic) vs.\ the other three experiments. As shown in panel (a) of Fig.~\ref{fig:results}, participants gave relatively high naturalness ratings to responses like that in \ref{beright.a}, suggesting that they did not take the response to fit the question. As discussed above, the content of the complement of \emph{be right} emerged as the most not-at-issue in Exp.~1. 

  \ex.
  \a.\label{beright.a}  Exp.~1 (QUD diagnostic) with \emph{be right}
  \\ {\bf Nora:} \emph{What did Lucy break?}
  \\ {\bf Leo:} \emph{XX is right that Lucy broke the plate.}
  \b.\label{beright.b} Exp.~2 (`asking whether' diagnostic )
  \\ {\bf Nora:} \emph{Is xx right that Lucy broke the plate?}
  \c.\label{beright.c} Exp.~3 (`direct dissent' diagnostic)
  \\ {\bf Nora:} \emph{xx is right that Lucy broke the plate.}
  \\ {\bf Leo:} \emph{No, she didn't break the plate.}
  \d.\label{beright.d} Exp.~4 (`yes, but' diagnostic)
  \\ {\bf Nora:} \emph{xx is right that Lucy broke the plate.}
  \\ {\bf Nina:} \emph{Yes, but she didn't break the plate.}
  \\ \hspace*{1cm} \emph{Yes, and she didn't break the plate.}
  \\ \hspace*{1cm} \emph{No, she didn't break the plate.}


  Why might this be? We hypothesize that this is because \emph{be right} signals that the question of whether Lucy broke the place must be salient in discourse. But no such discourse context is given and it is difficult to accommodate, so low naturalness ratings. This doesn't happen in the other diagnostics, shown in \ref{beright.b} to \ref{beright.d}.\footnote{When \emph{be right} is excluded, the Spearman rank correlations are:
    
   \begin{tabular}{l | c c c c}
   & Exp.~1 & Exp.~2 & Exp.~3 & Exp.~4 \\ \hline
   Exp.~1 (QUD diagnostic) & \cellcolor{lightgray} & .77 & .09 & .31 \\
   Exp.~2 (`asking whether' diagnostic) & \cellcolor{lightgray} & \cellcolor{lightgray} & .66 & .66 \\
   Exp.~3 (`direct dissent' diagnostic) & \cellcolor{lightgray}& \cellcolor{lightgray} & \cellcolor{lightgray} & .77  \\
   \hline
  % Exp.~4 (`yes, but' diagnostic) & & & & \cellcolor{lightgray} \\ \hline
   \end{tabular}} So, when using a particular diagnostic, one also has to worry about whether the expression might presuppose a particular context, if one wants to ask about how well an utterance fits the context.
   
   As mentioned above, none of our experiments replicated the effect reported in \citealt{syrett_experimental_2015}, that sentence-final NRRCs are more at-issue than sentence-medial ones. This includes Exp.~3, which implemented a variant of the `direct dissent' diagnostic that was used in \citealt{syrett_experimental_2015}. A difference between our Exp.~3 and Exp.~2 in \citealt{syrett_experimental_2015}, aside from the stimuli, is that we asked for naturalness ratings and they implemented it as a forced choice: do you choose to dissent with the main clause content or the content of the NRRC. An interesting follow-up would be to see whether our stimuli with the forced choice can reproduce their result.
   
   One of the most noticable differences between the results of the experiments is that Exp.~2 has much larger range and differentiation among the contents. Why might this be? It is the only diagnostic where the expression/content occurs in a polar question. We hypothesize that the polar question embedding highlights at-issueness differences. Content is differently suitable to partition the context set, with some content really well able to do this and other content not, and other content inbetween. All the other diagnostics rely on anaphoric accessibility of the proposition or how well it can address a question in prior discourse. 
   
   To investigate whether it is really embedding polar question that creates this differentiation, it would be good to investigate a diagnostic that also embeds the expression/content in a polar question but uses a different assumption about at-issueness. This is what we do in the next section.
        
\section{Experiments 5-6 \label{sec:3_more-experiments}}

  Exp.~5 is just like Exp.~2 except that we investigate the contents of the complements of the 20 clause-embedding predicates investigated in \citealt{tonhauser_how_2018} and \citealt{degen-tonhauser-glossa}. Exp.~6 also investigates these contents, but uses a  `direct assent' diagnostic in Exp.~3. As shown in \ref{exp6}, the expression/content occurs in a polar question and the response directly dissents with the content. 

  \ex.
  \a.\label{exp5} Exp.~5 (`asking whether' diagnostic )
  \\ {\bf Nora:} \emph{Is xx right that Lucy broke the plate?}
  \\ Question to participants: Is Nora asking whether Lucy broke the plate?
  \b.\label{exp6} Exp.~6 (`direct dissent' diagnostic)
  \\ {\bf Nora:} \emph{Is XX right that Lucy broke the plate?}
  \\ {\bf Leo:} \emph{Yes, she didn't break the plate.}
  \\ Question to participants: How natural is Leo's response to Nora's question?

  Both experiments were run a while back already. They also included a projection block (data reported in \citealt{hofmann-etal2024}). The results of the at-issueness block have not yet been reported.

  \subsection{Methods}

  \subsubsection{Participants}

  For both experiments, we recruited unique 80 participants on Prolific. These participants had registered on the platform as living in the USA and as having English as their primary language. They had at least 50 previous submissions and an approval rate of at least 97\%.  Table \ref{t:recruited} shows the age and gender distributions of the recruited participants.

    \begin{table}[h!]
    \centering
    \begin{tabular}{l | c | r r r }
                & recruited & ages (mean age) & f/m/nb/dnd \\ \hline
    Exp.~1 (QUD) & 80 & 18-81 (43.8) & 42/37/0/1  \\
    Exp.~2 (asking whether) & 80 & 20-74 (38.5)  & 48/30/1/1  \\
    Exp.~3 (direct dissent) & 80 & 18-77 (39.1) & 50/28/1/1  \\
    Exp.~4 (yes, but) &80 & 19-67 (38.0)  & 48/30/2/0 &  \\
    \hline
    \end{tabular}

    \caption{Information about the participants recruited in Exps.~1-4 (f = female, m = male, nb = nonbinary, dnd = did not disclose).}\label{t:recruited}
    \end{table}

  \subsubsection{Materials and procedure}

  \subsubsection{Data exclusion}

  \subsection{Results}

  \subsection{Discussion}

\section{General discussion \label{sec:4_discussion}}



\section{Conclusion \label{sec:5_conclusion}}

The conclusion is the last numbered section, and any ensuing sections are unnumbered.

\pagebreak
\section*{Abbreviations (if applicable)}\label{abbrev}

\textsc{acc} = accusative, \textsc{dat} = dative, \textsc{dem} = demonstrative, \textsc{nom} = nominative, \textsc{pl} = plural, \textsc{sg} = singular

For the standard abbreviations to be used here, refer to the \href{https://www.eva.mpg.de/lingua/resources/glossing-rules.php}{Leipzig glossing rules}.

\section*{Data availability/Supplementary files (if applicable)}

The journal encourages authors to make all data associated with their submission openly available, according to the FAIR principles (Findable, Accessible, Interoperable, Reusable). More information can be found \href{https://www.glossa-journal.org/site/editorial-policies/#data-policy}{here}.

If data/supplementary files are to be associated with the accepted paper, one of the options below should be followed:
\begin{enumerate}
\item upload the files to your chosen open repository and make note of the DOI that they will provide (most suitable for datasets or information that act as foundations to the research being published. This option makes the files more findable and more citable). We recommend an open repository such as osf.io, which allows you to create a "project" under which you can upload relevant files (datasets, analysis scripts, experimental materials, etc.). The project will be associated with a unique DOI. You can then include in your manuscript a citation of the OSF entry and/or a link to the project page on OSF, to direct interested readers to the supplementary materials. During review, please be sure that the link to the repository is anonymized to maintain a fully double masked review process. Instructions for doing this on the OSF may be found \href{https://help.osf.io/hc/en-us/articles/360019930333-Create-a-View-only-Link-for-a-Project}{here}. If you'd like to learn more about best practices for ensuring reproducibility, see \href{https://psyarxiv.com/hf297/}{Laurinavichyute and Vasishth (2021)}. Please contact us if you would like more information or advice about hosting your data on an open repository.
\item upload the files to the journal system during the submission process, as `data files'. The journal will then host them as part of the publication and provide them with a DOI (most suitable for non-data files or very short pieces of information, although option 1 is also suitable for these if the author prefers).
\end{enumerate}

\noindent In both cases, a `Data availability' or `Supplementary files' section must be added prior to the reference list that provides a title and very short summary of the files for each file. If option 1 was selected, you should also provide the DOI in this section. For example:

\noindent Supplementary file 1: Appendix. Scientific data related to the experiments. DOI: \doi{10.5334/gjgl.310.s1}

Ideally, supplementary files are also cited in the main text.

Please note that neither of the above two options will result in the files being typeset, so please ensure that they are in publishable format when you upload the accepted paper.


\section*{Ethics and consent (if applicable)}

Research involving human subjects, human material, or human data, must have been performed in accordance with the Declaration of Helsinki. Studies must have been approved by an appropriate ethics committee and the authors should include a statement in the article text detailing this approval, including the name of the ethics committee and reference number of the approval, or mention any exemptions to ethical approval that apply to their research. The identity of research subjects should be anonymised whenever possible. For research involving human subjects, informed consent to participate in the study must be obtained from participants (or their legal guardian).


\section*{Funding information (if applicable)}

Should the research have received a funding grant then the grant provider and grant number should be detailed.

\section*{Acknowledgements (optional)}

The authors wish to thank Martin Haspelmath for providing the generic style sheet for linguistics, and Kai von Fintel for giving permission to use and modify the \textit{Semantics \& Pragmatics} Latex template, bibliography style, and document class.

\section*{Competing interests (required)}

If any of the authors have any competing interests then these must be declared. Guidelines for competing interests can be found \href{https://www.glossa-journal.org/site/competing-interests/}{here}. If there are no competing interests to declare then the following statement should be present: `The author(s) has/have no competing interests to declare'.

\section*{Authors' contributions (optional)}\label{contrib}

A sentence or a short paragraph detailing the roles that each author held to contribute to the authorship of the submission.  Individuals listed must fit within the definition of an author, as per our \href{https://www.glossa-journal.org/site/author-guidelines/}{Author Guidelines}.

\nocite{*} %this is to get all the entries of the sample bibliography; delete this line for an actual Glossa submission

%\printbibliography %for use with biblatex; comment out if you use natbib
\bibliography{../at-issueness} %for use with natbib; comment out if you use biblatex, and change 'sample' by the name of your bib-file


\appendix

\setcounter{table}{0}
\renewcommand{\thetable}{A\arabic{table}}

\setcounter{figure}{0}
\renewcommand{\thefigure}{A\arabic{figure}}

\setcounter{ExNo}{0}


\section*{Supplements}

\section{Control stimuli in Exps.~1-4}\label{supp:stims}

The examples in \ref{control1}-\ref{control4} provide the two control stimuli used in each of Exps.~1-4. For the a.-examples, participants were expected to give a `totally fits' response (Exp.~1), a `yes' response (Exp.~2), a `totally natural' response (Exp.~3), and a `no' response (Exp.~4); for the b.-examples, the opposite response was expected. The numbers  after each example identify the mean ratings (Exps.~1-3) or the proportion of `no' responses (Exp.~4) after excluding participants who did not self-identify as native speakers of American English (but before excluding participants on the basis of these controls), showing that the control stimuli worked as intended.

\ex.\label{control1} Control stimuli in Exp.~1 (QUD diagnostic)
\a. Mary: Which course did Ava take?
\\ John: She took the French course. (.97)
\b. Jennifer: What does Betsy have?
\\ Robert: She loves dancing salsa. (.07)

\ex.\label{control2} Control stimuli in Exp.~2 (`asking whether' diagnostic)
\a. Mary: Did Arthur take a French course?
\\ Question to participants: Is Mary asking whether Arthur took a French course? (.96)
\b. Robert: Does Betsy have a cat?
\\ Question to participants: Is Robert asking whether Betsy loves apples? (.02)

\ex.\label{control3} Control stimuli in Exp.~3 (`direct dissent' diagnostic)
\a. Mary: Arthur took a French course.
\\ Lily: No, he took a Spanish course. (.87)
\b. Robert: Betsy has a cat.
\\ Maximilian: No, she doesn't like apples. (.05)

\ex.\label{control4} Control stimuli in Exp.~4 (`yes, but' diagnostic)
\a. Mary: Arthur took a French course.
\\ Lily: Yes, but Lisa loves cats. / Yes, and he didn't take a French course. / No, he didn't take a French course. (.95)
\b. Robert: Betsy has a cat.
\\ Maximilian: Yes, but she is good at math. / Yes, and she loves it so much. / No, she doesn't like apples. (0)

\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% TeX-engine: luatex
%%% End:
