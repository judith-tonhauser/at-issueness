% !TEX program = lualatex
% glossa-template.tex
% Copyright 2016 Guido Vanden Wyngaerd
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
% 
% The Current Maintainer of this work is 
% Guido Vanden Wyngaerd (guido.vandenwyngaerd@kuleuven.be).
%
% This work consists of the files 
% glossa.cls
% glossa.bst
% gl-authoryear-comp.cbx
% biblatex-gl.bbx
% glossa-template.tex
% glossa.png
%
% The files of the work are derived from the Semantics & Pragmatics style files
% by Kai von Fintel, Christopher Potts, and Chung-chieh Shan
% All changes are documented on the github repository 
% https://github.com/guidovw/Glossalatex.

\PassOptionsToPackage{table}{xcolor}
\PassOptionsToPackage{xcolor}{dvipsnames}
\documentclass[times,linguex]{glossa}
\usepackage{rotating}
\usepackage{tablefootnote}
\usepackage{colortbl}
\usepackage{color}
\usepackage{multicol}
\usepackage{booktabs}

\usepackage{adjustbox}
\usepackage{array}

\newcolumntype{R}[2]{%
>{\adjustbox{angle=#1,lap=\width-(#2)}\bgroup}%
l%
<{\egroup}%
}

\newcommand*\rots{\multicolumn{1}{R{90}{.7em}}}% no optional argument here, please!
%\usepackage{xcolor}

% possible options:
% [times] for Times font (default if no option is chosen)
% [cm] for Computer Modern font
% [lucida] for Lucida font (not freely available)
% [brill] open type font, freely downloadable for non-commercial use from http://www.brill.com/about/brill-fonts; requires xetex
% [charis] for CharisSIL font, freely downloadable from http://software.sil.org/charis/
% for the Brill an CharisSIL fonts, you have to use the XeLatex typesetting engine (not pdfLatex)
% for headings, tables, captions, etc., Fira Sans is used: https://www.fontsquirrel.com/fonts/fira-sans
% [biblatex] for using biblatex (the default is natbib, do not load the natbib package in this file, it is loaded automatically via the document class glossa.cls)
% [linguex] loads the linguex example package
% !! a note on the use of linguex: in glossed examples, the third line of the example (the translation) needs to be prefixed with \glt. This is to allow a first line with the name of the language and the source of the example. See example (2) in the text for an illustration.
% !! a note on the use of bibtex: for PhD dissertations to typeset correctly in the references list, the Address field needs to contain the city (for US cities in the format "Santa Cruz, CA")

%\addbibresource{sample.bib}
% the above line is for use with biblatex
% replace this by the name of your bib-file (extension .bib is required)
% comment out if you use natbib/bibtex

\let\B\relax %to resolve a conflict in the definition of these commands between xyling and xunicode (the latter called by fontspec, called by charis)
\let\T\relax
\usepackage{xyling} %for trees; the use of xyling with the CharisSIL font produces poor results in the branches. This problem does not arise with the packages qtree or forest.
%\usepackage[linguistics]{forest} %for nice trees!




% \pdf* commands provide metadata for the PDF output. ASCII characters only!
\pdfauthor{}
\pdftitle{What is at-issueness?}
\pdfkeywords{}

\title[What is at-issueness?]{What is at-issueness? An experimental comparison of diagnostics\\ 
\bigskip \large
Word count (including references, excluding abstract and supplements): 11,924
}
% Optional short title inside square brackets, for the running headers.

\author[]% short form of the author names for the running header. If no short author is given, no authors print in the headers.
{%as many authors as you like, each separated by \AND.
% \spauthor{Waltraud Paul\\
% \institute{CRLAO, CNRS-EHESS-INALCO}\\
% \small{%105, Bd. Raspail, 75005 Paris\\
% waltraud.paul@ehess.fr}
% }
% \AND
% \spauthor{Guido Vanden Wyngaerd \\
% \institute{KU Leuven}\\
% \small{%Warmoesberg 26, 1000 Brussel\\
% guido.vandenwyngaerd@kuleuven.be}
% }%
}

\input{author-added}

% positive coefficients/difference
\definecolor{red}{RGB}{178,24,43}

% negative coefficients/difference
\definecolor{blue}{RGB}{33,102,172}

% comments by JT
\newcommand{\jt}[1]{%TC:ignore
\textbf{\color{blue}JT: #1}%TC:endignore
}
\newcommand{\lh}[1]{%TC:ignore
\textbf{\color{orange}LH: #1}%TC:endignore
}

\begin{document}

\maketitle
%TC:ignore
\begin{abstract}
  At-issueness is a central concept in theoretical semantics and pragmatics, but there is no consensus about how it should be defined or diagnosed (e.g., \citealt{tonhauser_diagnosing_2012,anderbois_at-issue_2015,snider_at-issueness_2017,snider_anaphoric_2017,snider_distinguishing_2018,tonhauser_how_2018,koev_notions_2018,faller_discourse_2019,korotkova_evidential_2020}). We report the results of six experiments that investigate whether five diagnostics for at-issueness yield consistent results when applied to the same set of contents in English. Diagnostics are compared based on whether they reproduce contrasts reported in prior work, in particular (i) positional effects for appositive NRRCs found in \citet{syrett_experimental_2015} and (ii) fine-grained differences among the complements of clause-embedding predicates reported in \citet{degen_projection_2025}.
  %
  The results reveal substantial differences between diagnostics, indicating that they are not interchangeable. None of our experiments observed the positional effect for NRRCs (i), and only the diagnostics that embed the tested contents in polar questions come close to observing the predicate-level differences (ii). Our generalization, that diagnostics measuring the at-issueness of contents embedded in questions yield greater by-content differentiation than diagnostics embedding them in assertions, indicates that the speech act in which a content is presented plays a key role in affecting diagnostic outcomes. We argue that this effect of speech act on at-issueness ratings is due to how questions and assertions relate at-issue and not-at-issue content to speaker commitments, and cannot be explained by different notions of at-issueness assumed in the literature.
\end{abstract}
\begin{keywords}
  at-issueness, diagnostics, experimental pragmatics
\end{keywords}
%TC:endignore

\section{Introduction} \label{sec:1_introduction}
\textit{At-issueness} is a key concept in theoretical semantics and pragmatics,\footnote{\citet{potts_presupposition_2015} credits the term to Bill Ladusaw, \enquote{who began using it informally in his UCSC undergraduate classes in 1985} (p. 2).} used in the analysis of various phenomena, including presupposition, conventional implicature, evidentials, expressives, and co-speech gestures (e.g., \citealt{karttunen_conventional_1979,horton_presuppositions_1988,abbott_presuppositions_2000,faller_semantics_2002,faller_discourse_2019,potts_logic_2005,simons_what_2010,lee_evidentiality_2011,tonhauser_how_2018,esipova_composition_2019,korotkova_evidential_2020,barnes_information_2023,chen_presuppositions_2024,scontras_projection_2025}). It is generally understood as distinguishing the main point of an utterance (at-issue content) from propositions conveying background information (not-at-issue content), but there is no consensus how at-issueness should be diagnosed, and competing definitions reflect different assumptions about its underlying nature (e.g., \citealt{tonhauser_diagnosing_2012,snider_at-issueness_2017,snider_anaphoric_2017,snider_distinguishing_2018,tonhauser_how_2018,koev_notions_2018,faller_discourse_2019,esipova_composition_2019,korotkova_evidential_2020}). Consequently, empirical claims about whether a given expression contributes at-issue or not-at-issue content may be relative to specific diagnostics, and different diagnostics may not target the same underlying phenomenon.

% \subsection{Diagnosing at-issueness}
Four commonly used at-issueness diagnostics are illustrated in (\pref{qud}--\pref{yesbut}) for sentence-medial appositive non-restrictive relative clauses (NRRCs), which are typically taken to contribute not-at-issue content (\citealt{potts_logic_2005}). Accordingly, participants are expected to: give low question-answer-match ratings under the QUD diagnostic \ref{qud} (\citealt{amaral_review_2007,lee_evidentiality_2011,tonhauser_diagnosing_2012,chen_presuppositions_2024}); judge that the speaker is not asking about the  NRRC content under the `asking-whether' diagnostic \ref{aw} (\citealt{tonhauser_how_2018,solstad_cataphoric_2024,degen_projection_2025}); give low naturalness ratings under the direct-dissent diagnostic \ref{dd}, (\citealt{faller_semantics_2002,faller_evidentiality_2006,papafragou_epistemic_2006,amaral_review_2007,murray_evidentiality_2010,murray_varieties_2014,anderbois_crossing_2010,anderbois_at-issue_2015,tonhauser_diagnosing_2012,syrett_experimental_2015}); and prefer a \emph{yes}-response when denying the NRRC content under the `yes, but' diagnostic \ref{yesbut},  (\citealt{xue_correlation_2011,cummins_backgrounding_2013,destruel_cross-linguistic_2015}).

\ex. \label{qud}%
QUD diagnostic%
\a.[{\bf Nora: }] \emph{What did Greg buy?}
\b.[{\bf Leo: }] \emph{Greg, who bought a new car, is envied by his neighbor.}
\z.
Question to participants: How well does Leo's response fit Nora's question?\smallskip
\z.

\ex. \label{aw}%
`asking whether' diagnostic
\a.[{\bf Nora: }] \emph{Is Greg, who bought a new car, envied by his neighbor?}\z.
Question to participants: Is Nora asking whether Greg bought a new car?\smallskip
\z.

\begin{samepage}
  \ex. \label{dd} Direct-dissent diagnostic%
  \a.[{\bf Nora: }] \emph{Greg, who bought a new car, is envied by his neighbor.}
  \b.[{\bf Leo: }] \emph{No, that's not true, he didn't buy a new car.}
  \z.
  Question to participants: How natural is Leo's rejection of Nora's utterance?\smallskip
  \z.
\end{samepage}

\ex. \label{yesbut}%
`yes, but' diagnostic %
\a.[{\bf Nora: }] \emph{Greg, who bought a new car, is envied by his neighbor.}
\b.[{\bf Leo: }] \emph{Yes, but he didn't buy a new car.} /
\b.[] \hspace*{0em} \emph{Yes, and he didn't buy a new car.} /
\b.[] \hspace*{0em} \emph{No, he didn't buy a new car.}
\z.
Task for participants: Choose the response that sounds best.
\z.

The assumptions underlying these diagnostics can be organized around three properties of at-issue content identified in \citet{tonhauser_diagnosing_2012} as motivating diagnostic strategies:

\begin{enumerate}
  \item[(i)] at-issue content addresses the question under discussion (see also \citealt{amaral_review_2007,simons_what_2010}),
  \item[(ii)] the at-issue content of questions determines the relevant set of alternatives, and
  \item[(iii)] at-issue content can be directly assented or dissented with (see also \citealt{shanon_two_1976,groenendijk_studies_1984,faller_semantics_2002,faller_evidentiality_2006,murray_evidentiality_2010}).
\end{enumerate}

\noindent The QUD diagnostic \ref{qud} 
% (\citealt{lee_evidentiality_2011,tonhauser_diagnosing_2012,chen_presuppositions_2024})
targets property (i), assuming that discourse is structured around addressing a \textit{Question Under Discussion} (QUD) (\citealt{roberts_information_2012,ginzburg_interrogatives_1996}) and that at-issue content is the part of an utterance intended to address that question (\citealt{amaral_review_2007,simons_what_2010}). Assuming that only at-issue content can felicitously address an established QUD, the diagnostic presents the target content in a response to a question that makes it relevant. Question-answer match ratings are expected to be high when the content can be construed as at-issue and low otherwise.

The `asking whether' diagnostic \ref{aw}
% (e.g., \citealt{tonhauser_how_2018,solstad_cataphoric_2024,degen_projection_2025})
targets property (ii), testing whether the target content is interpreted as determining the question alternatives. Participants judge whether a speaker, who asks a polar question containing the target content, is asking whether that content is true. Such `asking whether' judgments are expected to be high when the target content is at-issue and low otherwise.

The direct-dissent diagnostic \ref{dd}
% (e.g., \citealt{faller_semantics_2002,faller_evidentiality_2006,papafragou_epistemic_2006,amaral_review_2007,murray_evidentiality_2010,murray_varieties_2014,anderbois_crossing_2010,anderbois_at-issue_2015,tonhauser_diagnosing_2012,syrett_experimental_2015})
and the `yes, but' diagnostic \ref{yesbut}
%(\citealt{xue_correlation_2011,cummins_backgrounding_2013,destruel_cross-linguistic_2015}) target property (iii)
target property (iii), assuming that only at-issue content can be directly affirmed or denied, whereas denying not-at-issue content requires more indirect discourse moves (\citealt{shanon_two_1976,faller_semantics_2002,faller_evidentiality_2006,potts_logic_2005,papafragou_epistemic_2006,amaral_review_2007}). Accordingly, the direct-dissent diagnostic assumes that directly dissenting with the target content is judged natural if the content is at-issue and unnatural otherwise. The `yes, but' diagnostic tests whether a target content can be denied while responding \emph{yes} to the assertion as a whole,
% . Originally developed to diagnose pragmatic inferences that are not semantic entailments (\citealt{onea_hungarian_2009}), it has been adopted as an at-issueness diagnostic
under the assumption that \emph{yes, but} responses provide an indirect denial suitable for dissenting with not-at-issue content (\citealt{xue_correlation_2011}).

% \subsection{Notions of at-issueness}
Although these diagnostics are widely used, there is no consensus on whether the properties they target correspond to a single underlying notion of at-issueness. \citet{tonhauser_diagnosing_2012} argues that diagnostics targeting properties (i)--(iii) can be understood as probing a common underlying notion of at-issueness, adopting the QUD-based definition in \Next.

\ex. \label{def:qai}%
QUD at-issueness: \hfill (based on \citealt{simons_what_2010}, p. 323)\\
A content $m$ is at-issue in a context $c$ iff
\a. \label{def:qai-relevant}%
$m$ is relevant\footnotemark\ to the QUD in $c$, and
\b.  \label{def:qai-conventional}%
% $m$ is appropriately conventionally marked relative to the QUD.
the speaker has a recognizable intention to address the QUD via $m$.
\z. 
\z.

\footnotetext{$m$ may be a proposition or a question denotation, and relevance to the QUD can be defined in terms of contextual entailment of a partial or complete answer (\citealt{roberts_information_2012,simons_what_2010}), or based on inferences about the probability of QUD-answers (\citealt{buring_d-trees_2003,beaver_sense_2008}).
% \ex. Relevance to the QUD in context $c$ \hfill (based on \citealt{simons_what_2010}, p. 316)
% \a. A proposition $p$ is relevant the QUD, iff it contextually entails in $c$ a partial or complete answer to the QUD.
% \b. A question $q$ is relevant to the QUD, iff it has an answer that is relevant to the QUD.
% \z. \z.
}

\noindent While this definition aligns naturally with property (i), it is less clear whether all diagnostics, in particular those targeting property (iii), track this QUD-based notion. Evidence for empirical differences between diagnostics comes from appositive NRRCs: although they are widely taken to contribute not-at-issue content, a forced-choice continuation study by \citet{syrett_experimental_2015} found that sentence-final appositive NRRCs pattern as more at-issue than medial ones, under a version of the direct-dissent diagnostic, which targets property (iii). \citet{snider_anaphoric_2017} argues that diagnostic targeting property (iii) are sensitive to this medial-final distinction, but diagnostics targeting properties (i) or (ii) are not. Similar diagnostic differences have been reported for sentence-final slifting parentheticals (\citealt{koev_notions_2018}) and evidential inferences (\citealt{korotkova_evidential_2020}).

These contrasts have motivated arguments that at-issueness is not a uniform notion (\citealt{koev_notions_2018}), but that property (iii) diagnostics are linked to an assertion-based notion of at-issueness, grounded in analyzing assertions as proposals to update the common ground  (\citealt{stalnaker_assertion_1978,clark_contributing_1989,ginzburg_resolving_1995,farkas_reacting_2010}). On this view, the at-issue content of an assertion is the proposition proposed to be added to the common ground, whereas not-at-issue content is presupposed (already entailed in the common ground; \citealt{stalnaker_presuppositions_1973,stalnaker_common_2002}), or added without being proposed (\citealt{murray_evidentiality_2010,murray_varieties_2014,anderbois_crossing_2010,anderbois_at-issue_2015}). This notion is defined as follows:\footnote{Further definitions of at-issueness proposed in the literature include analyses in terms of restrictive vs.\ non-restrictive modification (\citealt{esipova_composition_2019,esipova_not-at-issueness_2021}), and  coherence-based discourse structure (\citealt{hunter_shapes_2016,jasinskaja_not_2016}). Clarifying the theoretical relations among the various definitions of at-issueness proposed in the literature remains an important question for future research.}

\ex. \label{def:pai}%
Proposal at-issueness: \hfill (\citealt{koev_apposition_2013}, pp. 50--51)\\
A proposition $p$ is at-issue in a context $c$ iff
\a. $p$ is a proposal in $c$ and
\b. $p$ has not been accepted or rejected in $c$.
\z.
\z.

Although empirical differences between at-issueness diagnostics have been reported across a range of constructions, they have not, to date, been evaluated in a systematic experimental comparison that applies multiple diagnostics to the same contents.
%
At the same time, the diagnostic differences that have been reported can be alternatively interpreted in ways that do not require positing multiple underlying notions of at-issueness. One line of work (\citealt{snider_anaphoric_2017,snider_at-issueness_2017,snider_distinguishing_2018,korotkova_evidential_2020}) argues that diagnostics targeting properties (i) and (ii) genuinely diagnose QUD at-issueness,\footnote{Property (ii) can be seen as a forward-looking counterpart of property (i) (\citealt{snider_anaphoric_2017}): while property (i) concerns addressing an established QUD, property (ii) concerns determining the alternatives a question introduces. Under standard assumptions that explicit questions introduce or update the QUD (\citealt{roberts_information_2012,ginzburg_interrogatives_1996}), property (ii) aligns with the QUD-based definition, but it is incompatible with the proposal-based definition, which applies only to assertions.
} whereas diagnostics targeting property (iii) do not diagnose at-issueness at all, but instead track the availability of the target content for propositional anaphora, such as response particles (\emph{yes/no}) or propositional pro-forms (e.g., \emph{that} in \emph{that's not true}).

Further, theoretical proposals argue that QUD-based and proposal-based definitions are not genuinely distinct, but offer different analytical perspectives on the same underlying phenomenon: \citet{anderbois_at-issue_2015}, building on \citet{farkas_reacting_2010}, argue that proposing content for the common ground is intrinsically linked to managing the QUD, and \citet{faller_discourse_2019} analyzes assent and dissent as discourse moves that address the QUD.
% \footnote{Faller's work on evidentials (\citealt{faller_semantics_2002,faller_evidentiality_2006,faller_discourse_2019}) highlights that the reported content can be at-issue while crucially lacking speaker commitment, thus not being asserted. While Faller takes this as an argument for (unified) a QUD-based rather than assertion-based definition of at-issueness, her analysis does assume at-issue proposals that need not be asserted (c.f. phenomena that gave rise to analysis involving weakened and modified commitment in malamud...?).}
%
From this perspective, diagnostic divergence cannot be taken as direct evidence for multiple notions of at-issueness, but instead motivates careful analysis of how specific properties of diagnostics (e.g., whether they include propositional anaphora) may lead to diverging behavior  independently of any differences in at-issueness.

In sum, there is currently no agreed-upon definition of at-issueness, and existing diagnostics may or may not be probing the same underlying phenomenon. This raises two central questions: whether reported empirical differences between diagnostics can be confirmed experimentally, and whether competing definitions of at-issueness target the same underlying phenomenon. This paper takes a first step toward addressing these issues through a systematic experimental comparison of diagnostics designed to address the following research question:

\begin{itemize}
  \item Do the various diagnostics yield consistent results when applied to the same contents?
\end{itemize}

\noindent Initial experimental research on these questions has yielded mixed answers. First, as noted above, \citet{syrett_experimental_2015} report a positional effect for appositive NRRCs under a direct-dissent diagnostic. Because this medial-final distinction has been argued to be specific to assent and dissent-based (property iii) diagnostics, a key question is whether the same contrast emerges under other diagnostics when applied to identical materials.

Beyond appositives, \citealt{tonhauser_how_2018} compared two at-issueness diagnostics across a range of English expressions, including sentence-medial appositives and the complements of the clause-embedding predicates \emph{discover, know,} and \emph{annoyed} (p.~526ff). They found that the question-based `asking whether' diagnostic yielded lower ratings and smaller differentiation between contents than the second at-issueness diagnostic they used, the `are you sure?' diagnostic.\footnote{
The `are you sure?' diagnostic presents participants with dialogues like \Next (\citealt{tonhauser_how_2018}, p.~519) and collects ratings about whether Fred answered Carla's question (see also the `really' test of \citealt{shanon_two_1976}). This diagnostic cannot clearly be aligned with the three properties of at-issue content. 

\ex. Fred: Martha's new car, a BMW, was expensive.\\
Carla: Are you sure?\\
Fred: Yes, I am sure that Martha's new car is a BMW.
\z.

} Despite these differences, ratings from the two diagnostics were correlated, suggesting that they may nonetheless be sensitive to a shared underlying phenomenon. The possibility that diagnostics may differ in how strongly they differentiate among contents raises another key question: whether different diagnostics systematically reproduce fine-grained by-content differences.

Building on these observations, we compare at-issueness diagnostics by asking whether they reproduce by-content differences reported in the literature. In addition to appositive NRRCs, we examine the complements of clause-embedding predicates, for which \citet{degen_projection_2025} report  fine-grained differences under the `asking whether' diagnostic. \Cref{fig:dtglossa} shows the mean `asking whether' ratings for the 20 English predicates used in their study. 
\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{../../results+analysis/degen-tonhauser-glossa/graphs/mean-asking-whether-ratings.pdf}
  
  \caption{Mean `asking whether' ratings for the contents of the clausal complements of 20 clause-embedding predicates, from \citealt{degen_projection_2025}. Error bars indicate 95\% bootstrapped confidence intervals. Violin plots indicate the distribution of individual ratings.
  }
  \label{fig:dtglossa}
\end{figure}

This paper addresses the research question, whether the diagnostics yield consistent results when applied to the same target contents, through a systematic comparison of at-issueness diagnostics across six experiments. Our study compares the diagnostics by examining whether they reproduce contrasts between contents reported in prior work. Specifically, we ask whether different diagnostics converge on (i) the medial versus sentence-final distinction for appositive NRRCs and (ii) fine-grained differences among the contents of the complements of clause-embedding predicates. 

Experiments~1--4 apply the four diagnostics to a set of seven contents in English, including medial and final appositive NRRCs and the complements of selected clause-embedding predicates. While none of these four experiments observed the positional effect for NRRCs found by \citet{syrett_experimental_2015}, only Exp.~2 (`asking whether') comes close to observing the differences between the complements of clause-embedding predicates observed in \citet{degen_projection_2025}, suggesting that diagnostics do vary in whether they detect at-issueness differences between particular expressions. The `asking whether' diagnostic, as implemented in Exp.~2, which showed the greatest differentiation between contents, is the only diagnostic which asked participants are asked to judge the intentions of the speaker, and it is the only diagnostics where the target content is embedded in a polar question.

To test whether the greater differentiation under the `asking whether' diagnostic was due to the polar question embedding or from the response task itself, we compared the `asking whether' diagnostic (Exp.~5) with a direct-response diagnostic (\citealt{amaral_review_2007,tonhauser_diagnosing_2012}) that also embeds content in a polar question but elicits acceptability judgments for a direct response (Exp.~6), using the complement clauses of 20 clause-embedding predicates from \citet{degen_projection_2025}. The two experiments yielded highly correlated results, indicating that the observed high differentiation in Exp.~2 was driven by the polar question embedding, not the response task.

Our results, therefore, provide evidence that the speech act used to present the target content plays an important role: embedding the target content in polar questions yield results with greater by-content differentiation than embedding it in assertions.


\section{Experiments 1-4 \label{sec:2_experiments}}
To compare the results of at-issueness diagnostics, we conducted four experiments that each measured at-issueness with a different diagnostic, namely the QUD diagnostic (Exp.~1), the `asking whether' diagnostic (Exp.~2), the direct-dissent diagnostic (Exp.~3) and the `yes, but' diagnostic (Exp.~4).\footnote{The experiments, data and R code for generating the figures and analyses of the experiments reported in this paper are available at \url{https://anonymous.4open.science/r/at-issueness-diagnostics-232C/}.}
Each experiment tested the same set of contents associated with the seven types of expressions in \ref{stims}: sentence-medial and sentence-final NRRCs \Next[a--b], as well as the contents of the clausal complements of \emph{be right, discover, confess, confirm, discover,} and \emph{know} \Next[c--g].

\ex.\label{stims}
\a.\label{stims.a} Content of sentence-medial NRRC \\
\emph{Lucy, who broke the plate, apologized.} $\leadsto$ Lucy broke the plate\smallskip
\b.\label{stims.b} Content of sentence-final NRRC \\
\emph{The police found Jack, who saw the murder.} $\leadsto$ Jack saw the murder\smallskip
\b.\label{stims.c} Content of the clausal complement of \emph{know} \\
\emph{Ann knows that Raul cheated on his wife.} $\leadsto$ Raul cheated on his wife\smallskip
\b.\label{stims.d} Content of the clausal complement of \emph{discover} \\
\emph{Mary discovered that Denny ate the last cupcake.} $\leadsto$ Denny ate the last cupcake\smallskip
\b.\label{stims.e} Content of the clausal complement of \emph{be right} \\
\emph{Tom is right that Ann stole the money.} $\leadsto$ Ann stole the money\smallskip
\b.\label{stims.f} Content of the clausal complement of \emph{confirm} \\
\emph{Harry confirmed that Greg bought a new car.} $\leadsto$ Greg bought a new car\smallskip
\b.\label{stims.g} Content of the clausal complement of \emph{confess}  \\
\emph{Lucy confessed that Dustin lost his key.} $\leadsto$ Dustin lost his keys
\z.
\z.


These seven contents were chosen because prior literature observed differences in at-issueness between two or more of these contents using a particular diagnostic for at-issueness.  As discussed in \S1, \citealt{syrett_experimental_2015} observed differences between sentence-medial and -final NRRCs using a variant of the direct-dissent diagnostic, and \citealt{degen_projection_2025} observed differences between \emph{be right, discover, confess, confirm, discover,} and \emph{know} using the `asking whether' diagnostic. Thus, comparing these seven contents across the four diagnostics in Exps.~1--4 will allow us to assess whether the differences that emerge from one diagnostic also emerge from others. In each experiment, participants read the stimuli and gave ratings corresponding to the diagnostics.

\subsection{Methods}

\subsubsection{Participants}
For each of the four experiments, we recruited 80 unique participants on Prolific. These participants had registered on the platform as living in the USA and as having English as their primary language. They had at least 50 previous submissions and an approval rate of at least 97\%. Table \ref{t:recruited} shows the age and gender distributions of the recruited participants.

\begin{table}[h!]
  \centering
  \begin{tabular}{l | c | r r r }
    & recruited & ages (mean age) & f/m/nb/dnd \\ \hline
    Exp.~1 (QUD) & 80 & 18-81 (43.8) & 42/37/0/1  \\
    Exp.~2 (asking whether) & 80 & 20-74 (38.5)  & 48/30/1/1  \\
    Exp.~3 (direct dissent) & 80 & 18-77 (39.1) & 50/28/1/1  \\
    Exp.~4 (yes, but) &80 & 19-67 (38.0)  & 48/30/2/0 &  \\
    \hline
  \end{tabular}
  
  \caption{Information about the participants recruited in Exps.~1-4 (f = female, m = male, nb = nonbinary, dnd = did not disclose).}\label{t:recruited}
\end{table}

\subsubsection{Materials and procedure}

As shown in Fig.~\ref{fig:trials}, the response options differed by diagnostic. In Exp.~1 (QUD diagnostic, panel (a)), participants rated how well the response fit the question on a slider marked `totally doesn't fit' on one end (coded 0) and `totally fits' on the other end (coded as 1). In Exp.~2 (`asking whether' diagnostic, panel (b)), participants judged whether the question was about the target content, using a slider marked `no' on one end (coded as 0) and `yes' on the other (coded as 1). In Exp.~3 (direct-dissent diagnostic, panel (c)), participants rated the naturalness or the direct dissent on a slider marked `totally unnatural' (coded as 0) on one end and `totally natural' on the other (coded as 1). Finally, in Exp.~4 (`yes, but' diagnostic, panel (d)), participants chose the response that sounded best; the two indirect dissents were coded as 0 and the direct one as 1. Across the four experiments, the responses were coded so that 1 meant that the content to be diagnosed was rated as at-issue and 0 as not-at-issue.

\begin{figure}[ht]
  \centering
  % Top row
  \subfigure[Exp.~1: QUD diagnostic]{%
  \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp1}}%
  \label{fig:trialExp1}
  }
  \hfill
  \subfigure[Exp.~2: `asking whether' diagnostic]{%
  \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp2}}%
  \label{fig:trialExp2}
  }
  
  \vspace{1em}
  
  % Bottom row
  \subfigure[Exp.~3: direct-dissent diagnostic]{%
  \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp3}}%
  \label{fig:trialExp3}
  }
  \hfill
  \subfigure[Exp.~4: `yes, but' diagnostic]{%
  \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp4}}%
  \label{fig:trialExp4}
  }
  
  \caption{Sample trials in (a) Exp.~1, (b) Exp.~2, (c) Exp.~3, and (d) Exp.~4.}
  \label{fig:trials}
\end{figure}

Each of the seven contents in \ref{stims} was combined with one of the seven items in \ref{items} in each of the four experiments.

\begin{multicols}{2}
  \ex.\label{items}
  \a. Jack saw the murder.
  \b. Raul cheated on his wife.
  \c. Ann stole the money.
  \d. Danny ate the last cupcake.
  \b. Lucy broke the plate.
  \b. Dustin lost his key.
  \b. Greg bought a new car.
  \z.
  
\end{multicols}

Each experiment included two control stimuli serving as attention checks: one was expected to receive a response at one end of the slider (Exps.~1-3) or a `no' response (Exp.~4); the other control stimulus was expected to receive a response at the other end of the slider (Exps.~1-3) or a `yes' response (Exp.~4). See Supplement \ref{supp:stims} for the control stimuli used in Exps.~1-4.

In all four experiments, each participant's set of items was generated by randomly combining each of the seven contents in \ref{stims} with a unique item in \ref{items}. Participants completed a total of 9 trials, namely 7 target trials and the same 2 control trials. Trial order was randomized for each participant.

After completing the experiment, participants filled out a short optional demographic survey. To encourage truthful responses, participants were told that they would be paid no matter what answers they gave in the survey.

\subsubsection{Dependent measure and interpretation}
Following prior work (e.g., \citealt{tonhauser_how_2018}), we interpret higher/lower mean ratings as indicating that content is more/less at-issue under a given diagnostic, with two caveats: First, we remain agnostic about whether at-issueness is an underlyingly binary or a gradient property (cf. \citealt{tonhauser_how_2018,barnes_information_2023}). If at-issueness is gradient, the extent to which a content is at-issue may be understood as the extent to which it is relevant to the QUD or the main assertion, in which case gradient mean ratings may be taken to reflect gradient relevance. If at-issueness is categorical, content is at-issue iff it addresses the QUD or assertive proposal, and not-at-issue otherwise; and gradient mean ratings could be attributed to uncertainty about what the QUD/proposal is. For example, our interpretation of a content in a given utterance being more/less at-issue may be interpreted as reflecting the frequency or ease with which a particular QUD is attributed to that utterance.
\jt{is this really a caveat to the linking function?}
\lh{It does seem to me that it is, but this is based on my best interpretation of your previous bullet points.}
%
Second, we use the term \enquote{at-issueness diagnostic} descriptively throughout the paper, even though our findings may ultimately suggest that these diagnostics track distinct theoretical constructs. We return to this issue in the general discussion.

\subsubsection{Data exclusion}

We excluded the data of participants that were not self-reported native speakers of American English and of participants whose responses to one of the two control trials was more than 2 sd away from the group mean (Exps.~1--3) or whose responses to one of the two control trials was wrong (Exp.~4). Table \ref{t:excluded} shows how many participants were excluded in each experiment, demographic information for the remaining participants, and the number of data points that entered into the analyses.

\begin{table}[h!]
  \centering
  \begin{tabular}{l | r r | r r  | r }
    & \multicolumn{2}{c|}{\bf exclusion criterion} & \multicolumn{2}{c|}{\bf remaining participants} & data \\ 
    & language & fillers & ages (mean age) & f/m/nb/dnd &  points \\ \hline
    Exp.~1 (QUD)   & 1 &  10 &  18-81 (41.1) & 36/32/0/1 & 621 \\ 
    Exp.~2 (asking whether) &  2 &  4 & 22-74 (38.7) & 45/27/1/1 & 666 \\ 
    Exp.~3  (direct dissent) &  2 &  7 & 18-77 (39.5) & 44/25/1/1  & 639 \\ 
    Exp.~4  (yes, but) & 4 & 4 & 19-67 (38.5)  & 43/27/2/0 & 648 \\ 
    \hline
  \end{tabular}
  \caption{Information from Exps.~1-4 about the number of participants whose data was excluded based on their self-declared language (variety) and the fillers, about the remaining participants, and about the number of data points that entered into the analysis.}\label{t:excluded}
\end{table}

\subsection{Results}
Fig.~\ref{fig:results} plots the results of the four experiments by the expression that is associated with the seven target contents. Panel (a) shows the mean naturalness ratings in Exp.~1 (QUD diagnostic), panel (b) mean `asking whether' ratings in Exp.~2 (`asking whether' diagnostic), panel (c) shows mean naturalness ratings in Exp.~3 (direct-dissent diagnostic) and panel (d) the proportion of `no' choices in Exp.~4 (`yes, but' diagnostic).

\begin{figure}[h!]
  \centering
  % Top row
  \subfigure[Exp.~1 (QUD diagnostic)]{%
  \includegraphics[width=0.48\linewidth]{../../results+analysis/exps1-4/exp1/graphs/mean-ratings.pdf}%
  \label{fig:qud}
  }
  \hfill
  \subfigure[Exp.~2 (`asking whether' diagnostic)]{%
  \includegraphics[width=0.48\linewidth]{../../results+analysis/exps1-4/exp2/graphs/mean-ratings.pdf}%
  \label{fig:AK}
  }
  
  % \vspace{1em}
  
  % Bottom row
  \subfigure[Exp.~3 (direct-dissent diagnostic)]{%
  \includegraphics[width=0.48\textwidth]{../../results+analysis/exps1-4/exp3/graphs/mean-ratings.pdf}%
  \label{fig:dd}
  }
  \hfill
  \subfigure[Exp.~4 (`yes, but' diagnostic)]{%
  \includegraphics[width=0.48\textwidth]{../../results+analysis/exps1-4/exp4/graphs/mean-ratings.pdf}%
  \label{fig:yb}
  }
  \caption{Results of Exps.~1--4.
  Panels (a)--(c) show the mean responses by expression for (a) Exp.~1 (QUD diagnostic),  (b) Exp.~2 (`asking whether' diagnostic), and (c) Exp.~3 (direct-dissent diagnostic); panel (d) shows the proportion of `no' choices by expression in Exp.~4 (`yes, but' diagnostic). Error bars indicate 95\% bootstrapped confidence intervals. Violin plots in panels (a)-(c) show the kernel probability density of individual participants' ratings. Gray dots in panel (d) represent individual participant responses (`no' vs.\ `yes', jittered vertically and horizontally for legibility).}
  \label{fig:results}
\end{figure}

As is visually apparent in Fig.~\ref{fig:results}, the diagnostics differ in the overall range of mean responses across the seven contents (given as the difference between the largest and smallest by-content means). The range is largest in Exp.~2 (`asking whether' diagnostic), at .74 (from .1 to .83) and smallest in Exp.~3 (direct-dissent diagnostic), at .13 (.64 to .78). The results of Exp.~1 (QUD diagnostic), with a range of .27 (.51 to .77) and Exp.~4 (`yes, but' diagnostic), with a range of .46 (.5 to .96), fall in between.

%Exp 1
%min: 0.5055072
%max: 0.7713043
%range: 0.2657971

%Exp 2
%min: 0.09364865
%max: 0.8332432
%range: 0.7395946

%Exp 3
%min: 0.6443662
%max: 0.7752113
%range: 0.1308451

%Exp 4
%min: .5
%max: 0.958
%range: 0.458

The experiments differ in whether they reproduce distinctions between contents reported in prior work. \citet{syrett_experimental_2015}, using a variant of the direct-dissent diagnostic, found that sentence-medial NRRCs are more not-at-issue than sentence-final ones. In contrast, as shown in Fig.~\ref{fig:results}, no such difference is observed in Exps.~1--3; and in Exp.~4 (`yes, but' diagnostic), we find the opposite: sentence-final NRRCs are rated less at-issue than sentence-medial ones. Thus, none of the diagnostics as implemented in Exps.~1--4 replicate \citeauthor{syrett_experimental_2015}'s finding.

\citet{degen_projection_2025}, using the `asking whether' diagnostic, observed fine-grained differences in at-issueness among the complements of clause-embedding predicates, ordered as follows: \emph{know} < \emph{discover} < \emph{confess} < \emph{confirm} < \emph{be right}. As shown in Fig.~\ref{fig:results}, Exp.~2 (`asking whether') largely reproduces this pattern, except that \emph{confess} and \emph{discover} do not differ.

The other three experiments show fewer differences between the mean at-issueness ratings among the clause-embedding predicates. In Exp.~1 (QUD diagnostic), the embedded content of most predicates shows little differentiation, with only two predicates showing a clearly different pattern: the embedded content of \emph{confirm} is rated most at issue, and the embedded content of \emph{be right} is rated less at-issue than the other predicates -- the direction of this difference is the opposite to that observed in prior literature and the other experiments. In Exp.~3, no clear differences among clause-embedding predicates are found. Finally, in Exp.~4, the proportions of \emph{yes}-responses are similar for many of the clause-embedding predicates, but the highest proportion is found for content of the complement of \emph{be right}, and it is clearly different from the clause-embedding predicates on the lower end, such as \emph{confirm} and \emph{confess}.

\addtolength{\tabcolsep}{-.19em}
%
\begin{figure}[!h]
  \centering
  \subfigure[Exp.~1 (QUD diagnostic)]{%
  \mbox{\begin{tabular}{r | ccccccc}
    & \rots{be right} & \rots{confirm} & \rots{discover} & \rots{confess} & \rots{know} & \rots{final NRRC} & \rots{medial NRRC} \\
    \hline
    be right & \cellcolor{black} & \cellcolor{red} & \cellcolor{red} & \cellcolor{red} & \cellcolor{red} & \cellcolor{red} & \cellcolor{red} \\ 
    confirm & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    discover & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
    confess & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} \\ 
    know & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} \\ 
    final NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} \\ 
    medial NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} \\ 
    \hline
  \end{tabular}}}
  \hfill
  \subfigure[Exp.~2 (`asking whether' diagnostic)]{%
  \mbox{\begin{tabular}{r | ccccccc}
    & \rots{be right} & \rots{confirm} & \rots{discover} & \rots{confess} & \rots{know} & \rots{final NRRC} & \rots{medial NRRC} \\
    \hline
    be right & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    confirm & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    discover & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    confess & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    know & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} \\ 
    final NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} \\ 
    medial NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} \\ 
    \hline
  \end{tabular}}}
  
  \subfigure[Exp.~3 (direct-dissent diagnostic)]{%
  \mbox{\begin{tabular}{r | ccccccc}
    & \rots{be right} & \rots{confirm} & \rots{discover} & \rots{confess} & \rots{know} & \rots{final NRRC} & \rots{medial NRRC} \\
    \hline
    be right & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
    confirm & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
    discover & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
    confess & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} \\ 
    know & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} \\ 
    final NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} \\ 
    medial NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} \\ 
    \hline
  \end{tabular}}}
  \hfill
  \subfigure[Exp.~4 (`yes, but' diagnostic)]{%
  \mbox{\begin{tabular}{r | ccccccc}
    & \rots{be right} & \rots{confirm} & \rots{discover} & \rots{confess} & \rots{know} & \rots{final NRRC} & \rots{medial NRRC} \\
    \hline
    be right & \cellcolor{black} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    confirm & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
    discover & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
    confess & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{red} & \cellcolor{blue} & \cellcolor{white} \\ 
    know & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} \\ 
    final NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{red} \\ 
    medial NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} \\
    \hline
  \end{tabular}}}
  \caption{Pairwise differences between expressions,
  ordered from top to bottom and left to right by increasing mean in Exp.~2 (`asking whether' diagnostic). A white cell means that the 95\% HDI of the pair of the row expression and the column expression includes 0, a red cell means that the 95\% HDI does not include 0 and that the coefficient is positive (the row expression received a higher rating than the column expression), and a blue cell means that the 95\% HDI does not include 0 and the coefficient is negative (the row expression received a lower rating than the column expression).}
  \label{fig:pairwise}
\end{figure}

The differences described above are supported by post-hoc pairwise comparisons of the estimated means or proportions for each content, using the \texttt{emmeans} package (\citealt{emmeans}) in R (\citealt{r}), illustrated in Fig.~\ref{fig:pairwise}. These comparisons were based on mixed-effects beta regression models (Exps.~1--3) and a mixed-effects logistic regression model (Exp.~4), all fit using the \texttt{brms} package (\citealt{buerkner2017}) using weakly informative priors. The models predicted the ratings\footnote{To model the ratings in Exps.~1--3 using a beta regression, the ratings were first transformed from the interval [0,1] to the interval (0,1) using the method proposed in \citealt{smithson-verkuilen2006}.} from a fixed effect of expression (treatment-coded, with \emph{be right} as reference level), with random intercepts for participants and items. The output of the pairwise comparison were 95\% highest density intervals (HDIs) of estimated marginal mean differences between each of the expressions. We assume that two contents differ if their HDI does not include 0.\footnote{The full model outputs are available in the folder \texttt{results+analysis/exps1-4/} in the repository available at \url{https://anonymous.4open.science/r/at-issueness-diagnostics-232C/.}}

Accordingly, \Cref{fig:pairwise} shows that the only clear positional difference for NRRCs is observed in Exp.~4 (`yes, but' diagnostic), where the sentence-medial ones are rated as more at-issue than sentence-final ones, contrary to previous findings. The other three experiments show no differences between sentence-medial and sentence-final NRRCs. The differences between clause-embedding predicates observed in prior work using the `asking whether' diagnostic are largely replicated in Exp.~2, except for \emph{confess} and \emph{discover}, which do not differ from each other. The other three experiments show fewer differences between clause-embedding predicates, with Exp.~3 showing no differences at all. In particular, the embedded content of \emph{be right} is rated less at-issue than that of most other clause-embedding predicates in Exp.~1, but more at-issue than content of embedded clauses under most other predicates in Exp.~4.

We also find that the four experiments differ in the relative ratings assigned to the seven contents, with only limited overlap. Across all experiments, \emph{confirm} and \emph{discover} consistently received higher ratings (at least numerically) than \emph{confess}, which in turn received higher ratings than medial and final NRRCs. For all other pairs of expressions, however, the ordering was not consistent. In particular, the ranking of \emph{be right} relative to most other contents is inconsistent across experiments (e.g., compared to appositive NRRCs):  The embedded content of \emph{be right} received the lowest ratings in Exp.~1, but was among the most at-issue in the other three experiments. The embedded content of \emph{know} was rated (numerically) lower than that of \emph{confirm} in Exps.~1 and 2, but higher in Exps.~3 and 4.
%
This difference between the results of the experiments is quantified in the Spearman rank correlations shown in Table \ref{t:spearman}.\footnote{The Spearman rank correlation coefficient, a value between -1 and 1, is a nonparametric measure of rank correlation: the higher the absolute value of the coefficient, the more the relation between the two variables can be described using a monotonic function. If the coefficient is positive, the value of one variable tends to increase with an increase in the other. In the case of our experiments, a coefficient of 1 for two experiments would mean that there is a perfectly monotone increasing relation between the mean ratings of the seven contents in the two experiments: for any two contents c1 and c2, if c1 ranks below c2 in one experiment (that is, the mean rating of c1 is lower than that of c2), then that ranking is preserved in the other experiment.}

\begin{table}[ht!]
  \centering
  \begin{tabular}{l | c c c c}
    & Exp.~1 & Exp.~2 & Exp.~3 & Exp.~4 \\ \hline
    Exp.~1 (QUD diagnostic) & \cellcolor{lightgray} & .11 & -.29 & -.18 \\
    Exp.~2 (`asking whether' diagnostic) & \cellcolor{lightgray} & \cellcolor{lightgray} & .64 &.79 \\
    Exp.~3 (direct-dissent diagnostic) & \cellcolor{lightgray}& \cellcolor{lightgray} & \cellcolor{lightgray} & .79  \\
    \hline
    % Exp.~4 (`yes, but' diagnostic) & & & & \cellcolor{lightgray} \\ \hline
  \end{tabular}
  \caption{Spearman rank correlations between the results of Exps.~1--4.}\label{t:spearman}
\end{table}

The rank correlations are particularly low for Exp.~1 compared to the other three experiments, at least partly because of the low relative ranking of \emph{be right}. These results suggest that the four diagnostics as implemented in Exps.~1--4 interact differently with the seven contents investigated.


\subsection{Discussion}

Exps.~1--4 were designed to compare four at-issueness diagnostics that have been widely used in the literature. To assess whether the diagnostics yield consistent findings when applied to the same target contents, we asked whether they reproduce contrasts reported in prior work, particularly (i) the medial versus sentence-final distinction for appositive NRRCs, and (ii) fine-grained differences among the contents of the complements of clause-embedding predicates. The results of Exps.~1--4 suggest that the four diagnostics do differ in whether they reproduce these contrasts, and in the relative order of the seven contents investigated. Three main differences between the four experiments emerge:

\begin{enumerate}
  
  \item The four experiments differ in the extent to which they differentiate between the seven contents investigated, as evidenced by where they find by-content differences: Only the `asking whether' diagnostic (Exp.~2) comes close to comes close to observing fine-grained differences between the contents of the complements of clause-embedding predicates as in \citet{degen_projection_2025}.
  
  \item They differ in the relative order of the seven contents -- most notably in the case of the complement of \emph{be right}, which ranks low under the QUD diagnostic but high under the other diagnostics.
  
  \item None of the diagnostics as implemented here reproduce the positional effect for appositive NRRCs reported by \citet{syrett_experimental_2015}. Exps.~1-3 show no difference between medial and sentence-final NRRCs, while Exp.~4 (the `yes, but' diagnostic) yields the opposite pattern: here, medial NRRCs were judged as more at-issue than final ones.
  
\end{enumerate}

This section discusses the implications of these findings for the interpretation of the diagnostics and for theories of at-issueness.

\subsubsection{Positional effects for appositive NRRCs?} \label{ssub:appositives}

One factor that might explain the difference between our findings and those of \citet{syrett_experimental_2015}, apart from the stimuli, is the response task. Although both studies tested appositive NRRCs using dissent-based diagnostics presenting the target content in an assertion, their forced-choice implementation differs from our Exps.~3 and 4. In Exp.~3 (direct dissent), we elicited naturalness ratings rather than forced-choice judgments. Even in Exp.~4 (`yes, but'), which also used a forced-choice continuation task, the response options were different. In our implementation (based on \citealt{xue_correlation_2011}), all options rejected the target content, and participants chose between expressing direct dissent (\emph{no}), indirect dissent (\emph{yes, but}), or assent without contrast (\emph{yes, and}). In Syrett \& Koev's study, all options expressed direct dissent (\emph{no}), and participants chose whether to reject the appositive content or the main clause content, as illustrated in \Next.

\ex. \citealt{syrett_experimental_2015}, p.~17
\a.[A:] My friend Sophie, a classical violinist, performed a piece by Mozart.
\b.[B1:] No, she's not. (target: NRRC)
\b.[B2:] No, she didn't. (target: main clause)
\z. \z. 

While the findings suggest that positional effects for appositive NRRCs may not be robust across diagnostics, the corresponding task differences suggest that even small changes in the response task used to operationalize a diagnostic, such forced-choice alternatives, might reverse the observed pattern. More generally, different diagnostics vary in whether they detect any positional difference for appositive NRRCs at all. This suggests that previously reported effects may reflect task- or diagnostic-specific effects rather than stable properties of NRRC interpretation. A natural follow-up would be to test whether applying their particular forced-choice schema to our stimuli would reproduce their effect.

% \jt{i agree with you on this point but i don't think it warrants its own subsubsection, and it could be dramatically shorter, like a single paragraph, especially if (9) is in the intro}


\subsubsection{Interactions with discourse requirements: the case of \emph{be right} \label{ssub:be-right}}

The diagnostics as implemented here yielded different rank orders of contents. At first glance, one might take such differences as evidence that the diagnostics track distinct underlying notions of at-issueness. However, the most pronounced ranking difference, between the low ranking of the complement of \emph{be right} in Exp.~1 (QUD diagnostic) and its high ranking in the other experiments, does not appear to reflect a difference in at-issueness. Instead, it arises from how the QUD diagnostic interacts with the requirements that \emph{be right} places on the prior discourse.

As shown in panel (a) of Fig.~\ref{fig:results}, participants gave relatively low naturalness ratings to responses like that in \ref{beright.a}, indicating that they did not judge the response as fitting the question.

\ex.
\a.\label{beright.a}  Exp.~1 (QUD diagnostic) with \emph{be right}
\\ {\bf Nora:} \emph{What did Lucy break?}
\\ {\bf Leo:} \emph{Danny is right that she broke the plate.}
\b.\label{beright.b} Exp.~2 (`asking whether' diagnostic)
\\ {\bf Nora:} \emph{Is Danny right that she broke the plate?}
\c.\label{beright.c} Exp.~3 (`direct dissent' diagnostic)
\\ {\bf Nora:} \emph{Danny is right that she broke the plate.}
\\ {\bf Leo:} \emph{No, she didn't break the plate.}
\d.\label{beright.d} Exp.~4 (`yes, but' diagnostic)
\\ {\bf Nora:} \emph{Danny is right that she broke the plate.}
\\ {\bf Leo:} \emph{Yes, but she didn't break the plate.}
\\ \hspace*{1cm} \emph{Yes, and she didn't break the plate.}
\\ \hspace*{1cm} \emph{No, she didn't break the plate.}

We hypothesize that this is because \emph{be right} in \Last presupposes that Danny has previously committed to the proposition that \enquote{Lucy broke the plate} (\citealt{abusch_presupposition_2010,anand_factivity_2014}). In the three diagnostics in \Last[b--d], no previous discourse context is given, so this presupposition can be accommodated. In contrast, the preceding question in the QUD-diagnostic \Last[a] conflicts with the presupposition, making it difficult to accommodate. Specifically, we hypothesize that \emph{be right} signals that the question \enquote{whether Lucy broke the plate} is salient in the preceding discourse. This allows us to understand the ill-formedness based on QUD-based discourse structure, because this presupposed question is a subquestion (in the sense of \citealt{roberts_information_2012}) of the question in \Last[a] \enquote{What did Lucy break}, since every complete answer to the latter entails an answer to the former. The progression from the presupposed subquestion question to the explicitly given superquestion violates Roberts' constraint on QUD stacks (p. 6:15), which allows only the reverse order (from superquestions to subquestions).

As a result, low QUD-match ratings for \Last[a] are predicted, not because the embedded clause is not at-issue, but because the utterance presupposes an incoherent discourse context.%
\footnote{\label{fn:w-o-be-right}
When \emph{be right} is excluded, the Spearman rank correlations are:

\begin{tabular}{l | c c c c}
  & Exp.~1 & Exp.~2 & Exp.~3 & Exp.~4 \\ \hline
  Exp.~1 (QUD diagnostic) & \cellcolor{lightgray} & .77 & -.09 & -.31 \\
  Exp.~2 (`asking whether' diagnostic) & \cellcolor{lightgray} & \cellcolor{lightgray} & .66 & .66 \\
  Exp.~3 (`direct dissent' diagnostic) & \cellcolor{lightgray}& \cellcolor{lightgray} & \cellcolor{lightgray} & .77  \\
  \hline
  % Exp.~4 (`yes, but' diagnostic) & & & & \cellcolor{lightgray} \\ \hline
\end{tabular}}
This highlights that diagnostics may interact with contextual requirements independently of at-issueness, and such interactions must be taken into account when interpreting the results.


\subsubsection{Why does the `asking whether' diagnostic show greater differentiation? \label{ssub:differentiation}}
A striking difference between the results of the experiments is that Exp.~2 (`asking whether') showed the greatest differentiation between contents, whereas the other three experiments exhibited a smaller range of means, and fewer statistically supported differences between investigated contents. Among the first 4 experiments, Exp.~2 was the only one that came close to differentiating fine-grained by-content differences as reported in \cite{degen_projection_2025}.

Considering the question whether the existing definitions of at-issueness target the same underlying phenomenon, we might consider whether this empirical difference between diagnostics aligns with the divide emphasized in prior work between diagnostics that have been associated with a QUD-based definition (QUD, `asking whether') and those that have been argued to target a proposal-based definition (direct-dissent, `yes, but'). However, this distinction could not explain why the `asking whether' diagnostic behaves differently from the QUD diagnostic, since both have been linked to the QUD-based definition of at-issueness.

To explain the greater by-content differentiation of the `asking whether' diagnostic, we therefore focus on properties that set it apart from the other three diagnostics. Two differences are particularly salient: First, it is the only diagnostic where the target content itself occurs in a polar question, whereas in the other diagnostics, the target content appears in a declarative assertion. Second, it is the only diagnostic where participants are asked directly about the intentions of the speaker, while the other ones collect measures that are more indirectly tied to semantic interpretation, such as acceptability ratings and continuation choices. Either of these properties might be important for explaining the greater differentiation.

These considerations motivate two hypotheses,  which we tested in Exps.~5--6. The following section reports on these experiments, which compare the `asking whether' diagnostic to a diagnostic that also embeds the target content in a polar question but elicits naturalness ratings for a direct response to assess at-issueness. Both experiments yielded similarly fine-grained distinctions among contents, supporting the conclusion that the increased differentiation observed in Exp.~2 is driven primarily by interrogative embedding rather than by the response task.

\section{Experiments 5 and 6 \label{sec:3_more-experiments}}
%
Exps.~5 and 6 investigate whether the greater differentiation observed in Exp.~2 (`asking whether') was due to (i) embedding target contents in polar questions or (ii) the response task, testing two hypotheses:
\begin{enumerate}
  \item \textbf{Question-embedding hypothesis:} Differentiation between contents is greater when contents are embedded in a polar question than in a declarative assertion.
  % \jt{`polar question' is a sentence type; `declarative assertion' is both sentence type and speech act}
  
  \item \textbf{Response-task hypothesis:} Differentiation is greater when participants are asked directly what the utterance is about, compared to tasks such as acceptability judgments or forced-choice continuations.
  
\end{enumerate}

To test these hypotheses, we compared two diagnostics that both embed the target content in a polar question but differ in the response task. Exp.~5 used the `asking whether' diagnostic as in Exp.~2 \Next[a] and Exp.~6 uses a direct-response diagnostic (\citealt{amaral_review_2007,tonhauser_diagnosing_2012}), shown in \Next[b].


\ex. Implementation of the diagnostics in Exps.~  5--6 
\a.\label{exp5} Exp.~5 (`asking whether' diagnostic )
\\ {\bf Nora:} \emph{Is Tom right that Lucy broke the plate?}
\\ Question to participants: Is Nora asking whether Lucy broke the plate?
\b.\label{exp6} Exp.~6 (direct-response diagnostic)
\\ {\bf Nora:} \emph{Is Tom right that Lucy broke the plate?}
\\ {\bf Leo:} \emph{Yes, she didn't break the plate.}
\\ Question to participants: How natural is Leo's response to Nora's question?
\z. \z.

This direct-response diagnostic targets the assumption that at-issue content is interpreted as determining the question alternatives (property (ii)). Participants read a dialogue between two named speakers, where the first utters a polar question, which contributes the target content. They then rate the naturalness of a  \emph{yes}  response that asserts the target content. A response to a question is felicitous only if the target content provides a possible answer, that is, a question alternative (\citealt{von_stechow_focusing_1991}). Accordingly, naturalness ratings are expected to be high when the target content is at-issue and low otherwise.

Both experiments measured at-issueness of the contents of the complements of the 20 clause-embedding predicates from \citealt{degen_projection_2025}:

\ex. \label{ex:predicates}
20 clause-embedding predicates from \citealt{degen_projection_2025}:\smallskip\\ 
\emph{acknowledge,  admit, announce, be annoyed, be right, confess, confirm, demonstrate, discover, establish, hear, inform, know, pretend, prove, reveal, say, see, suggest, think}
\z. 

Both experiments also assessed the projection of the complement contents. This data was reported in \citealt{hofmann-etal2024}. Here we focus on the at-issueness data, which have not yet been reported.

If the greater differentiation between contents found in Exp.~2 (compared to Exps.~1, 3,  and 4) was driven primarily by presenting the target content in a polar question, we expect Exps.~5 and 6 to show similar fine-grained by-content differentiation of at-issueness. In contrast, if  Exp.~5 again shows greater differentiation than Exp.~6, this would support the response-task hypothesis, indicating that the task, rather the question embedding, drives the effect.

\subsection{Methods}

\subsubsection{Participants}

We recruited 300 participants on Amazon's Mechanical Turk platform for Exp.~5 and 250 participants on Prolific for Exp.~6.\footnote{Exp.~5 was run in August 2019 and Exp.~6 in August 2021.} Participants recruited on Mechanical Turk had U.S.\ IP addresses and at least 99\% of previous HITs approved. Participants recruited on Prolific had registered as U.S.-born native speakers of English residing in the USA and had an approval rate of at least 99\%. Table~\ref{t:recruited2} summarizes the age and gender distributions of the recruited participants.

\begin{table}[h!]
  \centering
  \begin{tabular}{l | c | r r r }
    & recruited & ages (mean age) & f/m/nb/dnd \\ \hline
    Exp.~5 (asking whether) & 300 & 19-74 (38.2) & --/--/--/--  \\
    Exp.~6 (direct assent) & 250 & 18-58 (25.5)  & 201/43/6/0  \\
    \hline
  \end{tabular}
  
  \caption{Information about the participants recruited in Exps.~5-6 (f = female, m = male, nb = nonbinary, dnd = did not disclose; gender information was not collected in Exp.~5).}\label{t:recruited2}
\end{table}

\subsubsection{Materials and procedure}

As shown in Fig.~\ref{fig:trials56}, the response task differed between experiments. In Exp.~5 (`asking whether' diagnostic, panel (a)), participants judged whether the question was about the content of the complement clause, using a slider marked `no' on one end (coded as 0) and `yes' on the other (coded as 1). In Exp.~6 (direct-response diagnostic, panel (b)), participants rated whether the response to the first speaker sounds good, on a slider marked `no' (coded as 0) on one end and `yes' on the other (coded as 1). In the initial instructions, participants were asked to imagine that they are at a party and that, when walking into the kitchen, they overhear somebody say something to somebody else. Across both experiments, the responses were coded so that 1 meant that the content of the embedded clause was rated as at-issue and 0 as not-at-issue.

\begin{figure}[h!]
  \centering
  % Top row
  \subfigure[Exp.~5: `asking whether' diagnostic]{%
  \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp5}}%
  \label{fig:trialExp5}
  }
  \hfill
  \subfigure[Exp.~6: direct response diagnostic]{%
  \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp6}}%
  \label{fig:trialExp6}
  }
  
  \caption{Sample trials in (a) Exp.~5 and (b) Exp.~6.}
  \label{fig:trials56}
\end{figure}

In both experiments, target stimuli were created by combining each of the 20 clause-embedding predicates in \ref{ex:predicates} with one of 20 items (listed in Supplement \ref{supp:a-clauses}). The same six control stimuli were included in both experiments. The contents targeted in these controls (see Supplement \ref{supp:control56}) were expected to be at-issue and served as attention checks. For each participant, the 20 predicates were randomly paired with 20 unique items, yielding one target stimulus per predicate. Participants thus saw 26 stimuli in total: 20 target items and 6 controls.\footnote{Each participant saw their set of 26 stimuli twice, once in the projection block and once in the at-issueness block. Block order was randomized. As mentioned above, we focus here on the at-issueness data.} Trial order was randomized for each participant. After completing the experiment, participants filled out a short optional demographic survey. To encourage truthful responses, participants were told that they would be paid no matter what answers they gave in the survey.

\subsubsection{Data exclusion}

We excluded the data of participants who did not self-identify as native speakers of American English, of participants whose responses to the projection or at-issueness controls were more than 2 sd away from the group mean, and of participants who always selected roughly the same point on the response scale for the target stimuli.
\jt{did we do this latter one in exps 1-4 as well?}
\lh{I don't think so, and if it should be the same in both, I would suggest omitting this latter criterion here, since it does not seem to make much of a difference.}
To identify such participants, we first identified participants whose mean variance on the target stimuli was more than 2 sd below the group mean variance and then manually inspecting their response patterns. Due to a programming error, 5 participants took Exp.~5 more than once. Since we were not able to identify which submission was their first submission, the data of these participants was also excluded. Table \ref{t:excluded2} shows how many participants were excluded in each experiment, the properties of the remaining participants, and the number of data points that entered into the analyses.

\begin{table}[h!]
  \centering
  \resizebox{\linewidth}{!}{
  \begin{tabular}{l | r r r | r r r | r }
    & \multicolumn{3}{c|}{\bf exclusion criterion} & \multicolumn{3}{c|}{\bf remaining participants} & data \\ 
    & language & controls & variance & ages (mean age) & f/m/nb/dnd & total &  points \\ \hline
    Exp.~5 (asking whether)  & 7 &  35 & 0 &  21-74 (39.2) & --/--/--/-- & 242 & 6292 \\ 
    Exp.~6 (direct assent) &  5 &  24 & 1 & 18-58 (24.9) & 187/28/5/0 & 220 & 5720 \\ 
    \hline
  \end{tabular}}
  \caption{Information from Exps.~5-6 about the number of participants whose data was excluded based on their self-declared language and language variety (`language'), the controls, and the variance of their responses, about the remaining participants, and about the number of at-issueness data points that entered into the analysis.}\label{t:excluded2}
\end{table}

\subsection{Results and discussion}
Fig.~\ref{fig:results2} shows the results of the two experiments by embedding predicate: panel (a) plots mean `asking whether' ratings in Exp.~5, and panel (b) plots mean naturalness ratings in Exp.~6 (direct-response).

\begin{figure}[h!]
  \centering
  \subfigure[Exp.~5 (`asking whether' diagnostic)]{%
  \includegraphics[width=0.485\linewidth]{../../results+analysis/exps5-6/exp5/graphs/mean-ratings.pdf}%
  \label{fig:results5}
  }
  %
  \subfigure[Exp.~6 (`direct assent' diagnostic)]{%
  \includegraphics[width=0.485\linewidth]{../../results+analysis/exps5-6/exp6/graphs/mean-ratings.pdf}%
  \label{fig:results6}
  }
  
  \caption{Results of Exps.~5--6. The panels show the mean ratings by expression for (a) Exp.~5 (asking whether diagnostic) and (b) Exp.~2 (direct assent diagnostic). Error bars indicate 95\% bootstrapped confidence intervals. Violin plots show the kernel probability density of individual participants' ratings.}
  \label{fig:results2}
\end{figure}

Overall, the results of two experiments yield highly similar patterns. The ranges of by-content means are comparable (Exp.~5 range: .75, .07 to .82; Exp.~6 range: .73, .09 to .82), and the relative orderings of contents by their means align closely, as reflected in a strong Spearman rank correlation ($r_s=.93$).

Crucially, both experiments show fine-grained by-content differentiation. For instance, for the subset of predicates also tested in Exps.~1--4, Exps.~5 and 6 reproduce the ordering expected based on \citet{degen_projection_2025} and show pairwise differences in the predicted directions for adjacent contents (\emph{know} < \emph{discover} < \emph{confess} < \emph{confirm} < \emph{be right}). Overall, the results in Exps.~5 and 6 are similar in revealing fine-grained differences among many rank-adjacent predicates.

There are also some differences between the experiments, concerning a small number of local reversals in the middle of the scale. For example, the content of the complement of \emph{demonstrate} comes out as more at-issue than that of \emph{announce}, \emph{confess}, and \emph{reveal} under the `asking whether' diagnostic as implemented in Exp.~5, but as less at-issue than the content embedded under these predicates under the implementation of the direct-response diagnostic in Exp.~6.

Fig.~\ref{fig:pairwise2} presents the results of post-hoc pairwise comparisons of the estimated means for each content. As in \Cref{sec:2_experiments}, we used \texttt{emmeans} (\citealt{emmeans}) in R (\citealt{r}) applied to mixed-effects beta regression models fit with \texttt{brms} (\citealt{buerkner2017}) using weakly informative priors. The models predicted ratings\footnote{To model the ratings using a beta regression, the ratings were first transformed from the interval [0,1] to the interval (0,1) using the method proposed in \citealt{smithson-verkuilen2006}.} from a fixed effect of content (treatment-coded, with \emph{be right} as the reference level). The pairwise comparisons support the above generalizations: while the two diagnostics as implemented here differ in which specific contrasts they detect, their overall patterns are highly consistent. Both diagnostics reveal fine-grained at-issueness differences between contents. At the same time, there are some differences, namely some contrasts that reached significance in experiment did not in the other.

\begin{figure}[!h]
  \renewcommand{\arraystretch}{1}
  \centering
  \subfigure[Exp.~5 (`asking whether' diagnostic)]{%
  \resizebox{.49\linewidth}{!}{
  \begin{tabular}{r|*{20}{>{\arraybackslash}p{\colw}}}
    & \rots{be right} & \rots{confirm} & \rots{say} & \rots{establish} & \rots{prove} & \rots{suggest} & \rots{demonstrate} & \rots{announce\phantom{yl}} & \rots{reveal} & \rots{admit} & \rots{confess} & \rots{think} & \rots{acknowledge} & \rots{pretend} & \rots{see\phantom{l}} & \rots{discover} & \rots{hear} & \rots{inform} & \rots{know} & \rots{be annoyed} \\
    \hline
    be right & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    confirm & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    say & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    establish & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    prove & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    suggest & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    demonstrate & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    announce & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    reveal & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    admit & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    confess & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    think & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    acknowledge & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    pretend & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    see & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    discover & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    hear & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
    inform & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} \\ 
    know & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} \\ 
    \hline
  \end{tabular}}}
  %
  \subfigure[Exp.~6 (direct-response diagnostic)]{%
  \resizebox{.48\linewidth}{!}{
  \begin{tabular}{r|*{20}{>{\centering\arraybackslash}p{\colw}}}
    & \rots{be right} & \rots{confirm} & \rots{say} & \rots{establish} & \rots{prove} & \rots{suggest} & \rots{demonstrate} & \rots{announce\phantom{l}} & \rots{reveal} & \rots{admit} & \rots{confess} & \rots{think} & \rots{acknowledge} & \rots{pretend} & \rots{see} & \rots{discover} & \rots{hear} & \rots{inform} & \rots{know} & \rots{be annoyed} \\
    \hline
    be right & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    confirm & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    say & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    establish & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    prove & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    suggest & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    demonstrate & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{red} & \cellcolor{red} & \cellcolor{white} & \cellcolor{red} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    announce & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    reveal & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    admit & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    confess & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    think & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    acknowledge & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    pretend & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{red} & \cellcolor{red} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} \\ 
    see & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{red} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} \\ 
    discover & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    hear & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
    inform & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} \\ 
    know & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} \\ 
    \hline
  \end{tabular}}}
  
  \caption{Pairwise differences between expressions, ordered from by increasing mean in Exp.~5 (`asking whether'). White cells indicate that the 95\% HDI of the difference includes 0. Red cells indicate a positive difference (the row expression received a higher rating than the column expression), and blue cells indicate a negative difference.}\label{fig:pairwise2}
\end{figure}
%
% In the results of Exp.~5, several differences are supported by the statistical analysis, where no difference is observed in Exp.~6: (i) \emph{prove} and \emph{suggest} are more at-issue than \emph{reveal}; (ii) \emph{confess}, \emph{think}, and \emph{acknowledge} are more at-issue than \emph{discover} and \emph{hear}; and (iii) \emph{pretend} and \emph{see} are more at-issue than \emph{inform} and \emph{know}. Conversely, Exp.~6 reveals differences not found in Exp.~5, including that: (i) \emph{confirm} and \emph{say} are more at-issue than \emph{establish}; (ii) \emph{pretend} is less at-issue than \emph{discover} and \emph{hear}; and (iii) \emph{see} is less at-issue than \emph{discover}.
% %
% \jt{I don't think all the differences need to be spelled out here; the reader can look for themselves. we should hit the highlights.}





Taken together, Exps.~5 and 6 suggest that the two diagnostics that embed target contents implemented here (`asking whether' and direct-response) yielded highly similar results for the 20 contents investigated, including fine-grained by-predicate differentiation. This supports the idea that presenting the target content in a polar question is what drives the increased by-content differentiation observed in Exps.~2, 5, and 6 compared to Exps.~1, 3, and 4, where the target content was presented in declarative assertions.

Nonetheless, small differences remain, for example in which by-content contrasts reached significance and in the precise rank ordering of contents. Since the two experiments used identical embedding contexts for the target content and both tested property (ii), which has been linked to a QUD-based definition of at-issueness, these differences may stem from the response tasks used: judging what a question is about (Exp.~5) versus evaluating the naturalness of a response (Exp.~6). This suggests that response task differences can affect at-issueness judgments in subtle ways.


\section{General discussion \label{sec:4_discussion}}

This paper reported the results of six experiments designed to investigate whether at-issueness  diagnostics yield consistent results when applied to the same target contents. Exps.~1--4 show that, as implemented, the diagnostics do not converge, suggesting that they are not interchangeable.

Taken together, the experiments provide converging evidence that presenting the target content in a polar question yields greater by-content differentiation than presenting it in an assertion: When target contents were presented in a polar question, as in the `asking whether' diagnostic (Exps.~2, 5) and the direct-response diagnostic (Exp.~6), we observed high by-content differentiation, reproducing fine-grained differences reported in prior work. In contrast, when the same contents were presented in an assertion, as in the QUD diagnostic (Exp.~1) and the dissent-based diagnostics (Exps.~3-4), the resulting ratings showed less differentiation. An implication is that clause type and the illocutionary force of the utterance in which the target content is presented needs to be taken into consideration, when interpreting outcomes of at-issueness diagnostics.

Beyond this main result, we observed additional differences between diagnostics that are specific to particular tested contents. First, diagnostics varied in whether they detected positional effects for appositive NRRCs, and even in the direction of such effects (\Cref{ssub:appositives}). This was the case for our dissent-based diagnostics (Exps.~3--4) and \citetpos{syrett_experimental_2015} study, despite their shared reliance on the underlying assumptions that at-issue content cannot be directly dissented with (property (iii)). The studies differ in the choice or implementation of the response tasks, suggesting that relatively small design choices, such as the alternatives in a forced-choice continuation task, can affect results.

Second, the complement of \emph{be right} ranked low under the QUD diagnostic (Exp.~1) despite coming out as the most at-issue content in all other experiments (\Cref{ssub:be-right}). We argued that this reflects an interaction between the QUD diagnostic and the discourse presuppositions of \emph{be right}, rather than a systematic difference in at-issueness.

A methodological implication of these diagnostic differences is that they cannot be treated as interchangeable. Theoretical claims based on one diagnostic should therefore be relativized to the diagnostic used (see also \citealt{snider_anaphoric_2017,snider_at-issueness_2017,snider_distinguishing_2018,koev_notions_2018,korotkova_evidential_2020}). Therefore, empirical investigations should carefully consider that results may depend on whether the target content was presented in an assertion or polar question, contextual requirements of the expressions used, or the particular task design.

The remainder of this section discusses further implications of our findings, offering discussion on the role of question embedding for diagnosing at-issueness (\Cref{ssec:discussion-questions}), and on what the observed differences might imply for the question of whether there are distinct underlying phenomena associated with the notions of QUD at-issueness and proposal at-issueness (\Cref{ssec:discussion-differences}).


\subsection{Speech act, at-issueness, and commitment \label{ssec:discussion-questions}}

We suggest that the lower by-content differentiation observed in diagnostics that embed target content in assertions, compared to polar questions, may reflect a ceiling effect in assertion-based diagnostics. We hypothesize that this could result from how the illocutionary force of assertions relates propositional content to speaker commitment in different ways: in assertions, but not in questions, the speaker commits to the truth of the at-issue main clause content.

To consider the argument in detail, we begin by noting that at-issue content and not-at-issue content contributed by polar questions differ in their relationship to speaker commitments. The at-issue contribution of a polar question such as \Next determines the set of question alternatives, without committing the speaker to any of the alternatives \Next[a].

\ex. \emph{Is Greg, who bought a car, envied by his neighbor?} \label{ex:greg-question}
    \a. At-issue contribution: determining the question alternatives: \\
    $\{\textnormal{Greg, who bought a car, is envied by his neighbor},$\\
    \phantom. \hfill$\textnormal{Greg, who bought a car, is not envied by his neighbor}\}$\\
    $\not\Rightarrow$ \emph{Greg is envied by his neighbor.} \smallskip
    \b. $\Rightarrow$ \emph{Greg bought a car.} \hfill (not-at-issue content)
    \z. \z. 

In contrast, the not-at-issue NRRC content \Last[b] is assumed to be true across all question alternatives, and thus throughout the entire context set, giving rise to projection \citep{abusch_presupposition_2010,simons_what_2010,abrusan_predicting_2011,tonhauser_how_2018,degen_projection_2025}. As a result, the projective not-at-issue content and the at-issue main clause content differ in their \emph{epistemic status} relative to the speaker commitments: Because the not-at-issue proposition projects, it is treated as part of the speaker's commitments, while the at-issue main clause content is not.

In assertions, the contrast between the epistemic status of not-at-issue content and the at-issue main-clause content is weakened. An assertion the proposes to add the at-issue main clause content the common ground, and also commits the speaker to its truth (\citealt{gunlogson_true_2001}). For instance, the at-issue contribution in \Next, commits the speaker to the main clause content \Next[a]. In addition, the assertion in \Next comes with speaker commitment to the not-at-issue NRRC content \Next[b] as well.

\ex. \emph{Greg, who bought a car, is envied by his neighbor.} \label{ex:greg-assertion}
  \a. $\Rightarrow$ \emph{Greg is envied by his neighbor.} \hfill (at-issue main clause content)
  \b. $\Rightarrow$ \emph{Greg bought a car.} \hfill (not-at-issue content)
  \z.\z.


We suggest that because the at-issue main clause content and not-at-issue content have the same epistemic status in assertions relative to speaker commitments, the two types of content are harder to distinguish for participants. 
%
This reasoning helps explain why the two question-based diagnostics yielded highly similar results. Both the asking whether diagnostic used in Exps.~2 and 5 and the direct-response diagnostic used in Exp.~6 embed the target content $p$ in a polar question, as in \Next, where the target content is \Next[a], and the utterance signals that speaker is committed to the main clause at-issue content \Next[b].

\ex. \emph{Helen confirmed that Tony had a drink last night.} \label{ex:helen-assertion} 
  \a. $\textsf{p}:$ \emph{Tony had a drink last night} \hfill (target content)
  \b. $\textsf{q}:$ \emph{Helen confirmed} \textsf{p} \hfill (main-clause content)
  \z.\z.

Now, if \Last[a] (\textsf{p}) is interpreted as more at-issue, then participants will give responses that are consistent with this more at-issue interpretation. If \textsf{p} is interpreted as less at-issue, construe \textsf{q} as the primary at-issue contribution. In this case, asserting $\textsf{q}:$ \emph{Helen confirmed} \textsf{p} also leads the speaker to commit to the target content \textsf{p}. As a result, the supposed not-at-issue content \textsf{p} would be similar in its epistemic status to the at-issue main clause content \textsf{p}, because the speaker is committed to both, which could make them harder to distinguish. The epistemic status of the at-issue main clause content and not-at-issue content is therefore highly similar in assertions.

We suggest that this similarity makes the two types of content harder to distinguish in assertion-based diagnostics. This would lead to not-at-issue content being rated more similarly to at-issue content, giving rise to overall higher ratings for not-at-issue content and reduced differentiation across contents, essentially creating a ceiling effect.

For diagnostics that embed target content in polar questions, the distinct epistemic status between not-at-issue content and the at-issue main clause content avoids this difficulty in differentiation. \lh{We could also look at response times across experiments to look for support for this hypothesis.} For example, for the polar question embedding in \Next, the target content is \Next[a].

\ex. \emph{Did Helen confirm that \underline{Tony had a drink last night}?} \label{ex:helen-question}
    \a. $\textsf{p}:$ \emph{Tony had a drink last night} \hfill (target content)
    \b. $\textsf{q}:$ \emph{Helen confirmed \textsf{p}} \hfill (main-clause content)
    \z. \z. 

Here, if \Last[a] (\textsf{p}) is interpreted as more at-issue, then participants will interpret the question as being (more) about whether \textsf{p}. If \textsf{p} is interpreted as less at-issue, participants will interpret the question as being (more) about whether \textsf{q}. In that case, \textsf{p} is likely to project, leading to speaker commitment. However, since the main clause content of the question (about whether \textsf{p}) does not come with speaker commitment, the at-issue main clause content and the not-at-issue content differ in their epistemic status. 

% An important question for research on at-issueness is why certain expressions lead to their associated content being interpreted as more or less at-issue, which lexical properties can affect this and how (e.g., \citealt{abrusan_predicting_2011,anand_factivity_2014,schlenker_triggering_2021,anand_facts_2024,bade_new_2024,bade_word_2024}).

In sum, the differences in by-content variation between diagnostics that embed contents in polar questions versus assertions can be understood as a result of how the illocutionary force of assertions and polar questions interacts with a further property of at-issue content, namely that the speaker is overall more likely to be committed to not-at-issue content. This will be the case either by entailment (like when the embedded content in (\pref{ex:greg-assertion}+\pref{ex:helen-assertion}) is not-at-issue), or by projection from entailment-cancelling environments like polar questions (like when the embedded content in (\pref{ex:greg-question}+\pref{ex:helen-question}) is not-at-issue).

To our knowledge, no previous literature has proposed that the speech act in which target content is presented can itself be a major driver (or inhibitor) of differentiation. Here, we saw that polar questions more transparently reveal how different contents can be interpreted as at-issue or not-at-issue, and suggested that this may be because the two contents differ in their epistemic status. Assertions, in contrast, commit the speaker both to the at-issue assertion and the not-at-issue content, thereby obscuring the distinction. Consequently, diagnostics that embed the target content in questions provide a particularly sensitive test of at-issueness. Embedding target content in questions therefore allows for detection of more fine-grained differences in at-issueness associated with the conventional meaning of particular expressions, whereas assertions introduce a confounding factor: the speaker commits to both types of content, reducing differentiation in at-issueness judgments.

\begin{itemize}
  \item \jt{the paragraph around 12 is about a sentence-medial NRRC, which is maximally different in terms of at-issueness and speaker commitment from the at-issue content, which is at-issue and the speaker is not committed. you suggested above that speaker commitment is relevant. so when we have content that is not as clearly not-at-issue as sentence-medial NRRCs, like the CC of ``discover'' or of ``reveal'', why does embedding in questions help bring out differences between them? i don't see how the example in 12 helps explain this, or something is missing}

  \lh{It's less that question embeddings help to bring out the differences, but more that assertions obscure the differences. I hope that's clearer now.}

  \item \jt{does this imply that embedding under negation should also not work so well (commitment to negated at-issue content) but embedding under ``perhaps'' (or another epistemic modal) should? don't we have experiments like Exp 6 but with embedding under ``perhaps'' and with embedding under negation?}
  
  \lh{It shouldn't, but I hadn't really considered AI content in various non-veridical environments when I wrote the first draft. In the current version, it should become clearer that I am talking about AI main clause content. In assertions with negation or "perhaps", there is still at least the main clause content that the speaker is committed to.}

\end{itemize}


\subsection{Diagnostic differences and notions of at-issueness \label{ssec:discussion-differences}}

Because the diagnostics are grounded in distinct assumptions about what it means for content to be at-issue, the observed differences between diagnostics also bear on the broader question of whether existing diagnostics track a common underlying notion of at-issueness or operationalize distinct phenomena. While many of the diagnostic differences in our data find plausible explanations in methodological and contextual factors, we found no obvious empirical split between QUD-at-issueness and proposal at-issueness. This section considers what our results suggest for this issue.

As reviewed in \Cref{sec:1_introduction}, diagnostics differ both in the properties they target and in the theoretical notions they are taken to diagnose. Recall the definitions of QUD at-issueness and proposal at-issueness, repeated here:

\ex.[\ref{def:qai}]%
QUD at-issueness: \hfill (based on \citealt{simons_what_2010}, p. 323)\\
A content $m$ is at-issue in a context $c$ iff
\a. \label{def:qai-relevant}%
$m$ is relevant\footnotemark\ to the QUD in $c$, and
\b.  \label{def:qai-conventional}%
% $m$ is appropriately conventionally marked relative to the QUD.
the speaker has a recognizable intention to address the QUD via $m$.
\z. 
\z.

\ex.[\ref{def:pai}] Proposal at-issueness: \hfill (\citealt{koev_apposition_2013}, pp. 50--51)\\
A proposition $p$ is at-issue in a context $c$ iff
\a. $p$ is a proposal in $c$ and
\b. $p$ has not been accepted or rejected in $c$.
\z.
\z.

Table~\ref{tab:diagnostics-notions} summarizes how the four diagnostics from Exps.~1--4 have been mapped onto these notions in the literature. Three broad positions can be distinguished. On one view, all diagnostics ultimately target a single underlying phenomenon (\citealt{tonhauser_diagnosing_2012,anderbois_at-issue_2015,faller_discourse_2019}), so any empirical differences must be attributed to independent factors. A second view holds that some diagnostics track QUD at-issueness while others track anaphoric availability (\citealt{snider_at-issueness_2017,snider_anaphoric_2017,snider_distinguishing_2018,korotkova_evidential_2020}), predicting systematic differences between diagnostics that involve propositional anaphora and those that do not. A third view posits genuinely distinct notions, such as QUD at-issueness and proposal at-issueness (\citealt{koev_notions_2018}), which predicts that at least some diagnostic differences reflect this theoretical divide.

\begin{table}[ht]
\centering
\resizebox{\linewidth}{!}{
  \begin{tabular}{l p{3.1cm} p{3.4cm} p{3.2cm} p{2cm}}
\toprule
 Diagnostic & \multirow{2}{*}{\parbox{3cm}{Property targeted by diagnostic}} & \multicolumn{3}{l}{Underlying notion assumed to correspond to property} \\
\cmidrule(lr){3-5}
  & & \small Uniform at-issueness
  & \small Anaphoric availability
  & Dual-notion\\ 

 & & \scriptsize \citealt{tonhauser_diagnosing_2012},\newline \citealt{anderbois_at-issue_2015},\newline \citealt{faller_discourse_2019}
 & \scriptsize \citealt{snider_at-issueness_2017},\newline \citealt{korotkova_evidential_2020}
 & \scriptsize \citealt{koev_notions_2018} \\
\midrule

\multirow{2}{*}{QUD diagnostic}
 & \multirow{2}{*}{(i) addressing QUD}
 & \multirow{7}{*}{\parbox{3.2cm}{\centering QUD at-issueness}}
 & \multirow{4}{*}{\parbox{2.3cm}{\centering QUD\\ at-issueness}}
 & \multirow{2}{*}{\parbox{1.9cm}{\centering QUD\\ at-issueness}}\\ 
 \\ \cmidrule(lr){1-2}\cmidrule(lr){5-5}

\multirow{2}{*}{Asking whether}
 & (ii) determining \newline \phantom{(ii) }alternatives
 & 
 & 
 & \multirow{2}{*}{\parbox{1.9cm}{\centering --}} \\
 \cmidrule(lr){1-2}\cmidrule(lr){4-5}

Direct dissent
 & \multirow{2.5}{*}{\parbox{4cm}{(iii) direct dissent/\newline \phantom{(iii) }assent}}
 & 
 & \multirow{2.5}{*}{\parbox{2.3cm}{\centering Anaphoric\\ availability}}
 & \multirow{2.5}{*}{\parbox{1.9cm}{\centering Proposal\\ at-issueness}} \\
\cmidrule(lr){1-1}

`Yes, but'
 & 
 & 
 & 
 &  \\
\bottomrule
\end{tabular}}
\caption{Mapping between at-issueness diagnostics, the properties they target \citep{tonhauser_diagnosing_2012}, and the underlying theoretical notions assumed in different theoretical approaches.}
\label{tab:diagnostics-notions}
\end{table}

Under the view that assumes a uniform notion of at-issueness (\citealt{tonhauser_diagnosing_2012,anderbois_at-issue_2015,faller_discourse_2019}), all diagnostics target the same underlying notion of at-issueness and all diagnostic differences would have to be explained by factors independent of at-issueness. The anaphoric availability view (\citealt{snider_at-issueness_2017,snider_at-issueness_2017,snider_distinguishing_2018,korotkova_evidential_2020}) assumes that some diagnostics targeting properties (i) and (ii) genuinely target QUD at-issueness and diagnostics targeting property (iii) diagnose anaphoric availability. This predicts systematic differences between diagnostics that do and do not involve propositional anaphora. Under the dual-notion position (\citealt{koev_notions_2018}), which assumes separate underlying phenomena associated with the two notions defined above, at least some diagnostic differences should be explained by the distinction. Here, we consider our main findings in light of these positions.

First, the contrast that aligns with the clearest difference between diagnostics we found -- whether target contents are presented in polar questions versus assertions -- may appear related to the distinction between QUD-based and proposal-based definitions of at-issueness, since both involve a question versus assertion contrast. However, as discussed in \Cref{ssub:differentiation}, this pattern is not predicted by the differences in the underlying notions targeted by the diagnostics that have been proposed in the literature. The dual-notion view could only provide an explanation for differences between diagnostics targeting property (i) (the QUD diagnostic) and those targeting property (iii) (direct dissent and `yes, but'). The anaphoric-availability view would be supported by differences between diagnostics targeting properties (i) or (ii)\footnote{The status of the direct-response diagnostic further complicates the picture. It targets property (ii), which Snider aligns with QUD-based at-issueness, but it also involves the response particle yes, which has been argued to diagnose anaphoric availability in property (iii) diagnostics. It is therefore unclear how this diagnostic should be classified under the anaphoric-availability view.} such as the QUD diagnostic and `asking whether' and those targeting property (iii). Our main contrast, however, cuts across these groupings. Although the main diagnostic difference is not straightforwardly predicted by either the dual-notion view or the anaphoric-availability view, it remains in principle compatible with all three positions.

Second, the diagnostics differ in how they interact with contextual requirements imposed by particular expressions. A clear example is the behavior of \emph{be right} under the QUD diagnostic, where low QUD-match ratings do not plausibly reflect not-at-issueness, but instead arise from a pragmatic incompatibility: \emph{be right} presupposes a discourse structure that conflicts with the assumptions made by the diagnostic (see Section~\ref{ssub:be-right}). A related concern is raised by \citet{snider_at-issueness_2017,snider_distinguishing_2018}, who emphasized that the direct-dissent and `yes but' diagnostic involve propositional anaphora in the interpretation in the response particles \emph{yes/no} (as does the direct-response diagnostic in Exp.~6). Ratings under these diagnostics may therefore reflect constraints on anaphoric availability that are independent of at-issueness. Although our data show no clear split between diagnostics that involve response particles (Exps.~3, 4, and 6) and those that do not, the broader point remains: different diagnostics impose different requirements on discourse structure, common ground, and anaphoric accessibility, all of which can independently affect acceptability judgments. This supports the conclusion that some differences between diagnostics arise from interactions with expression-specific contextual requirements rather than from differences in at-issueness per se.

Third, some small differences between diagnostics can be attributed to response-task effects. This is evident in the subtle differences between Exps.~5 and 6 (see \Cref{ssec:5-6-discussion}), which differed only in response format, and in our failure to replicate \citeposs{syrett_experimental_2015} \citeyear{syrett_experimental_2015} reported positional effect for appositive NRRCs (see \cref{ssub:appositives}). While they found sentence-final appositives to be more at-issue than sentence-medial ones under a version of the direct-dissent diagnostic, our assent/dissent-based \emph{yes, but} diagnostic in Exp.~4 showed a difference in the opposite direction, while the other experiments found no difference between them (Exp.1--3). Taken together, these results provide no evidence for a stable notion of at-issueness under which sentence-final appositives are systematically more at-issue than medial ones (or the other way round), and they highlight how even small task differences can affect outcomes.
% \jt{does this paragraph argue that response task effects don't point to different underlying notions of at-issueness? or does it go off track and argue that sentence-medial vs -final NRRCs may not differ in at-issueness?}

At the same time, among most pairs from Exps.~1--4, the Spearman rank correlation was at least moderate (when excluding \emph{be right}, see \cref{fn:w-o-be-right}), suggesting some convergence among diagnostics, and that the diagnostics, as implemented there, are at least partially sensitive to a shared underlying property.

Our data does not provide conclusive evidence about whether or not the diagnostics track fundamentally different underlying notions of at-issueness. However, the fact that many of the differences find explanations outside this question, seems more compatible with assuming that the diagnostics offer different, partially overlapping windows onto a single discourse phenomenon, that interacts with multiple discourse factors (speaker commitments, speech acts, contextual requirements, and the given alternatives) in complex and sometimes subtle ways, so that even small differences in task design can make a difference.


\section{Conclusion \label{sec:5_conclusion}}

In a series of six experiments, this study investigated how different diagnostics for at-issueness behave when applied to the same linguistic stimuli, using five different diagnostics: the QUD diagnostic, the `asking whether' diagnostic, the direct-dissent diagnostic, the `yes, but' diagnostic, and the direct-response diagnostic. Our findings provide experimental confirmation for claims that there are empirical differences between at-issueness diagnostics (\citealt{snider_anaphoric_2017,snider_at-issueness_2017,snider_distinguishing_2018,koev_notions_2018,faller_discourse_2019,korotkova_evidential_2020}). The diagnostics yielded different results, with some diagnostics showing greater differentiation among contents than others. The main finding was embedding the target content in questions leads to greater differentiation among contents than embedding it in assertions. We suggested that this finding highlights the need to consider the speech act context when interpreting results from at-issueness diagnostics. An important question for future work remains open: what the results of different diagnostics might reveal about whether or not they reflect a shared underlying notion of at-issueness.

\pagebreak

\section*{Data accessibility statement}
The experiments, data and R code for generating the figures and analyses of the experiments reported in this paper are available at \url{https://anonymous.4open.science/r/at-issueness-diagnostics-232C/}.

\section*{Ethics and consent}
All experiments were conducted with approval from the ethics review committee of [university name redacted for review].


% \section*{Funding information (if applicable)}
%   We gratefully acknowledge the National Science Foundation grant BCS #1452674 (to Marie-Catherine de Marneffe,
% Craige Roberts, and Judith Tonhauser), which provided financial support for the data collection in Exps.~5 and 6.

% \section*{Acknowledgements (optional)}
%   We thank Taylor Mahler for assistance in collecting the data in Exps.~5 and 6 as well as valuable comments. 

% \section*{Competing interests}
%   The authors declare that they have no competing interests.



% \nocite{*} %this is to get all the entries of the sample bibliography; delete this line for an actual Glossa submission
%\printbibliography %for use with biblatex; comment out if you use natbib
\bibliography{at-issueness} %for use with natbib; comment out if you use biblatex, and change 'sample' by the name of your bib-file

%TC:ignore
\appendix

\setcounter{table}{0}
\renewcommand{\thetable}{A\arabic{table}}

\setcounter{figure}{0}
\renewcommand{\thefigure}{A\arabic{figure}}

\setcounter{ExNo}{0}


\section*{Supplements}

\section{Control stimuli in Exps.~1--4}\label{supp:stims}

The examples in \ref{control1}-\ref{control4} provide the two control stimuli used in each of Exps.~1-4. For the a.-examples, participants were expected to give a `totally fits' response (Exp.~1), a `yes' response (Exp.~2), a `totally natural' response (Exp.~3), and a `no' response (Exp.~4); for the b.-examples, the opposite response was expected. The numbers  after each example identify the mean ratings (Exps.~1-3) or the proportion of `no' responses (Exp.~4) after excluding participants who did not self-identify as native speakers of American English (but before excluding participants on the basis of these controls), showing that the control stimuli worked as intended.

\ex.\label{control1} Control stimuli in Exp.~1 (QUD diagnostic)
\a. Mary: Which course did Ava take?
\\ John: She took the French course. (.97)
\b. Jennifer: What does Betsy have?
\\ Robert: She loves dancing salsa. (.07)

\ex.\label{control2} Control stimuli in Exp.~2 (`asking whether' diagnostic)
\a. Mary: Did Arthur take a French course?
\\ Question to participants: Is Mary asking whether Arthur took a French course? (.96)
\b. Robert: Does Betsy have a cat?
\\ Question to participants: Is Robert asking whether Betsy loves apples? (.02)

\ex.\label{control3} Control stimuli in Exp.~3 (`direct dissent' diagnostic)
\a. Mary: Arthur took a French course.
\\ Lily: No, he took a Spanish course. (.87)
\b. Robert: Betsy has a cat.
\\ Maximilian: No, she doesn't like apples. (.05)

\ex.\label{control4} Control stimuli in Exp.~4 (`yes, but' diagnostic)
\a. Mary: Arthur took a French course.
\\ Lily: Yes, but Lisa loves cats. / Yes, and he didn't take a French course. / No, he didn't take a French course. (.95)
\b. Robert: Betsy has a cat.
\\ Maximilian: Yes, but she is good at math. / Yes, and she loves it so much. / No, she doesn't like apples. (0)

\section{20 clauses}\label{supp:a-clauses}
The contents of the following 20 clauses, which realized the complements of the 20 clause-embedding predicates, were investigated in Exps.~5--6:

\begin{multicols}{2}
  \begin{enumerate}%[leftmargin=3ex,itemsep=-2pt]
    \item Mary is pregnant.
    \item Josie went on vacation to France.
    \item Emma studied on Saturday morning.
    \item Olivia sleeps until noon.
    \item Sophia got a tattoo.
    \item Mia drank 2 cocktails last night.
    \item Isabella ate a steak on Sunday.
    \item Emily bought a car yesterday.
    \item Grace visited her sister.
    \item Zoe calculated the tip.
    
    %\columnbrea      
    \item  Danny ate the last cupcake.
    \item  Frank got a cat.
    \item  Jackson ran 10 miles.
    \item  Jayden rented a car.
    \item  Tony had a drink last night.
    \item  Josh learned to ride a bike yesterday.
    \item  Owen shoveled snow last winter.
    \item  Julian dances salsa.
    \item  Jon walks to work.
    \item  Charley speaks Spanish.
    
  \end{enumerate}
\end{multicols}

\section{Control stimuli in Exps.~5--6}\label{supp:control56}
The control stimuli in Exps.~5--6 were the contents of the main clause polar questions in \Next. The non-restrictive relative clauses (NRRCs), given in parentheses in \Next, were included in Exp.~6, where at-issueness was measured with an assent diagnostic. The control stimuli here consisted of two clauses (like the target stimuli), to allow the relevant speaker to assent with one of two clauses.

\ex. Sentences for control stimuli in in question embedding experiments (Exps.~5--6)
\a. Do these muffins (, which are really delicious,) have blueberries in them?
\b. Does this pizza (, which I just made from scratch,) have mushrooms on it? 
\b. Was Jack (, who is my long-time neighbor,) playing outside with the kids? 
\b. Does Ann (, who is a local performer,) dance ballet?
\b. Were John's kids (, who are very well-behaved,) in the garage?
\b. Does Samantha (, who is really into fashion,) have a new hat?
\z.
\z.

We expected participants to give low responses on the at-issueness diagnostics for the control stimuli in \Last, indicating that the main clause content is at-issue.

%TC:endignore
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% TeX-engine: luatex
%%% End:
