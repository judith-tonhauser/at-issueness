% !TEX TS-program = lualatexmk
% glossa-template.tex
% Copyright 2016 Guido Vanden Wyngaerd
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
% 
% The Current Maintainer of this work is 
% Guido Vanden Wyngaerd (guido.vandenwyngaerd@kuleuven.be).
%
% This work consists of the files 
% glossa.cls
% glossa.bst
% gl-authoryear-comp.cbx
% biblatex-gl.bbx
% glossa-template.tex
% glossa.png
%
% The files of the work are derived from the Semantics & Pragmatics style files
% by Kai von Fintel, Christopher Potts, and Chung-chieh Shan
% All changes are documented on the github repository 
% https://github.com/guidovw/Glossalatex.

\documentclass[times,linguex]{glossa}
% possible options:
% [times] for Times font (default if no option is chosen)
% [cm] for Computer Modern font
% [lucida] for Lucida font (not freely available)
% [brill] open type font, freely downloadable for non-commercial use from http://www.brill.com/about/brill-fonts; requires xetex
% [charis] for CharisSIL font, freely downloadable from http://software.sil.org/charis/
% for the Brill an CharisSIL fonts, you have to use the XeLatex typesetting engine (not pdfLatex)
% for headings, tables, captions, etc., Fira Sans is used: https://www.fontsquirrel.com/fonts/fira-sans
% [biblatex] for using biblatex (the default is natbib, do not load the natbib package in this file, it is loaded automatically via the document class glossa.cls)
% [linguex] loads the linguex example package
% !! a note on the use of linguex: in glossed examples, the third line of the example (the translation) needs to be prefixed with \glt. This is to allow a first line with the name of the language and the source of the example. See example (2) in the text for an illustration.
% !! a note on the use of bibtex: for PhD dissertations to typeset correctly in the references list, the Address field needs to contain the city (for US cities in the format "Santa Cruz, CA")

%\addbibresource{sample.bib}
% the above line is for use with biblatex
% replace this by the name of your bib-file (extension .bib is required)
% comment out if you use natbib/bibtex

\let\B\relax %to resolve a conflict in the definition of these commands between xyling and xunicode (the latter called by fontspec, called by charis)
\let\T\relax
\usepackage{xyling} %for trees; the use of xyling with the CharisSIL font produces poor results in the branches. This problem does not arise with the packages qtree or forest.
\usepackage[linguistics]{forest} %for nice trees!

% \pdf* commands provide metadata for the PDF output. ASCII characters only!
\pdfauthor{}
\pdftitle{What is at-issueness?}
\pdfkeywords{}

\title[What is at-issueness?]{What is at-issueness? An experimental comparison of diagnostics\\ 
  % \bigskip \large Word count: 4720
  }
% Optional short title inside square brackets, for the running headers.

\author[]% short form of the author names for the running header. If no short author is given, no authors print in the headers.
{%as many authors as you like, each separated by \AND.
  % \spauthor{Waltraud Paul\\
  % \institute{CRLAO, CNRS-EHESS-INALCO}\\
  % \small{%105, Bd. Raspail, 75005 Paris\\
  % waltraud.paul@ehess.fr}
  % }
  % \AND
  % \spauthor{Guido Vanden Wyngaerd \\
  % \institute{KU Leuven}\\
  % \small{%Warmoesberg 26, 1000 Brussel\\
  % guido.vandenwyngaerd@kuleuven.be}
  % }%
}

\input{author-added}

\begin{document}


\maketitle


\begin{abstract}
  At-issueness is a key concept in theoretical semantics/pragmatics, but there is no consensus about how it is defined or diagnosed (e.g., \citealt{tonhauser_diagnosing_2012,tonhauser_how_2018,koev_notions_2018}). We present experimental data investigating whether four widely used diagnostics for at-issueness yield consistent results. Our findings reveal significant differences across diagnostics, indicating they are not interchangeable. Since the diagnostics target distinct theoretical conceptions of at-issueness, these differences offer insight into their comparability.

\end{abstract}

% \begin{keywords}
%   at-issueness, experimental pragmatics, discourse interpretation
% \end{keywords}

\section{Introduction \label{sec:1_introduction}}
  At-issueness is a key concept in theoretical semantics and pragmatics, distinguishing between at-issue propositions conveyed by an utterance, those contributing to its main point, and those that do not (e.g., \citealt{karttunen_conventional_1979,horton_presuppositions_1988,abbott_presuppositions_2000,faller_semantics_2003,potts_logic_2005,tonhauser_diagnosing_2012}). Despite its importance, the concept lacks a unified definition. Instead, various theoretical notions (\citealt{koev_notions_2018,tonhauser_how_2018}) and empirical diagnostics (e.g., \citealt{tonhauser_diagnosing_2012}) have been proposed. This paper addresses the question whether four widely used diagnostics for at-issueness yield consistent results when testing the same stimuli. Our findings reveal significant differences across diagnostics, indicating they are not interchangeable. Since the diagnostics target distinct theoretical conceptions of at-issueness, these differences offer insight into their comparability.

  % Do the results support the notion that different theoretical conceptions of at-issueness are distinct?

  The four diagnostics we tested are illustrated in (\pref{qud}--\pref{yesbut}) for sentence-medial non-restrictive relative clauses (NRRCs), which are usually taken to contribute non-at-issue content.  As appositive content is generally taken to be not-at-issue, participants are expected to: Give low naturalness ratings under the QUD diagnostic \ref{qud} and the direct dissent diagnostic \ref{dd}, not interpret the speaker to be asking about the content under the `asking-whether' diagnostic in \ref{aw}, will choose one of the \emph{yes}-responses under the `yes, but' diagnostic in \ref{yesbut}.

  \ex. \label{qud}%
    QUD diagnostic (e.g., \citealt{tonhauser_diagnosing_2012,chen_presuppositions_2024})
    \a.[A:] \emph{What did Greg buy?}
    \b.[B:] \emph{Greg, who bought a new car, is envied by his neighbor.}
    \z.
    Question to participants: How well does B's response fit A's question?
  \z.

  \ex. \label{aw}%
    `asking whether' diagnostic (e.g., \citealt{tonhauser_how_2018,solstad_cataphoric_2024})\smallskip\\
      \emph{Is Greg, who bought a new car, envied by his neighbor?}\smallskip
  \\ Question to participants: Is the speaker asking whether Greg bought a new car?
  \z.

  \ex. \label{dd} Direct dissent diagnostic (e.g., \citealt{tonhauser_diagnosing_2012,syrett_experimental_2015})
    \a.[A:] \emph{Greg, who bought a new car, is envied by his neighbor.}
    \b.[B:]\emph{No, that's not true, he didn't buy a new car.}
    \z.
  Question to participants: How natural is B's rejection of A's utterance?
  \z.

  \ex. \label{yesbut}%
    `yes, but' diagnostic (e.g., \citealt{xue_correlation_2011,destruel_cross-linguistic_2015})
    \a.[A:] \emph{Greg, who bought a new car, is envied by his neighbor.}
    \b.[B:] \emph{Yes, but he didn't buy a new car.} /
    \b.[] \emph{Yes, and he didn't buy a new car.} /
    \b.[] \emph{No, he didn't buy a new car.}
    \z.
    Task for participants: Choose the response that sounds best.
  \z.

  The diagnostics reflect different theoretical conceptions of at-issueness (\citealt{koev_notions_2018}), and they have led to different empirical results, discussed below.


  \subsection{QUD-based diagnostics}
    The diagnostics in \ref{qud} and \ref{aw} are based on the assumption that discourse is organized around addressing a question under discussion (QUD) (\citealt{roberts_information_1996,ginzburg_interrogatives_1996}), and that the at-issue content of an utterance addresses a QUD that is established by the preceding discourse (\citealt{amaral_review_2007})\footnote{is this the right reference?}. This notion, defined explicitly in \citealt{simons_what_2010}, is labeled Q(uestion)-at-issueness in \citepos{koev_notions_2018} overview:

    \ex. \label{def:qai}%
      Q-at-issueness: \hfill (based on \citealt{simons_what_2010}: 26, \citealt{koev_notions_2018}: 2)\\
      A content $m$ is Q-at-issue in a context $c$ iff
      \a. \label{def:qai-relevant}%
        $m$ is relevant to the QUD in $c$, and
      \b.  \label{def:qai-conventional}%
        $p$ is appropriately conventionally marked relative to the QUD.
      \z. 
    \z.

    Here, $m$ may be either a propositional content or a question meaning. Relevance to the QUD is defined as follows:

    \ex. Relevance to the QUD in context $c$ \hfill (based on \citealt{simons_what_2010}: 13)
      \a. A proposition $p$ is relevant the QUD iff it contextually entails in $c$ a partial or complete answer to the QUD.
      \b. A question $q$ is relevant to the QUD, iff it has an answer that is relevant to the QUD.
      \z.
    \z.

    \subsubsection{QUD-diagnostic}
    The QUD-diagnostic from \citealt{tonhauser_diagnosing_2012} operationalizes Q-at-issueness through naturalness judgments. It builds on two assumptions:
    \begin{enumerate}
      \item An overt question explicitly introduces a QUD.\footnote{add reference}
      \item An utterance is felicitous only if its at-issue content is relevant to the QUD (\citealt{amaral_review_2007,tonhauser_diagnosing_2012}).
    \end{enumerate}

    \noindent To test whether a given content $m$ can be construed as Q-at-issue, participants are presented with a context that establishes a QUD via an overt question, followed by a response that includes $m$. For instance, \ref{qud} is used to diagnose the status of the content $m$ of the appositive RC (Greg bought a car) conveyed by B's utterance $U$, by presenting it as a response to a question $Q$ that $m$ is relevant to (What did Greg buy?), and asking a naturalness rating for $U$ as a response to $Q$.

    \ex.[\ref{qud}]
      \a.[A:] \emph{What did Greg buy?}
      \b.[B:] \emph{Greg, who bought a new car, is envied by his neighbor.}
      \z.
      Question to participants: How well does B's response fit A's question?
    \z.

    If $m$ (Greg bought a car) is interpreted as addressing the QUD, the response should receive high naturalness ratings. However, responses like (\pref{qud}B) typically receive low ratings, suggesting that $m$ is not at-issue, that is, even though $m$ is relevant to $Q$ and thereby satisfies the first part of the definition in \ref{def:qai-relevant}. The low naturalness should, therefore, reflect that $m$ is not-at-issue due to the second part of the definition in \ref{def:qai-conventional}: The low ratings for (\pref{qud}B) support the claim that appositive RCs are not appropriately conventionally marked to contribute at-issue content.
    

    \subsubsection{Asking whether}
    Because the definition in \ref{def:qai} references the preceding context, \citet{koev_notions_2018} suggests that QUD-at-issueness is a backward-looking notion of at-issueness. However, overt questions may explicitly raise a QUD\footnote{add reference}, and thereby make a content Q-at-issue in the subsequent discourse. This is what is targeted by the `asking whether' diagnostic in \ref{aw} (\citealt{tonhauser_how_2018}), based on the assumption that it is the at-issue content of interrogatives that partitions the context set, as opposed to their non-at-issue content (p.502).

    \ex.[\ref{aw}]%
        \emph{Is Greg, who bought a new car, envied by his neighbor?}\smallskip
    \\ Question to participants: Is the speaker asking whether Greg bought a new car?
    \z.

    explain explain
    If participants respond "no," this suggests that the appositive content (Greg bought a new car) is not part of the at-issue content of the interrogative, providing evidence that it is not Q-at-issue. This diagnostic thus complements the QUD-diagnostic by probing the at-issueness of content from the perspective of explicitly raised questions rather than previously established ones.

  \subsection{Proposal at-issueness}
    The direct dissent diagnostic \ref{dd} and the `yes, but' diagnostic \ref{yesbut} reflect the notion of P(roposal)-at-issueness, based on the assumption that at-issue content contributes to the main assertion of an utterance, which is taken to constitute a proposal to update the common ground.

     \ex. P-at-issueness: \hfill (\citealt{koev_apposition_2013,koev_notions_2018})\\
      A proposition $p$ is P-at-issue in a context $c$ iff
      \a. $p$ is a proposal in $c$ and
      \b. $p$ has not been accepted or rejected in $c$.
      \z.
    \z.

    \begin{itemize}
      \item at-issue content is proposed to be added to the common ground, whereas not-at-issue content is imposed on the common ground (e.g., Murray, 2014; AnderBois et al., 2015); on another, at-issue utterance content is (minimally) relevant to the Question Under Discussion of the utterance (e.g., Simons et al., 2010; Beaver et al., 2017)
    \end{itemize}

  \subsubsection{Direct dissent/assent}

  \ex.[\ref{dd}]
    \a.[A:] \emph{Greg, who bought a new car, is envied by his neighbor.}
    \b.[B:]\emph{No, that's not true, he didn't buy a new car.}
    \z.
  Question to participants: How natural is B's rejection of A's utterance?
  \z.

  \subsubsection{yes, but}

  \ex.[\ref{yesbut}]%
    \a.[A:] \emph{Greg, who bought a new car, is envied by his neighbor.}
    \b.[B:] \emph{Yes, but he didn't buy a new car.} /
    \b.[] \emph{Yes, and he didn't buy a new car.} /
    \b.[] \emph{No, he didn't buy a new car.}
    \z.
    Task for participants: Choose the response that sounds best.
  \z.

  \subsection{Previous findings}
    To investigate how consistent the diagnostics are, we conducted four experiments measuring the at-issueness of the same contents across diagnostics. Prior research has identified disagreements, potentially arising from diagnostic differences:

    \subsubsection{Medial appositives}  

    \begin{itemize}
      \item  \citealt{koev_notions_2018}: English medial appositive RCs can be Q-at-issue, but not P-at-issue: they behave as NAI for the direct dissent test, but can address the QUD in the QUD diagnostic (Based on impressionistic judgment data)

      \item An experimental study in \citealt{syrett_experimental_2015} found that sentence-medial appositives are less at-issue than sentence-final ones using the direct dissent test
      
      \item \citealt{drozdov_projection_2024} found no difference with the `asking whether' diagnostic
      
      \item \cite{tonhauser_diagnosing_2012}: Paraguayan Guaraní medial appositive NPs (e.g., \emph{chesy angiru} \lq my mother's friend\rq) behave as NAI according to all tested diagnostics, but yields mixed results with the QUD-diagnostic
    \end{itemize}


    \subsubsection{What else is interesting}

    \begin{itemize}
      \item i think \emph{be right} and \emph{know} are interesting in our data
      \item 
    \end{itemize}
    

    \subsubsection{Lexical gradience}

    \begin{itemize}
       \item experimental data is needed because the pragmatic factors involved in determining at-issueness are complex
       \item lexical influences, potentially understood in terms of lexical variation wrt what is \enquote{appropriately conventionally marked} as possibly at-issue, seem to have gradient effects, see below
     \end{itemize} 

  {\bf JT: \citealt{degen-tonhauser-glossa} will hopefully be accepted soon, we should include something like this figure because prior results but also to motivate the inclusion of be right and confirm in the stimuli of the four experiments}
      
  \begin{figure}[h!]
    \centering

  \includegraphics[width=0.7\textwidth]{../../results/main/degen-tonhauser-glossa/graphs/mean-asking-whether-ratings.pdf}

    \caption{Mean `asking whether' ratings for the contents of the clausal complements of 20 clause-embedding predicates, from \citealt{degen-tonhauser-glossa}.}
    \label{fig:dtglossa}
    \end{figure}

\section{Experiments \label{sec:2_experiments}}

  To compare the results of at-issueness diagnostics, we conducted four experiments that each measured at-issueness with a different diagnostic, namely the QUD diagnostic (Exp.~1), the `asking whether' diagnostic (Exp.~2), the direct dissent diagnostic (Exp.~3) and the `yes, but' diagnostic (Exp.~4).\footnote{The experiments, data and R code for generating the figures and analyses of the experiments reported in this paper are available at INSERT URL TO ANONYMOUS GITHUB REPO BEFORE SUBMISSION. All experiments were conducted with approval from the ethics review committee of [university name redacted for review].} To be able to compare the results of the diagnostics, the same seven contents shown in \ref{stims} were investigated under the four diagnostics: the contents of sentence-medial and sentence-final NRRCs \ref{stims.a}-\ref{stims.b}, as well as the contents of the clausal complements of \emph{know, discover, confess, confirm} and \emph{be right} \ref{stims.c}-\ref{stims.g}. These seven contents were instantiated by the same items across the four experiments.

  \ex.\label{stims}
    \a.\label{stims.a} Content of sentence-medial NRRC \\
      \emph{Lucy, who broke the plate, apologised.} $\leadsto$ Lucy broke the plate
    \b.\label{stims.b} Content of sentence-final NRRC \\
    \emph{The police found Jack, who saw the murder.} $\leadsto$ Jack saw the murder
    \b.\label{stims.c} Content of the clausal complement of \emph{know} \\
    \emph{Ann knows that Raul cheated on his wife.} $\leadsto$ Raul cheated on his wife
    \b.\label{stims.d} Content of the clausal complement of \emph{discover} \\
    \emph{Mary discovered that Denny ate the last cupcake.} $\leadsto$ Denny ate the last cupcake
    \b.\label{stims.e} Content of the clausal complement of \emph{be right} \\
    \emph{Tom is right that Ann stole the money.} $\leadsto$ Ann stole the money
    \b.\label{stims.f} Content of the clausal complement of \emph{confirm} \\
    \emph{Harry confirmed that Greg bought a new car.} $\leadsto$ Greg bought a new car
    \b.\label{stims.g} Content of the clausal complement of \emph{confess}  \\
    \emph{Lucy confessed that Dustin lost his key.} $\leadsto$ Dustin lost his keys
    \z.
  \z.
  
These seven contents were chosen with two considerations in mind. First, several of the contents were investigated in prior literature, which found differences in at-issueness between the contents. This includes the content of sentence-medial and -final NRRCs as well as the content of the complement of \emph{know, discover} and \emph{confess} (e.g., \citealt{syrett_experimental_2015,tonhauser_how_2018}). Second, the contents of the complements of \emph{be right} and \emph{confirm} were included because \citealt{degen-tonhauser-glossa} observed that they 



  In each experiment, participants read the stimuli and gave ratings corresponding to the diagnostics.

  \subsection{Methods}
    
  \subsubsection{Participants}

  For each of the four experiments, we recruited unique 80 participants on Prolific. These participants had registered on the platform as living in the USA and as having English as their primary language. They had at least 50 previous submissions and an approval rate of at least 97\%.  Table \ref{t:recruited} shows the age and gender distributions of the recruited participants.

  \begin{table}[h!]
  \centering
  \begin{tabular}{l | c | r r r }
              & recruited & ages (mean age) & f/m/nb/dnd \\ \hline
  Exp.~1 (QUD) & 80 & 18-81 (43.8) & 42/37/0/1  \\
  Exp.~2 (asking whether) & 80 & 20-74 (38.5)  & 48/30/1/1  \\
  Exp.~3 (direct dissent) & 80 & 18-77 (39.1) & 50/28/1/1  \\
  Exp.~4 (yes, but) &80 & 19-67 (38.0)  & 48/30/2/0 &  \\
  \hline
  \end{tabular}

  \caption{Information about the participants recruited in Exps.~1-4 (f = female, m = male, nb = nonbinary, dnd = did not disclose).}\label{t:recruited}
  \end{table}

  \subsubsection{Materials and procedure}
  
The four experiments measured the at-issueness of the seven contents in \ref{stims} with a different at-issueness diagnostic, namely the QUD diagnostic (Exp.~1), the `asking whether' diagnostic (Exp.~2), the direct dissent diagnostic (Exp.~3) and the `yes, but' diagnostic (Exp.~4). As illustrated in \ref{diag} for the content of sentence-medial NRRCs (here: Lucy broke the plate), each diagnostic was implemented as is standard in the literature: In Exp.~1 \ref{diag.a}, which implemented the QUD diagnostic, participants read a dialogue between two named speakers, where the first utters an interrogative sentence (the presumed QUD) that is about the content to be diagnosed and the second responds with a declarative that contributes the content to be diagnosed. In Exp.~2 \ref{diag.b}, which implemented the `asking whether' diagnostic, participants read an interrogative sentence uttered by a named speaker, where the interrogative sentence contributes the content to be diagnosed. In Exp.~3 \ref{diag.c}, which implemented the `direct dissent' diagnostic, participants read a dialogue between two named speakers, where the first utters a declarative sentence with the content to be diagnosed and the second directly dissents with the content to be diagnosed. Finally, in Exp.~4 \ref{diag.d}, which implemented the `yes, but' diagnostic, participants read a dialogue between two named speakers where the first utters a declarative sentence that contributes the content to be diagnosed and the second responds with one of two indirect dissent variants (\emph{yes, but..}, \emph{yes, and...}) or with a direct dissent.

\ex.\label{diag} Implementations of the diagnostics in Exps.~1-4
\a.\label{diag.a} Exp.~1 (QUD diagnostic)
\\ {\bf Nora:} \emph{What did Lucy break?}
\\ {\bf Leo:} \emph{Lucy, who broke the plate, apologized.}
\b.\label{diag.b} Exp.~2 (`asking whether' diagnostic )
\\ {\bf Nora:} \emph{Did Lucy, who broke the plate, apologize?}
\c.\label{diag.c} Exp.~3 (`direct dissent' diagnostic)
\\ {\bf Nora:} \emph{Lucy, who broke the plate, apologized.}
\\ {\bf Leo:} \emph{No, she didn't break the plate.}
\d.\label{diag.d} Exp.~4 (`yes, but' diagnostic)
\\ {\bf Nora:} \emph{Lucy, who broke the plate, apologized.}
\\ {\bf Nina:} \emph{Yes, but she didn't break the plate.}
\\ \hspace*{1cm} \emph{Yes, and she didn't break the plate.}
\\ \hspace*{1cm} \emph{No, she didn't break the plate.}

As shown in Fig.~\ref{fig:trials}, the response options in each of the four experiments also differed depending on the diagnostic: In Exp.~1 (QUD diagnostic), shown in panel (a), participants were asked how well the response fits the question and they gave their response on a slider marked `totally doesn't fit' on one end (coded 0) and `totally fits' on the other end (coded as 1). In Exp.~2 (`asking whether' diagnostic), shown in panel (b), participants were asked whether the question is about the content to be diagnosed and they gave their response on a slider marked `no' on one end (coded as 1) and `yes' on the other (coded as 0). In Exp.~3 (direct dissent diagnostic), participants were asked how natural the direct dissent and participants gave their response on a slider marked `totally unnatural' (coded as 0) on one end and `totally natural' on the other (coded as 1). Finally, in Exp.~4 (`yes, but' diagnostic), participants were asked to choose the response that sounded best; the two indirect dissents were coded as 1 and the direct one as 0. Across the four experiments, the responses were coded as 0 or 1 such that 0 meant that the content to be diagnosed was rated as at-issue and 1 meant that the content was rated as not-at-issue.


 \begin{figure}[h!]
  \centering
  % Top row
  \subfigure[Exp.~1: QUD diagnostic]{%
    \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp1}}%
    \label{fig:trialExp1}
  }
  \hfill
  \subfigure[Exp.~2: `asking whether' diagnostic]{%
    \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp2}}%
    \label{fig:trialExp2}
  }

  \vspace{1em}

  % Bottom row
  \subfigure[Exp.~3: `direct dissent' diagnostic]{%
    \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp3}}%
    \label{fig:trialExp3}
  }
  \hfill
  \subfigure[Exp.~4: `yes, but' diagnostic]{%
    \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp4}}%
    \label{fig:trialExp4}
  }

  \caption{Sample trials in (a) Exp.~1, (b) Exp.~2, (c) Exp.~3, and (d) Exp.~4.}
  \label{fig:trials}
  \end{figure}
  
  Each of the seven contents in \ref{stims} was instantiated by one of the seven items shown in \ref{items} in each of the four experiments.
 
 \ex.\label{items}
 \a. Jack saw the murder.
 \b. Raul cheated on his wife.
 \c. Ann stole the money.
 \d. Danny ate the last cupcake.
 \b. Lucy broke the plate.
 \b. Dustin lost his key.
 \b. Greg bought a new car.
 \z.
 
 Each experiment also included two control items each, which functioned as attention checks: one item was expected to be at-issue and the other one not-at-issue. See Supplement \ref{supp:stims} for the control items used in each experiment.
 
 In each of the four experiments, each participant's set of items was generated by randomly combining each of the seven contents in \ref{stims} with a unique content in \ref{items}. Participants completed a total of 9 trials, namely 7 target trials and the same 2 control trials. Trial order was randomized.
 
After completing the experiment, participants filled out a short optional demographic survey. To encourage truthful responses, participants were told that they would be paid no matter what answers they gave in the survey. 

  \subsubsection{Data exclusion}
    
  We excluded the data of participants who did not self-identify as native speakers of
  American English and of participants whose responses to either one of the two control trials was more than 2 sd away from the group mean (Exps.~1-3) or whose responses to either one of the two control trials was wrong (Exp.~4).   Table \ref{t:excluded} shows how many participants were excluded in each experiment, the properties of the remaining participants, and the number of data points that entered into the analyses.

  \begin{table}[h!]
  \centering
  \begin{tabular}{l | r r | r r  | r }
               & \multicolumn{2}{c|}{\bf exclusion criterion} & \multicolumn{2}{c|}{\bf remaining participants} & data \\ 
              & language & fillers & ages (mean age) & f/m/nb/dnd &  points \\ \hline
  Exp.~1 (QUD   & 1 &  10 &  18-81 (41.1) & 36/32/0/1 & 621 \\ 
  Exp.~2 (asking whether) &  2 &  4 & 22-74 (38.7) & 45/27/1/1 & 666 \\ 
  Exp.~3  (direct dissent) &  2 &  7 & 18-77 (39.5) & 44/25/1/1  & 639 \\ 
  Exp.~4  (yes, but) & 4 & 4 & 19-67 (38.5)  & 43/27/2/0 & 648 \\ 
  \hline
  \end{tabular}
  \caption{Information from Exps.~1-4 about the number of participants whose data was excluded based on their self-declared language (variety) and the fillers, about the remaining participants, and about the number of data points that entered into the analysis.}\label{t:excluded}
  \end{table}

  \subsection{Results}
  
  The four panels of Fig.~\ref{fig:results} show the results of the four experiments for the seven target contents and the two controls, that is, the mean naturalness ratings in Exp.~1 (QUD diagnostic), the mean `asking whether' ratings in Exp.~2 (`asking whether' diagnostic), the mean naturalness ratings in Exp.~3 (`direct dissent' diagnostic) and the proportion of `no' choices in Exp.~4 (`yes, but' diagnostic). As shown, the results of the four experiments exhibit differences in the absolute rating of the seven target contents compared to the two controls, which received ratings at floor and at ceiling across the four experiments: In Exp.~2 (`asking whether' diagnostic), the seven target contents received a broad range of ratings between the two extremes, whereas they all received relatively high ratings in Exp.~3 (`direct dissent' diagnostic). The results of the other two experiments fall in-between. 
  
  The results of the four experiments also exhibit differences in the relative ratings of the seven target contents with respect to one another.
  

  \begin{figure}[h!]
    \centering

    % Top row
    \subfigure[Exp.~1: QUD diagnostic]{%
      \includegraphics[width=0.48\linewidth]{../../results/main/exp1/graphs/mean-ratings.pdf}%
      \label{fig:qud}
    }
    \hfill
    \subfigure[Exp.~2: `asking whether' diagnostic]{%
      \includegraphics[width=0.48\linewidth]{../../results/main/exp2/graphs/mean-ratings.pdf}%
      \label{fig:AK}
    }

    \vspace{1em}

    % Bottom row
    \subfigure[Exp.~3: `direct dissent' diagnostic]{%
      \includegraphics[width=0.48\textwidth]{../../results/main/exp3/graphs/mean-ratings.pdf}%
      \label{fig:dd}
    }
    \hfill
    \subfigure[Exp.~4: `yes, but' diagnostic]{%
      \includegraphics[width=0.48\textwidth]{../../results/main/exp4/graphs/mean-ratings.pdf}%
      \label{fig:yb}
    }

    \caption{Results of Exps.~1--4. Panels (a)--(c) show the mean responses by content for the QUD diagnostic in Exp.~1 (a), the `asking whether' diagnostic in Exp.~2 (b), and the `direct dissent' diagnostic in Exp.~3 (c). Panel (d) shows the proportion of `no' choices by content for the `yes, but' diagnostic in Exp.~4. Error bars indicate 95\% bootstrapped confidence intervals. Violin plots in panels (a)--(c) show the kernel probability density of individual participants’ ratings. Gray dots in panel (d) represent individual participant responses (either ‘no’ or one of the ‘yes’-responses, jittered vertically and horizontally for legibility).}
    \label{fig:results}
  \end{figure}

   Second, the content manipulation affects the ratings differently across the four diagnostics, sometimes in opposite directions. This results in a different order of predicates by response means between experiments.
    \begin{itemize}
      \item For instance, \emph{be right} ranks highest under the `asking whether' diagnostic (\Cref{fig:AK}), and the `yes, but' test (\Cref{fig:yb}), but ranks lowest under the QUD-diagnostic (\Cref{fig:qud}), and shows no clear effect in the direct dissent diagnostic (\Cref{fig:dd}).
    \end{itemize}
    
    \begin{itemize}
      \item Analysis similar to what we did in projection study? -- Interaction effects
      \item How about something similar to the rank-analysis that Yvonne Kilian did for comparing diagnostics?

    \end{itemize}

  \subsection{Discussion}
    The differening results between diagnostics suggest that they are not interchangeable.

    \subsubsection{Sensitivity}

      \begin{itemize}
        \item Further, while the `asking whether' diagnostic, for contents embedded in questions, is sensitive enough to detect fine-grained differences between contents, the smaller range of response means for the other diagnostics could suggest the need for a more sensitive diagnostic for contents embedded in declarative assertions.

        \item We did not replicate the effect reported in \citealt{syrett_experimental_2015}, that sentence-final NRRCs receive higher at-issueness ratings than sentence-medial ones.

        \item  Additional comparison to \citealt{syrett_experimental_2015} (details omitted in the abstract) points to potential effects of the response task and the speech act of the utterance embedding the tested content.

      \end{itemize}

    \subsubsection{Order}

      \begin{itemize}
        \item In particular, the varying relative order of by-content means across diagnostics provide an initial argument that they target distinct properties of the content.
      \end{itemize}

\section{Theoretical implications}

\section{Conclusion}

The conclusion is the last numbered section, and any ensuing sections are unnumbered.

\pagebreak
\section*{Abbreviations (if applicable)}\label{abbrev}

\textsc{acc} = accusative, \textsc{dat} = dative, \textsc{dem} = demonstrative, \textsc{nom} = nominative, \textsc{pl} = plural, \textsc{sg} = singular

For the standard abbreviations to be used here, refer to the \href{https://www.eva.mpg.de/lingua/resources/glossing-rules.php}{Leipzig glossing rules}.

\section*{Data availability/Supplementary files (if applicable)}

The journal encourages authors to make all data associated with their submission openly available, according to the FAIR principles (Findable, Accessible, Interoperable, Reusable). More information can be found \href{https://www.glossa-journal.org/site/editorial-policies/#data-policy}{here}.

If data/supplementary files are to be associated with the accepted paper, one of the options below should be followed:
\begin{enumerate}
\item upload the files to your chosen open repository and make note of the DOI that they will provide (most suitable for datasets or information that act as foundations to the research being published. This option makes the files more findable and more citable). We recommend an open repository such as osf.io, which allows you to create a "project" under which you can upload relevant files (datasets, analysis scripts, experimental materials, etc.). The project will be associated with a unique DOI. You can then include in your manuscript a citation of the OSF entry and/or a link to the project page on OSF, to direct interested readers to the supplementary materials. During review, please be sure that the link to the repository is anonymized to maintain a fully double masked review process. Instructions for doing this on the OSF may be found \href{https://help.osf.io/hc/en-us/articles/360019930333-Create-a-View-only-Link-for-a-Project}{here}. If you'd like to learn more about best practices for ensuring reproducibility, see \href{https://psyarxiv.com/hf297/}{Laurinavichyute and Vasishth (2021)}. Please contact us if you would like more information or advice about hosting your data on an open repository.
\item upload the files to the journal system during the submission process, as `data files'. The journal will then host them as part of the publication and provide them with a DOI (most suitable for non-data files or very short pieces of information, although option 1 is also suitable for these if the author prefers).
\end{enumerate}

\noindent In both cases, a `Data availability' or `Supplementary files' section must be added prior to the reference list that provides a title and very short summary of the files for each file. If option 1 was selected, you should also provide the DOI in this section. For example:

\noindent Supplementary file 1: Appendix. Scientific data related to the experiments. DOI: \doi{10.5334/gjgl.310.s1}

Ideally, supplementary files are also cited in the main text.

Please note that neither of the above two options will result in the files being typeset, so please ensure that they are in publishable format when you upload the accepted paper.


\section*{Ethics and consent (if applicable)}

Research involving human subjects, human material, or human data, must have been performed in accordance with the Declaration of Helsinki. Studies must have been approved by an appropriate ethics committee and the authors should include a statement in the article text detailing this approval, including the name of the ethics committee and reference number of the approval, or mention any exemptions to ethical approval that apply to their research. The identity of research subjects should be anonymised whenever possible. For research involving human subjects, informed consent to participate in the study must be obtained from participants (or their legal guardian).


\section*{Funding information (if applicable)}

Should the research have received a funding grant then the grant provider and grant number should be detailed.

\section*{Acknowledgements (optional)}

The authors wish to thank Martin Haspelmath for providing the generic style sheet for linguistics, and Kai von Fintel for giving permission to use and modify the \textit{Semantics \& Pragmatics} Latex template, bibliography style, and document class.

\section*{Competing interests (required)}

If any of the authors have any competing interests then these must be declared. Guidelines for competing interests can be found \href{https://www.glossa-journal.org/site/competing-interests/}{here}. If there are no competing interests to declare then the following statement should be present: `The author(s) has/have no competing interests to declare'.

\section*{Authors' contributions (optional)}\label{contrib}

A sentence or a short paragraph detailing the roles that each author held to contribute to the authorship of the submission.  Individuals listed must fit within the definition of an author, as per our \href{https://www.glossa-journal.org/site/author-guidelines/}{Author Guidelines}.

\nocite{*} %this is to get all the entries of the sample bibliography; delete this line for an actual Glossa submission

%\printbibliography %for use with biblatex; comment out if you use natbib
\bibliography{../at-issueness} %for use with natbib; comment out if you use biblatex, and change 'sample' by the name of your bib-file


\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% TeX-engine: luatex
%%% End:
