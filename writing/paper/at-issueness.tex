% !TEX program = lualatex
% glossa-template.tex
% Copyright 2016 Guido Vanden Wyngaerd
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
% 
% The Current Maintainer of this work is 
% Guido Vanden Wyngaerd (guido.vandenwyngaerd@kuleuven.be).
%
% This work consists of the files 
% glossa.cls
% glossa.bst
% gl-authoryear-comp.cbx
% biblatex-gl.bbx
% glossa-template.tex
% glossa.png
%
% The files of the work are derived from the Semantics & Pragmatics style files
% by Kai von Fintel, Christopher Potts, and Chung-chieh Shan
% All changes are documented on the github repository 
% https://github.com/guidovw/Glossalatex.

\PassOptionsToPackage{table}{xcolor}
\PassOptionsToPackage{xcolor}{dvipsnames}
\documentclass[times,linguex]{glossa}
\usepackage{rotating}
\usepackage{tablefootnote}
\usepackage{colortbl}
\usepackage{color}
\usepackage{multicol}
\usepackage{booktabs}

\usepackage{adjustbox}
\usepackage{array}

\newcolumntype{R}[2]{%
    >{\adjustbox{angle=#1,lap=\width-(#2)}\bgroup}%
    l%
    <{\egroup}%
}

\newcommand*\rots{\multicolumn{1}{R{90}{.7em}}}% no optional argument here, please!
%\usepackage{xcolor}

% possible options:
% [times] for Times font (default if no option is chosen)
% [cm] for Computer Modern font
% [lucida] for Lucida font (not freely available)
% [brill] open type font, freely downloadable for non-commercial use from http://www.brill.com/about/brill-fonts; requires xetex
% [charis] for CharisSIL font, freely downloadable from http://software.sil.org/charis/
% for the Brill an CharisSIL fonts, you have to use the XeLatex typesetting engine (not pdfLatex)
% for headings, tables, captions, etc., Fira Sans is used: https://www.fontsquirrel.com/fonts/fira-sans
% [biblatex] for using biblatex (the default is natbib, do not load the natbib package in this file, it is loaded automatically via the document class glossa.cls)
% [linguex] loads the linguex example package
% !! a note on the use of linguex: in glossed examples, the third line of the example (the translation) needs to be prefixed with \glt. This is to allow a first line with the name of the language and the source of the example. See example (2) in the text for an illustration.
% !! a note on the use of bibtex: for PhD dissertations to typeset correctly in the references list, the Address field needs to contain the city (for US cities in the format "Santa Cruz, CA")

%\addbibresource{sample.bib}
% the above line is for use with biblatex
% replace this by the name of your bib-file (extension .bib is required)
% comment out if you use natbib/bibtex

\let\B\relax %to resolve a conflict in the definition of these commands between xyling and xunicode (the latter called by fontspec, called by charis)
\let\T\relax
\usepackage{xyling} %for trees; the use of xyling with the CharisSIL font produces poor results in the branches. This problem does not arise with the packages qtree or forest.
%\usepackage[linguistics]{forest} %for nice trees!




% \pdf* commands provide metadata for the PDF output. ASCII characters only!
\pdfauthor{}
\pdftitle{What is at-issueness?}
\pdfkeywords{}

\title[What is at-issueness?]{What is at-issueness? An experimental comparison of diagnostics\\ 
  \bigskip \large
  Word count (including references, excluding abstract and supplements): 11,924
  }
% Optional short title inside square brackets, for the running headers.

\author[]% short form of the author names for the running header. If no short author is given, no authors print in the headers.
{%as many authors as you like, each separated by \AND.
  % \spauthor{Waltraud Paul\\
  % \institute{CRLAO, CNRS-EHESS-INALCO}\\
  % \small{%105, Bd. Raspail, 75005 Paris\\
  % waltraud.paul@ehess.fr}
  % }
  % \AND
  % \spauthor{Guido Vanden Wyngaerd \\
  % \institute{KU Leuven}\\
  % \small{%Warmoesberg 26, 1000 Brussel\\
  % guido.vandenwyngaerd@kuleuven.be}
  % }%
}

\input{author-added}

% positive coefficients/difference
\definecolor{red}{RGB}{178,24,43}

% negative coefficients/difference
\definecolor{blue}{RGB}{33,102,172}

% comments by JT
\newcommand{\jt}[1]{\textbf{\color{blue}JT: #1}}
\newcommand{\lh}[1]{\textbf{\color{orange}LH: #1}}

\begin{document}

\maketitle
%TC:ignore
\begin{abstract}
  At-issueness is a central concept in theoretical semantics and pragmatics, but there is no consensus about how it should be defined or diagnosed (e.g., \citealt{tonhauser_diagnosing_2012,snider_anaphoric_2017,snider_distinguishing_2018,tonhauser_how_2018,koev_notions_2018,faller_discourse_2019,korotkova_evidential_2020}). We present the results of six experiments designed to investigate whether four widely used diagnostics for at-issueness yield consistent results. Our findings reveal substantial differences between diagnostics, indicating that they are not interchangeable and that the choice and implementation of diagnostics matter for empirical generalizations about at-issueness.
  %
  Diagnostics that measure the at-issueness of contents embedded in questions show the greatest differentiation to me across expressions, indicating that speech act embedding plays a key role.\jt{key role in what? in general, how we assessed the diagnostics (differentiation) and how they differ (declarative vs.\ interrogative, response tasks) needs to be set up better, so that this sentence doesn't come so out of the blue} However, the theoretical divide between QUD-based and assertion-based diagnostics assumed in previous literature\jt{this also comes out of the blue} does not appear to be the primary source of divergence.\jt{the word ``divergence'' is also hard to interpret here because we haven't said anything yet about how we'll evaluate the diagnostics and what the results were} Instead, we argue that the crucial difference lies in how questions and assertions relate at-issue and not-at-issue content to speaker commitments.\jt{this sentence belongs with the first sentence above, about declarative vs. interrogative}
\end{abstract}
%TC:endignore

\begin{keywords}
  at-issueness, diagnostics, experimental pragmatics
\end{keywords}

\section{Introduction \label{sec:1_introduction}}
  At-issueness is a key concept in theoretical semantics and pragmatics, used in the analysis of various phenomena, including presupposition, conventional implicature, evidentials, and expressives (e.g., \citealt{karttunen_conventional_1979,horton_presuppositions_1988,abbott_presuppositions_2000,faller_semantics_2002,potts_logic_2005,tonhauser_diagnosing_2012}). It is generally understood as distinguishing propositions expressing the main point of an utterance (at-issue content) from those conveying background information (not-at-issue content), but there is no consensus how at-issueness should be defined or diagnosed, and multiple competing definitions and diagnostics reflect different assumptions about its underlying nature (e.g., \citealt{tonhauser_diagnosing_2012,snider_anaphoric_2017,snider_distinguishing_2018,tonhauser_how_2018,koev_notions_2018,faller_discourse_2019,esipova_composition_2019,korotkova_evidential_2020}). Consequently, empirical claims about whether a given expression contributes at-issue or not-at-issue content may be relative to specific diagnostics, and different diagnostics may not even target the same underlying phenomenon.

  Four commonly used at-issueness diagnostics are illustrated in (\pref{qud}--\pref{yesbut}) for sentence-medial appositive non-restrictive relative clauses (NRRCs), which are typically taken to contribute not-at-issue content (\citealt{potts_logic_2005}). Accordingly, the diagnostics are expected to show the following patterns: Under the QUD diagnostic \ref{qud}, participants are expected to give low question-answer match ratings, reflecting the assumption that only at-issue content can address a previous question (e.g., \citealt{lee_evidentiality_2011,tonhauser_diagnosing_2012,chen_presuppositions_2024}). Under the `asking-whether' diagnostic \ref{aw}, participants are expected to judge that the speaker is not asking about the  NRRC content (e.g., \citealt{tonhauser_how_2018,solstad_cataphoric_2024,degen-tonhauser-glossa}). Under the direct-dissent diagnostic \ref{dd}, rejecting the NRRC content is expected to be infelicitous, yielding low naturalness ratings (e.g., \citealt{faller_semantics_2002,faller_evidentiality_2006,papafragou_epistemic_2006,amaral_review_2007,murray_evidentiality_2010,murray_varieties_2014,anderbois_crossing_2010,anderbois_at-issue_2015,tonhauser_diagnosing_2012,syrett_experimental_2015}). Finally, under the `yes, but' diagnostic \ref{yesbut}, participants are expected to prefer signalling agreement with the previous assertion (i.e. a \emph{yes}-response) when denying the NRRC content (e.g., \citealt{xue_correlation_2011,cummins_backgrounding_2013,destruel_cross-linguistic_2015}).



  \ex. \label{qud}%
    QUD diagnostic%
    \a.[{\bf Nora: }] \emph{What did Greg buy?}
    \b.[{\bf Leo: }] \emph{Greg, who bought a new car, is envied by his neighbor.}
    \z.
    Question to participants: How well does Leo's response fit Nora's question?\smallskip
  \z.

  \ex. \label{aw}%
    `asking whether' diagnostic
      \a.[{\bf Nora: }] \emph{Is Greg, who bought a new car, envied by his neighbor?}\z.
    Question to participants: Is Nora asking whether Greg bought a new car?\smallskip
  \z.

  \begin{samepage}
  \ex. \label{dd} Direct-dissent diagnostic%
    \a.[{\bf Nora: }] \emph{Greg, who bought a new car, is envied by his neighbor.}
    \b.[{\bf Leo: }] \emph{No, that's not true, he didn't buy a new car.}
    \z.
  Question to participants: How natural is Leo's rejection of Nora's utterance?\smallskip
  \z.
  \end{samepage}

  \ex. \label{yesbut}%
    `yes, but' diagnostic %
    \a.[{\bf Nora: }] \emph{Greg, who bought a new car, is envied by his neighbor.}
    \b.[{\bf Leo: }] \emph{Yes, but he didn't buy a new car.} /
    \b.[] \hspace*{0em} \emph{Yes, and he didn't buy a new car.} /
    \b.[] \hspace*{0em} \emph{No, he didn't buy a new car.}
    \z.
    Task for participants: Choose the response that sounds best.
  \z.

  The assumptions underlying these diagnostics can be organized around three properties of at-issue content identified  in \citet{tonhauser_diagnosing_2012} as motivating diagnostic strategies: (i) at-issue content addresses the question under discussion, (ii) the at-issue content of questions determines the relevant set of alternatives, and (iii) at-issue content can be directly assented or dissented with.
  
  The QUD diagnostic \ref{qud} is based on assumption (i). It adopts the view that discourse is structured around addressing a Question Under Discussion (QUD) (\citealt{roberts_information_1996,ginzburg_interrogatives_1996}) and that at-issue content is the part of an utterance intended to address that question (\citealt{amaral_review_2007,simons_what_2010}). Accordingly, the diagnostic assumes that only at-issue content can felicitously address a previously established QUD (\citealt{tonhauser_diagnosing_2012}). The diagnostic presents the target content in a response to a question about that content, and question-answer match ratings are expected to be high when the target content can be construed as at-issue and low otherwise.

  The `asking whether' diagnostic \ref{aw} is based on assumption (ii), namely that the at-issue content of a question is more likely to determine the question partition of the context set, whereas not-at-issue content is less likely to do so (\citealt{tonhauser_diagnosing_2012,tonhauser_how_2018}). The diagnostic presents the target content in a polar question asked by a named speaker (here: Nora), and participants judge if the speaker was asking whether the target content is true. Such `asking whether' judgments are expected to be high when the target content is construed as at-issue and low otherwise.

  Finally, the direct-dissent diagnostic \ref{dd} and the `yes, but' diagnostic \ref{yesbut} are based on  assumption (iii), that only the at-issue content of an assertion can be directly affirmed and denied, whereas rejecting not-at-issue content requires more indirect discourse moves (\citealt{faller_semantics_2002,faller_evidentiality_2006,papafragou_epistemic_2006,amaral_review_2007}). The direct-dissent diagnostic tests whether directly dissenting with the target content is judged natural: such responses are expected to be judged natural if the content is at-issue and unnatural otherwise. Relatedly, the `yes, but' diagnostic tests whether a target content can be denied while responding \emph{yes} to the assertion as a whole. It was originally designed to diagnose pragmatic inferences that are not semantic entailments, with the assumption is that such pragmatic inferences can be denied without contradicting the assertion (i.e., using \emph{yes, but} rather than \emph{no}, see \citealt{onea_hungarian_2009}). \citet{xue_correlation_2011} adopt the test as a diagnostic for at-issueness, assuming that a \emph{yes, but} response constitutes an indirect denial suitable for denying not-at-issue content.

  Originally developed to diagnose pragmatic inferences that are not semantic entailments (\citealt{onea_hungarian_2009}), it has been adopted as an at-issueness diagnostic under the assumption that yes but responses constitute an indirect denial appropriate for not-at-issue content (\citealt{xue_correlation_2011}).


  tonhauser, simons: all QUD related
  \citealt{snider_at-issueness_2017,snider_anaphoric_2017,snider_distinguishing_2018}: qud + anaphora, also anderbois
  \citealt{koev_notions_2018} different notions
  \citealt{faller_discourse_2019} different notions
  \citealt{korotkova_evidential_2020} different notions

  Previous research has emphasized that these assent/dissent-based diagnostics :  On another view, these diagnostics target a distinct notion of at-issueness (see \citealt{koev_notions_2018} and discussion in \citealt{faller_discourse_2019,korotkova_evidential_2020}, \jt{also Anderbois et al 2015 JoS?}), under which the at-issue content of an assertion constitutes a proposal to update the common ground (based on \citealt{farkas_reacting_2010})\jt{Hm, the diagnostic has been around much longer than FB 2010; is this reference really appropriate here?}. Accordingly, such content can be directly affirmed or denied using default discourse moves that include response particles. On this view, not-at-issue content is either presupposed (already entailed in the common ground; \citealt{stalnaker_presuppositions_1973,stalnaker_common_2002}), or newly imposed on the common ground (\citealt{murray_varieties_2014,anderbois_at-issue_2015}), and requires special discourse moves for rejection (\citealt{potts_logic_2005}).\jt{Why not just say that not-at-issue content cannot be direct affirmed or denied, why is it important to differentiate different ways of being NAI content here? Also, the diagnostic doesn't always use response particles, so this feels a bit off track?}

  % a contrast that has been highlighted by \citet{snider_at-issueness_2017,snider_anaphoric_2017,snider_distinguishing_2018,koev_notions_2018,faller_discourse_2019}, and \citet{korotkova_evidential_2020}
  - at-issueness can be modeled in different ways (\citealt{fall})
  - koev, korotkova: these are different underlying properties
  - snider: not different notions of at-issueness, but anaphoric availability; \citet{snider_anaphoric_2017,snider_at-issueness_2017,snider_distinguishing_2018} has argued that they do not reflect at-issueness at all, but rather target the anaphoric availability of propositional content for response particles like English \emph{yes/no}.

  Definitions of at-issueness:
  - QUD
  - assertions: proposal vs presupposition/imposition
  - restrictive modification vs not 

  Consequently, there is currently no agreed-upon definition of at-issueness,\jt{this comes out of the blue; there hasn't yet really been a mention or discussion of definitions of at-issueness, but characterizations of diagnostics and the concepts they rely on} and existing diagnostics may not be probing the same underlying phenomenon. This raises two central questions:

  \begin{enumerate}
    \item Do the various diagnostics yield the same results?
    \item Do the existing definitions of at-issueness target the same underlying phenomenon?
  \end{enumerate}

  \noindent Initial research on these questions has yielded mixed answers.

  While appositive NRRCs are widely taken to contribute not-at-issue content (\citealt{potts_logic_2005,amaral_review_2007,tonhauser_diagnosing_2012,destruel_cross-linguistic_2015,tonhauser_how_2018,solstad_cataphoric_2024}), a forced-choice continuation task in \citet{syrett_experimental_2015} suggested that sentence-final appositive NRRCs pattern as more at-issue than medial ones, under a version of the direct-dissent diagnostic.
  % \jt{Is it important to mention the task here?}
  % This finding has been interpreted as evidence that final appositive NRRCs are more at-issue at the point in discourse when participants select a response (\citealt{syrett_experimental_2015,jasinskaja_not_2016}).\jt{iI don't understand why this sentence occurs here; it doesn't contribute to characterizing the state-of-the-art about AI results}
  \citet{snider_at-issueness_2017} further argued that the direct-dissent diagnostic is sensitive to this medial/final distinction, while other tests are not.
  % \jt{this one is good because it shows that there's stuff to investigate}

  Beyond appositives, \citealt{tonhauser_how_2018} compared at-issueness measures for a range of 19 English expressions including sentence-medial appositives and the clause-embedding predicates \emph{discover, know,} and \emph{annoyed}, using two diagnostics of at-issueness: the question-based `asking whether' diagnostic and the `Are you sure?' diagnostic (p.526ff).\jt{Readers will not understand what this diagnostic is about} \footnote{explain diagnostic (see also the `really' test in \citealt{shanon_two_1976})}. They found that contents were overall received lower overall ratings with the `asking whether' diagnostic, and the `Are you sure?' diagnostic showed greater differentiation across expressions. Despite these differences, ratings from both diagnostics were correlated, suggesting that they may nonetheless be sensitive to a shared underlying phenomenon.

  To date, however, there has been no systematic experimental comparison of diagnostics to investigate whether the diagnostics yield consistent results. This paper takes a first step toward addressing the above questions (i+ii) in a systematic way.\jt{question ii is about definitions but no much has been said about definitions.} Specifically, we assess whether the four widely used diagnostics in (\pref{qud})--(\pref{yesbut}) give rise to the same pattern of results when applied to the same target contents. Our findings reveal significant differences across diagnostics, indicating they are not interchangeable. Because each diagnostic is grounded in distinct theoretical assumptions about what it means for content to be at-issue, this comparison also bears on whether currently available conceptions of at-issueness converge on a common underlying notion.

  We present the results from six experiments that systematically vary the diagnostic used to assess the at-issueness status of the same types of contents across experiments in English. Experiments 1--4 tests propositional contents\jt{why `propositional'?}\lh{to clarify what is meant by "content"} associated with seven types of expressions: sentence-medial and sentence-final NRRCs and the complements of selected clause-embedding predicates (\emph{be right, confirm, confess, discover,} and \emph{know}). These contents were selected because previous research found variability in their behavior on at-issueness diagnostics, such as Syrett and Koev's \citeyear{syrett_experimental_2015} finding that medial and final NRRCs yield different results on the direct dissent diagnostic. Further, \citealt{degen-tonhauser-glossa} found fine-grained differences between the embedded content of 20 English clause-embedding predicates using the asking-whether diagnostic. \Cref{fig:dtglossa} shows the mean `asking whether' ratings by predicate in their study.\jt{this paragraph needs to be merged with the previous one, and present the experiments in a more systematic way: the data in Fig 1 has nothing to do with Experiments 1-4.}

  \begin{figure}[h!]
    \centering

    \includegraphics[width=0.7\textwidth]{../../results+analysis/degen-tonhauser-glossa/graphs/mean-asking-whether-ratings.pdf}

    \caption{Mean `asking whether' ratings for the contents of the clausal complements of 20 clause-embedding predicates, from \citealt{degen-tonhauser-glossa}. Error bars indicate 95\% bootstrapped confidence intervals. Violin plots indicate the distribution of individual ratings.
    }

    
    \label{fig:dtglossa}
  \end{figure}

  By directly comparing how each diagnostic evaluates these contents, our study provides the first systematic assessment of how comparable and interchangeable at-issueness diagnostics are. Experiments 1--4 applied the four diagnostics in \ref{qud}--\ref{yesbut} to NRRCs and to the complements of our selected clause-embedding predicates.\jt{this repeats what was said above} Only Exp.~2 (`asking whether') comes close to observing the differences between the clause-embedding predicates observed in \citet{degen-tonhauser-glossa}, suggesting that diagnostics do vary in whether they detect at-issueness differences between particular expressions. Notably, the `asking whether' diagnostic, as implemented in Exp.~2, which showed the greatest differentiation between contents, is the only diagnostic where the target content is embedded in a polar question.\jt{at this point, I don't think the reader will appreciate why this is ``notable'' -- this needs to be set up more explicitly}

  To test whether this greater differentiation was due to the interrogative embedding or from the response task itself, we compared the `asking whether' diagnostic (Exp.~5) with a diagnostic that also embeds content in a polar question, but elicits acceptability judgments for a direct response (Exp.~6), \jt{so isn't this a 5th diagnostic? but the text above only talks about four diagnostics that we test in this paper} like in the direct-dissent diagnostic, using the same 20 clause-embedding predicates from \citet{degen-tonhauser-glossa}. The two experiments yielded highly correlated results, indicating that the observed increased differentiation is driven by the interrogative embedding, not the response task. Finally, none of our experiments observed the positional effect found by \citet{syrett_experimental_2015}, suggesting that even small task differences can affect outcomes.\jt{if the big point of our paper is that interrogatives are somehow better, then this last sentence steals that thunder by being plopped on here. is it important enough to be mentioned in the introduction?}

  Overall, our findings show that the four diagnostics are not interchangeable: they differ in how strongly they differentiate among the contents tested.\jt{feels repetitive at this point} Our results provide evidence that the speech act used to present the target content plays an important role: embedding the target content in questions yield results with greater by-content differentiation than embedding it in assertions.\jt{this already occurred in the previous paragraph; suggests a reorganization is needed} However, we find no clear split corresponding to the theoretical divide assumed in prior literature, between diagnostics targeting at-issueness relative to the QUD \ref{qud}+\ref{aw} on the one hand, and those targeting at-issueness relative to an assertive proposal \ref{dd}+\ref{yesbut} on the other. Instead, we argue that the relevant speech-act difference we do find lies in how questions and assertions relate at-issue and not-at-issue content to speaker commitments.\jt{too detailed for the intro} Our findings also suggest that differences in how the diagnostics interact with contextual requirements of particular expressions, and the choice and implementation of the response task may affect results. A key takeaway is that future empirical work on at-issueness should continue to employ multiple diagnostics, to avoid results that are tied to a single diagnostics.\jt{i disagree. i think people can continue to publish work with just one diagnostic but they need to be aware that other diagnostics might show different results, i.e., not overinterpret their results}\lh{
  Consequently, empirical claims about whether a given expression contributes at-issue or not-at-issue content are often diagnostic-relative.} Moreover, given the role of question embeddings, speech act type should be explicitly taken into account when diagnosing at-issueness.



  We operationalize each diagnostic through its established empirical task:\jt{what is an empirical task?} question-answer match ratings for the QUD diagnostic, speaker intention judgments\jt{i've never heard this term} for the asking-whether diagnostic, naturalness ratings for direct dissent, and forced-choice responses for the `yes, but' diagnostic. For each of the contents, we collect ratings across multiple items and participants,\jt{why does this need to be said at all? any good experiment will have multiple items and participants?} and compare the mean responses. Given that we are aggregating over multiple items and participants, we may say that the mean rating for one content is higher/lower than that of another, or that they do not differ.\jt{i don't understand what this is conveying} Following prior work (e.g., \citealt{tonhauser_how_2018}), we interpret higher mean/lower ratings as indicating that content is more/less at-issue under a given diagnostic,\jt{this belongs in the methods section} with two caveats:

  First, we remain agnostic about whether at-issueness is an underlyingly binary or a gradient property (cf. \citealt{tonhauser_how_2018,barnes_information_2023}). If at-issueness is gradient, the extent to which a content is at-issue may be understood as the extent to which it is relevant to the QUD or the main assertion, in which case gradient mean ratings may be taken to reflect gradient relevance. If at-issueness is categorical, content is at-issue iff it addresses the QUD or assertive proposal, and not-at-issue otherwise; and gradient mean ratings could be attributed to uncertainty about what the QUD/proposal is. For example, our interpretation of a content in a given utterance being more/less at-issue may be interpreted as reflecting the frequency or ease with which a particular QUD is attributed to that utterance.\jt{is this really a caveat to the linking function?}
  %
  Second, we use the term \enquote{at-issueness diagnostic} descriptively throughout the paper, even though our findings may ultimately suggest that these diagnostics track distinct theoretical constructs. We return to this issue in the general discussion.


\section{Experiments 1-4 \label{sec:2_experiments}}
  To compare the results of at-issueness diagnostics, we conducted four experiments that each measured at-issueness with a different diagnostic, namely the QUD diagnostic (Exp.~1), the `asking whether' diagnostic (Exp.~2), the direct-dissent diagnostic (Exp.~3) and the `yes, but' diagnostic (Exp.~4).\footnote{See the ‘Data accessibility statement’ for a link to the Github repository that provides access to the two experiments, the data,
and the analysis scripts.}
  Each experiment tested the same manipulation,\jt{do experiments test manipulations?} comparing the propositional contents\jt{see above on `propositional'?} of the seven types of expressions (contents)\jt{i don't understand this phrasing: is ``know'' a type of expression? is the complement of `know' a type of expression? and why does ``content'' occur in parentheses after ``types of expressions''? we are comparing the at-issueness of seven contents, no?} illustrated in \ref{stims}: the contents of sentence-medial and sentence-final NRRCs \ref{stims.a}-\ref{stims.b}, as well as the contents of the clausal complements of \emph{know, discover, confess, confirm} and \emph{be right} \ref{stims.c}-\ref{stims.g}. Contents were randomly paired with items from a set of items shared across all four experiments (see example pairings in \Next).\jt{this last sentence belongs in the methods section}

    \ex.\label{stims}
    \a.\label{stims.a} Content of sentence-medial NRRC \\
      \emph{Lucy, who broke the plate, apologized.} $\leadsto$ Lucy broke the plate\smallskip
    \b.\label{stims.b} Content of sentence-final NRRC \\
    \emph{The police found Jack, who saw the murder.} $\leadsto$ Jack saw the murder\smallskip
    \b.\label{stims.c} Content of the clausal complement of \emph{know} \\
    \emph{Ann knows that Raul cheated on his wife.} $\leadsto$ Raul cheated on his wife\smallskip
    \b.\label{stims.d} Content of the clausal complement of \emph{discover} \\
    \emph{Mary discovered that Denny ate the last cupcake.} $\leadsto$ Denny ate the last cupcake\smallskip
    \b.\label{stims.e} Content of the clausal complement of \emph{be right} \\
    \emph{Tom is right that Ann stole the money.} $\leadsto$ Ann stole the money\smallskip
    \b.\label{stims.f} Content of the clausal complement of \emph{confirm} \\
    \emph{Harry confirmed that Greg bought a new car.} $\leadsto$ Greg bought a new car\smallskip
    \b.\label{stims.g} Content of the clausal complement of \emph{confess}  \\
    \emph{Lucy confessed that Dustin lost his key.} $\leadsto$ Dustin lost his keys
    \z.
    \z.


    These seven contents were chosen because prior literature observed differences in at-issueness between two or more of these contents using a particular diagnostic for at-issueness.  Specifically, as discussed in \S1, \citealt{syrett_experimental_2015} observed differences between sentence-medial and -final NRRCs using a variant of the direct-dissent diagnostic,
    % \citealt{tonhauser_how_2018} observed differences between sentence-medial NRRCs and the contents of the complements of \emph{know, discover} and \emph{be annoyed} using the `asking whether' diagnostic,
    and \citealt{degen-tonhauser-glossa} observed differences between \emph{know, discover, confess, confirm} and \emph{be right} using the `asking whether' diagnostic. Thus, comparing these seven contents across the four diagnostics in Exps.~1-4 will allow us to assess whether the differences that emerge from one diagnostic also emerge from others. In each experiment, participants read the stimuli and gave ratings corresponding to the diagnostics.

  \subsection{Methods}
    
    \subsubsection{Participants}
    For each of the four experiments, we recruited 80 unique participants on Prolific. These participants had registered on the platform as living in the USA and as having English as their primary language. They had at least 50 previous submissions and an approval rate of at least 97\%. Table \ref{t:recruited} shows the age and gender distributions of the recruited participants.

      \begin{table}[h!]
      \centering
      \begin{tabular}{l | c | r r r }
                  & recruited & ages (mean age) & f/m/nb/dnd \\ \hline
      Exp.~1 (QUD) & 80 & 18-81 (43.8) & 42/37/0/1  \\
      Exp.~2 (asking whether) & 80 & 20-74 (38.5)  & 48/30/1/1  \\
      Exp.~3 (direct dissent) & 80 & 18-77 (39.1) & 50/28/1/1  \\
      Exp.~4 (yes, but) &80 & 19-67 (38.0)  & 48/30/2/0 &  \\
      \hline
      \end{tabular}

      \caption{Information about the participants recruited in Exps.~1-4 (f = female, m = male, nb = nonbinary, dnd = did not disclose).}\label{t:recruited}
      \end{table}

    \subsubsection{Materials and procedure}
      
      The four experiments measured the at-issueness of the seven contents in \ref{stims}, each using a different diagnostic: the QUD diagnostic (Exp.~1), the `asking whether' diagnostic (Exp.~2), the direct-dissent diagnostic (Exp.~3), and the `yes, but' diagnostic (Exp.~4). \ref{diag} illustrates how each diagnostic was implemented using sentence-medial NRRCs (with the item `Lucy broke the plate').\jt{this feels repetitive to examples (1)-(4) from the intro. perhaps just show Fig 2?}

      In Exp.~1 (QUD diagnostic, \ref{diag.a}), participants read a dialogue between two named speakers, where the first utters a constituent question (the presumed QUD) that is about the target content and the second responds with a declarative sentence that contributes the target content. In Exp.~2 (`asking whether' diagnostic, \ref{diag.b}), participants read a polar question uttered by a named speaker, which itself contributes the target content.
      %
      In Exp.~3 (direct-dissent diagnostic, \ref{diag.c}), participants read a dialogue between two named speakers, where the first utters a declarative sentence with the target content and the second directly dissents with the target content. 
      %
      Finally, in Exp.~4 (`yes, but' diagnostic, \ref{diag.d}), participants read a dialogue between two named speakers where the first utters a declarative sentence that contributes the target content and the second responds with one of two indirect dissent variants (\emph{yes, but..}, \emph{yes, and...}) or a direct dissent.

      \ex.\label{diag} Implementation of the diagnostics in Exps.~1-4
      \a.\label{diag.a} Exp.~1 (QUD diagnostic)
      \\ {\bf Nora:} \emph{What did Lucy break?}
      \\ {\bf Leo:} \emph{Lucy, who broke the plate, apologized.}\smallskip
      \b.\label{diag.b} Exp.~2 (`asking whether' diagnostic )
      \\ {\bf Nora:} \emph{Did Lucy, who broke the plate, apologize?}\smallskip
      \c.\label{diag.c} Exp.~3 (direct-dissent diagnostic)
      \\ {\bf Nora:} \emph{Lucy, who broke the plate, apologized.}
      \\ {\bf Leo:} \emph{No, she didn't break the plate.}\smallskip
      \d.\label{diag.d} Exp.~4 (`yes, but' diagnostic)
      \\ {\bf Nora:} \emph{Lucy, who broke the plate, apologized.}
      \\ {\bf Nina:} \emph{Yes, but she didn't break the plate.}
      \\ \hspace*{1cm} \emph{Yes, and she didn't break the plate.}
      \\ \hspace*{1cm} \emph{No, she didn't break the plate.}


      As shown in Fig.~\ref{fig:trials}, the response options differed by diagnostic. In Exp.~1 (QUD diagnostic, panel (a)), participants rated how well the response fit the question on a slider marked `totally doesn't fit' on one end (coded 0) and `totally fits' on the other end (coded as 1). In Exp.~2 (`asking whether' diagnostic, panel (b)), participants judged whether the question was about the target content, using a slider marked `no' on one end (coded as 0) and `yes' on the other (coded as 1). In Exp.~3 (direct-dissent diagnostic, panel (c)), participants rated the naturalness or the direct dissent on a slider marked `totally unnatural' (coded as 0) on one end and `totally natural' on the other (coded as 1). Finally, in Exp.~4 (`yes, but' diagnostic, panel (d)), participants chose the response that sounded best; the two indirect dissents were coded as 0 and the direct one as 1. Across the four experiments, the responses were coded so that 1 meant that the content to be diagnosed was rated as at-issue and 0 as not-at-issue.

      \begin{figure}[h!]
      \centering
      % Top row
      \subfigure[Exp.~1: QUD diagnostic]{%
        \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp1}}%
        \label{fig:trialExp1}
      }
      \hfill
      \subfigure[Exp.~2: `asking whether' diagnostic]{%
        \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp2}}%
        \label{fig:trialExp2}
      }

      \vspace{1em}

      % Bottom row
      \subfigure[Exp.~3: direct-dissent diagnostic]{%
        \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp3}}%
        \label{fig:trialExp3}
      }
      \hfill
      \subfigure[Exp.~4: `yes, but' diagnostic]{%
        \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp4}}%
        \label{fig:trialExp4}
      }

      \caption{Sample trials in (a) Exp.~1, (b) Exp.~2, (c) Exp.~3, and (d) Exp.~4.}
      \label{fig:trials}
      \end{figure}

      Each of the seven contents in \ref{stims} was combined with one of the seven items in \ref{items} in each of the four experiments.
     
      \ex.\label{items}
        \a. Jack saw the murder.
        \b. Raul cheated on his wife.
        \c. Ann stole the money.
        \d. Danny ate the last cupcake.
        \b. Lucy broke the plate.
        \b. Dustin lost his key.
        \b. Greg bought a new car.
        \z.

      Each experiment included two control stimuli serving as attention checks: one was expected to receive a response at one end of the slider (Exps.~1-3) or a `no' response (Exp.~4); the other control stimulus was expected to receive a response at the other end of the slider (Exps.~1-3) or a `yes' response (Exp.~4). See Supplement \ref{supp:stims} for the control stimuli used in Exps.~1-4.

      In all four experiments, each participant's set of items was generated by randomly combining each of the seven contents in \ref{stims} with a unique content in \ref{items}. Participants completed a total of 9 trials, namely 7 target trials and the same 2 control trials. Trial order was randomized for each participant.

      After completing the experiment, participants filled out a short optional demographic survey. To encourage truthful responses, participants were told that they would be paid no matter what answers they gave in the survey.

    \subsubsection{Data exclusion}

      We excluded the data of participants that were not self-reported native speakers of American English and of participants whose responses to one of the two control trials was more than 2 sd away from the group mean (Exps.~1--3) or whose responses to one of the two control trials was wrong (Exp.~4). Table \ref{t:excluded} shows how many participants were excluded in each experiment, demographic information for the remaining participants, and the number of data points that entered into the analyses.

      \begin{table}[h!]
        \centering
        \begin{tabular}{l | r r | r r  | r }
                     & \multicolumn{2}{c|}{\bf exclusion criterion} & \multicolumn{2}{c|}{\bf remaining participants} & data \\ 
                    & language & fillers & ages (mean age) & f/m/nb/dnd &  points \\ \hline
        Exp.~1 (QUD)   & 1 &  10 &  18-81 (41.1) & 36/32/0/1 & 621 \\ 
        Exp.~2 (asking whether) &  2 &  4 & 22-74 (38.7) & 45/27/1/1 & 666 \\ 
        Exp.~3  (direct dissent) &  2 &  7 & 18-77 (39.5) & 44/25/1/1  & 639 \\ 
        Exp.~4  (yes, but) & 4 & 4 & 19-67 (38.5)  & 43/27/2/0 & 648 \\ 
        \hline
        \end{tabular}
        \caption{Information from Exps.~1-4 about the number of participants whose data was excluded based on their self-declared language (variety) and the fillers, about the remaining participants, and about the number of data points that entered into the analysis.}\label{t:excluded}
      \end{table}

  \subsection{Results}
    Fig.~\ref{fig:results} plots the results of the four experiments by the expression that is associated with the seven target contents: panel (a) shows the mean naturalness ratings in Exp.~1 (QUD diagnostic), panel (b) mean `asking whether' ratings in Exp.~2 (`asking whether' diagnostic), panel (c) mean naturalness ratings in Exp.~3 (direct-dissent diagnostic) and panel (d) the proportion of `no' choices in Exp.~4 (`yes, but' diagnostic).

    \begin{figure}[h!]
        \centering
        % Top row
        \subfigure[Exp.~1 (QUD diagnostic)]{%
          \includegraphics[width=0.48\linewidth]{../../results+analysis/exps1-4/exp1/graphs/mean-ratings.pdf}%
          \label{fig:qud}
        }
        \hfill
        \subfigure[Exp.~2 (`asking whether' diagnostic)]{%
          \includegraphics[width=0.48\linewidth]{../../results+analysis/exps1-4/exp2/graphs/mean-ratings.pdf}%
          \label{fig:AK}
        }

        % \vspace{1em}

        % Bottom row
        \subfigure[Exp.~3 (direct-dissent diagnostic)]{%
          \includegraphics[width=0.48\textwidth]{../../results+analysis/exps1-4/exp3/graphs/mean-ratings.pdf}%
          \label{fig:dd}
        }
        \hfill
        \subfigure[Exp.~4 (`yes, but' diagnostic)]{%
          \includegraphics[width=0.48\textwidth]{../../results+analysis/exps1-4/exp4/graphs/mean-ratings.pdf}%
          \label{fig:yb}
        }
      \caption{Results of Exps.~1--4.
        Panels (a)--(c) show the mean responses by expression for (a) Exp.~1 (QUD diagnostic),  (b) Exp.~2 (`asking whether' diagnostic), and (c) Exp.~3 (direct-dissent diagnostic); panel (d) shows the proportion of `no' choices by expression in Exp.~4 (`yes, but' diagnostic). Error bars indicate 95\% bootstrapped confidence intervals. Violin plots in panels (a)-(c) show the kernel probability density of individual participants' ratings. Gray dots in panel (d) represent individual participant responses (`no' vs.\ `yes', jittered vertically and horizontally for legibility).}
      \label{fig:results}
      \end{figure}
      
      \jt{at this point, the reader expects to read about the results of the comparison. section 1 alluded to one way in which the results of the diagnostics would be compared, namely by whether they show the differences that previous research found, that is, between medial and final NRRCs, and between the five CCs of the clause-embedding predicates. but that's not what the reader gets now; rather, they read about ``range of by-content means'', which is totally surprising to the reader. my proposal would be to use this range description to help the reader digest the four panels but to not make such a big deal about it as putting it in a subsubsection suggests. also, i am not comfortable with already calling this a result that suggests anything: a diagnostic could have a very small range, but if the means for the individual contents were very small, the diagnostic might still differentiate between the contents.}

    \subsubsection{Range of by-content means}
      We observe that the results of the four experiments differ in the range of the (mean or proportion of) ratings, that is, the difference between the largest and smallest means. The range is largest in Exp.~2 (`asking whether' diagnostic), at .74 (.1 to .83) and smallest in Exp.~3 (direct-dissent diagnostic), at .13 (.64 to .78). The results of Exp.~1 (QUD diagnostic, with a range of .27 (.51 to .77) and Exp.~4 (`yes, but' diagnostic), with a range of .46 (.5 to .96), fall in between. These results suggest that the four diagnostics, as implemented here, differ in how much they differentiate between the seven contents investigated, with the `asking whether' diagnostic showing the most differentiation and the direct-dissent and the QUD diagnostic showing the least.\jt{what i mean with ``differentiation'' is whether the diagnostic suggests that two contents differ in at-issueness, not whether the means are spread out widely across the range. those are related, but different things.}

      %Exp 1
        %min: 0.5055072
        %max: 0.7713043
        %range: 0.2657971

        %Exp 2
        %min: 0.09364865
        %max: 0.8332432
        %range: 0.7395946

        %Exp 3
        %min: 0.6443662
        %max: 0.7752113
        %range: 0.1308451

        %Exp 4
        %min: .5
        %max: 0.958
        %range: 0.458

    \subsubsection{Rank order and Spearman rank correlations} 
    
    \jt{as i've pointed out above, the intro says that the contents were chosen because previous work found that they differ on some diagnostic and we'll look at whether they are also differentiated in these four diagnostics. so that would be something the reader is looking for now. this discussion here isn't about that, it is about differences between the diagnostics but not in a way that the reader will appreciate, i think; perhaps the ordering business can be mentioned after the main result is presented?}
        
      We also find that the four experiments differ in the relative ratings assigned to the seven contents, with only limited overlap. Across all experiments, \emph{confirm} and \emph{discover} consistently received higher ratings (at least numerically) than \emph{confess}, which in turn received higher ratings than medial and final NRRCs. For all other pairs of expressions, however, the ordering was not consistent. In particular, the ranking of \emph{be right} relative to most other contents is inconsistent across experiments (e.g., compared to appositive NRRCs):  The embedded content of \emph{be right} received the lowest ratings in Exp.~1, but was among the most at-issue in the other three experiments. The embedded content of \emph{know} was rated (numerically) lower than that of \emph{confirm} in Exps.~1 and 2, but higher in Exps.~3 and 4.

      This difference between the results of the experiments is quantified in the Spearman rank correlations shown in Table \ref{t:spearman}.\footnote{The Spearman rank correlation coefficient, a value between -1 and 1, is a nonparametric measure of rank correlation: the higher the absolute value of the coefficient, the more the relation between the the two variables can be described using a monotonic function. If the coefficient is positive, the value of one variable tends to increase with an increase in the other. In the case of our experiments, a coefficient of 1 for two experiments would mean that there is a perfectly monotone increasing relation between the mean ratings of the seven contents in the two experiments: for any two contents c1 and c2, if c1 ranks below c2 in one experiment (that is, the mean rating of c1 is lower than that of c2), then that ranking is preserved in the other experiment.}

      \begin{table}[ht!]
        \centering
        \begin{tabular}{l | c c c c}
        & Exp.~1 & Exp.~2 & Exp.~3 & Exp.~4 \\ \hline
        Exp.~1 (QUD diagnostic) & \cellcolor{lightgray} & .11 & -.29 & -.18 \\
        Exp.~2 (`asking whether' diagnostic) & \cellcolor{lightgray} & \cellcolor{lightgray} & .64 &.79 \\
        Exp.~3 (direct-dissent diagnostic) & \cellcolor{lightgray}& \cellcolor{lightgray} & \cellcolor{lightgray} & .79  \\
        \hline
        % Exp.~4 (`yes, but' diagnostic) & & & & \cellcolor{lightgray} \\ \hline
        \end{tabular}
      \caption{Spearman rank correlations between the results of Exps.~1-4.}\label{t:spearman}
      \end{table}

      The rank correlations are particularly low for for Exp.~1 compared to the other three experiments, at least partly because of the low relative ranking of \emph{be right}. These results suggests that the four diagnostics as implemented in Exps.~1-4 interact differently with the seven contents investigated.

    \subsubsection{Pairwise differences between expressions}
    
      Finally, the experiments differ in whether they reproduce distinctions between contents reported in prior literature.\jt{i think this should be first: first describe the differences for sentence medial and final nrrcs, and the five CCs, then present the stats} Fig.~\ref{fig:pairwise} presents the results of post-hoc pairwise comparisons of the estimated means/proportions for each content, using the `emmeans' package (\citealt{emmeans}) in R (\citealt{r}). The input to the pairwise comparisons were mixed-effects beta regression models (Exps.~1-3) or a mixed-effects logistic regression model (Exp.~4). All models were fit using the `brms' package (\citealt{buerkner2017}) using weakly informative priors. The models predicted the ratings\footnote{To model the ratings in Exps.~1-3 using a beta regression, the ratings were first transformed from the interval [0,1] to the interval (0,1) using the method proposed in \citealt{smithson-verkuilen2006}.} from a fixed effect of expression (with treatment coding and `be right' as reference level) and included random by-participant and by-item intercepts. The output of the pairwise comparison were 95\% highest density intervals (HDIs) of estimated marginal mean differences between each of the expressions. We assume that two contents differ if their HDI does not include 0.\footnote{The full model outputs are available in the folder \texttt{results+analysis/exps1-4/} in the repository linked in the Data accessibility statement.}

      Recall that \citealt{syrett_experimental_2015}, using a variant of the direct-dissent diagnostic, found that sentence-medial NRRCs are more not-at-issue than sentence-final ones. In contrast, as shown in Figs.~\ref{fig:results} and \ref{fig:pairwise}, no such difference is observed in Exps.~1-3; and in Exp.~4 (`yes, but' diagnostic), we find the opposite: sentence-final NRRCs are rated less at-issue than sentence-medial ones. Thus, none of the diagnostics as implemented in Exps.~1-4 replicate \citeauthor{syrett_experimental_2015}'s finding.

      Recall also that
      % \citealt{tonhauser_how_2018} and
      \citealt{degen-tonhauser-glossa}, using the `asking whether' diagnostic, observed  the following at-issueness differences among the content of the complement of clause-embedding predicates: \emph{know} < \emph{discover} < \emph{confess} < \emph{confirm} < \emph{be right} (where the embedded content of \emph{know} is least at-issue, and that of \emph{be right} is most at-issue). As shown in Figs.~\ref{fig:results} and \ref{fig:pairwise}, Exp.~2 (`asking whether') largely replicates this pattern, except that \emph{confess} and \emph{discover} do not differ.

      In Exp.~1 (QUD diagnostic), the embedded content of \emph{confirm} is more at-issue than that of \emph{confess, know,}, but the only other difference observed (among clause-embedding predicates) is that the embedded content of \emph{be right} is less at-issue than those of the other predicates -- the direction of this difference is the opposite from that observed in prior literature and the other experiments. In Exp.~3, no differences between the embedded contents of clause-embedding predicates are found. Finally, in Exp.~4, the content of the complement of \emph{be right} is more at-issue than those of \emph{confirm, confess,} and \emph{know}, that of \emph{confirm} is more at-issue than that of \emph{confess}, and that of \emph{discover} is more at-issue than that of \emph{confess}. These results suggest that the diagnostics, as implemented in Exps.~1-4, differ in whether they indicate differences in at-issueness between the contents of the complements of the five clause-embedding predicates included in the experiments.

      \addtolength{\tabcolsep}{-.19em}
      %
      \begin{figure}[!h]
        \centering
        \subfigure[Exp.~1 (QUD diagnostic)]{%
        \mbox{\begin{tabular}{r | ccccccc}
        & \rots{be right} & \rots{confirm} & \rots{discover} & \rots{confess} & \rots{know} & \rots{final NRRC} & \rots{medial NRRC} \\
        \hline
         be right & \cellcolor{black} & \cellcolor{red} & \cellcolor{red} & \cellcolor{red} & \cellcolor{red} & \cellcolor{red} & \cellcolor{red} \\ 
  confirm & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  discover & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
  confess & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} \\ 
  know & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} \\ 
  final NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} \\ 
  medial NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} \\ 
        \hline
        \end{tabular}}}
        \hfill
        \subfigure[Exp.~2 (`asking whether' diagnostic)]{%
        \mbox{\begin{tabular}{r | ccccccc}
        & \rots{be right} & \rots{confirm} & \rots{discover} & \rots{confess} & \rots{know} & \rots{final NRRC} & \rots{medial NRRC} \\
        \hline
         be right & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  confirm & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  discover & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  confess & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  know & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} \\ 
  final NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} \\ 
  medial NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} \\ 
        \hline
        \end{tabular}}}

        \subfigure[Exp.~3 (direct-dissent diagnostic)]{%
        \mbox{\begin{tabular}{r | ccccccc}
        & \rots{be right} & \rots{confirm} & \rots{discover} & \rots{confess} & \rots{know} & \rots{final NRRC} & \rots{medial NRRC} \\
        \hline
         be right & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
  confirm & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
  discover & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
  confess & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} \\ 
  know & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} \\ 
  final NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} \\ 
  medial NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} \\ 
        \hline
        \end{tabular}}}
        \hfill
        \subfigure[Exp.~4 (`yes, but' diagnostic)]{%
        \mbox{\begin{tabular}{r | ccccccc}
        & \rots{be right} & \rots{confirm} & \rots{discover} & \rots{confess} & \rots{know} & \rots{final NRRC} & \rots{medial NRRC} \\
        \hline
         be right & \cellcolor{black} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  confirm & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
  discover & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
  confess & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{red} & \cellcolor{blue} & \cellcolor{white} \\ 
  know & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} \\ 
  final NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{red} \\ 
  medial NRRC & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} \\
        \hline
        \end{tabular}}}
      \caption{Pairwise differences between expressions,
        ordered from top to bottom and left to right by increasing mean in Exp.~2 (`asking whether' diagnostic). A white cell means that the 95\% HDI of the pair of the row expression and the column expression includes 0, a red cell means that the 95\% HDI does not include 0 and that the coefficient is positive (the row expression received a higher rating than the column expression), and a blue cell means that the 95\% HDI does not include 0 and the coefficient is negative (the row expression received a lower rating than the column expression).}
        \label{fig:pairwise}
      \end{figure}

      These results also lend further support to the above reported finding that the four diagnostics, as implemented here, differ in how much they differentiate between the seven contents investigated. In particular, while none of the experiments found differences between medial and final NRRCs, the results of Exp.~2 (`asking whether' diagnostic) distinguished between most of the contents of the complements of the five clause-embedding predicates, whereas the results of Exp.~3 (direct-dissent diagnostic) distinguished between the least of these contents. In line with the range of means/proportions reported above, the pattern of differences between contents suggests that the `asking whether' diagnostic showed the most differentiation, while the direct-dissent and QUD diagnostics showed the least.

    

  \subsection{Discussion}
  
Exps.~1-4 were designed to compared the results of four different diagnostics of at-issueness that have been used in prior literature. The results of the experiments suggest that the diagnostics, in the particular way in which they were implemented in the experiments, differ on several dimensions.
    \begin{enumerate}
      \item They differ in the extent to which they differentiate between the seven contents investigated, as evidenced by differences in the range of mean ratings and the numbers of reliable by-content differences. The `asking whether' diagnostic (Exp.~2) showed the most differentiation and the direct-dissent diagnostic (Exp.~3) showed the least.

      \item They differ in the relative order of the seven contents. For example. the relative ranking of \emph{be right} and other contents (e.g., appositive NRRCs) differs across Exps.~1--4.

      \item They differ with respect to where they find by-content differences: For instance, Exps.~1--3 did not find the positional effect reported in \citealt{syrett_experimental_2015} for appositive NRRCs under a forced choice direct-dissent diagnostic. In our study, Exp.~4, using the `yes but' test, a forced-choice direct-response diagnostic, found an effect opposite to theirs: appositive NRRCs were more at issue in medial position, compared to final ones.

    \end{enumerate}

    This section offers discussion of these findings, particularly addressing the question why the `asking whether' exhibits the most differentiation among the diagnostics, why \emph{be right} in particular ranks high under all diagnostics except for the QUD diagnostic, and how the differences between diagnostics we found bear on whether they target distinct underlying notions of at-issueness.

    \subsubsection{Why does the `asking whether' diagnostic show greater differentiation? \label{ssub:differentiation}}
      One of the most noticeable differences between the results of the experiments is that Exp.~2 (`asking whether') showed the greatest differentiation between contents, whereas the other three experiments exhibited a smaller range of means, and fewer statistically reliable differences between investigated contents. Among the first 4 experiments, Exp.~2 was the only one that came close to differentiating fine-grained by-predicate differences as reported in \cite{degen-tonhauser-glossa}.

      To explain this difference, appeal to the divide emphasized in prior work between question-based diagnostics (QUD, `asking whether') and assertion-based diagnostics (direct-dissent, `yes, but'):\jt{is this an imperative (`appeal to...') or is something missing here?} Question-based tests are typically taken to probe whether a proposition is at issue relative to a QUD introduced in the discourse,\jt{this is very far away from how Tonhauser et al 2018 characterized the asking-whether diagnostic} whereas assertion-based diagnostics are assumed to rely on different assumptions: \citet{snider_at-issueness_2017,snider_anaphoric_2017,snider_distinguishing_2018} suggests that they reflect the anaphoric availability of propositional content to be antecedents for response particles, which may be independent of at-issueness, while others suggest that these diagnostics target a distinct notion of at-issueness relative to the proposal made by an assertion (\citealt{koev_notions_2018,faller_discourse_2019,korotkova_evidential_2020}). However, this distinction could not explain why the `asking whether' diagnostic behaves differently from the QUD diagnostic, since both are considered question-based.

      Instead, we must look to something that is present in the `asking whether' test,\jt{diagnostic?} but not the others to explain the greater by-content differentiation. Two crucial differences set apart the `asking whether' test from the other three: First, it is the only diagnostic where the target content itself occurs inside a polar question, whereas the other diagnostics test content embedded in declarative assertions. Second, it is the only diagnostic in which participants are asked directly about the intentions of the speaker, whereas the other ones collect measures that are more indirectly tied to semantic interpretation, such as acceptability ratings and continuation choices. Either of these distinctive characteristics could account for the greater differentiation. This yields two hypotheses, which we tested in Exps.~5--6, presented in \Cref{sec:3_more-experiments}.


       %  Embedding the target content in a question, or the response task, asking participants to judge speaker intentions were what we identified as likely explanatory factors.

    \subsubsection{Do ranking differences suggest different underlying notions? \label{ssub:be-right}}
    
    \jt{this subsubsection is about the odd rating for be right in Exp 1 but the subsubsection title suggests otherwise}

      The diagnostics, as implemented here, yield different rank orders regarding which contents are judged more or less at-issue. One might initially take this to suggest that different diagnostics in fact track different theoretical notions of at-issueness. However, the most striking ranking difference, between the low ranking of the complement of \emph{be right} in Exp.~1 (QUD diagnostic) and its high ranking in the other three experiments, does not appear to reflect a conceptual difference. Instead, it arises from how the QUD diagnostic interacts with additional discourse requirements of \emph{be right}. As shown in panel (a) of Fig.~\ref{fig:results}, participants gave relatively low naturalness ratings to responses like that in \ref{beright.a}, suggesting that they did not view the response as fitting the question.
      % As discussed above, the content of the complement of \emph{be right} emerged as the least at-issue in Exp.~1. 
  
      \ex.
        \a.\label{beright.a}  Exp.~1 (QUD diagnostic) with \emph{be right}
        \\ {\bf Nora:} \emph{What did Lucy break?}
        \\ {\bf Leo:} \emph{Danny is right that she broke the plate.}
        \b.\label{beright.b} Exp.~2 (`asking whether' diagnostic)
        \\ {\bf Nora:} \emph{Is Danny right that she broke the plate?}
        \c.\label{beright.c} Exp.~3 (`direct dissent' diagnostic)
        \\ {\bf Nora:} \emph{Danny is right that she broke the plate.}
        \\ {\bf Leo:} \emph{No, she didn't break the plate.}
        \d.\label{beright.d} Exp.~4 (`yes, but' diagnostic)
        \\ {\bf Nora:} \emph{Danny is right that she broke the plate.}
        \\ {\bf Leo:} \emph{Yes, but she didn't break the plate.}
        \\ \hspace*{1cm} \emph{Yes, and she didn't break the plate.}
        \\ \hspace*{1cm} \emph{No, she didn't break the plate.}

      We hypothesize that this is because \emph{be right} in \Last presupposes that Danny has previously committed to the proposition that \enquote{Lucy broke the plate} (\citealt{abusch_presupposition_2010,anand_factivity_2014}). In the three diagnostics in \Last[b--d], no previous discourse context is given, so this presupposition can be accommodated. 
      %
      In contrast, the preceding question in the QUD-diagnostic \Last[a] conflicts with the presupposition, making it difficult to accommodate. Specifically, we hypothesize that \emph{be right} signals that the question \enquote{whether Lucy broke the plate} is salient in the preceding discourse. This allows us to understand the ill-formedness based on QUD-based discourse structure, because this presupposed question is a subquestion (in the sense of \citealt{roberts_information_1996}) of the question in \Last[a] \enquote{What did Lucy break}, since every complete answer to the latter entails an answer to the former. The progression from the presupposed subquestion question to the explicitly given superquestion violates Roberts' constraint on QUD stacks (p. 6:15, (10giii)), which allows only the reverse order (from superquestions to subquestions).

      As a result, low QUD-match ratings for \Last[a] are predicted, not because the embedded clause fails to be at-issue, but because the utterance presupposes an incoherent discourse context.%
        \footnote{\label{fn:w-o-be-right}
          When \emph{be right} is excluded, the Spearman rank correlations are:

        \begin{tabular}{l | c c c c}
        & Exp.~1 & Exp.~2 & Exp.~3 & Exp.~4 \\ \hline
        Exp.~1 (QUD diagnostic) & \cellcolor{lightgray} & .77 & -.09 & -.31 \\
        Exp.~2 (`asking whether' diagnostic) & \cellcolor{lightgray} & \cellcolor{lightgray} & .66 & .66 \\
        Exp.~3 (`direct dissent' diagnostic) & \cellcolor{lightgray}& \cellcolor{lightgray} & \cellcolor{lightgray} & .77  \\
        \hline
        % Exp.~4 (`yes, but' diagnostic) & & & & \cellcolor{lightgray} \\ \hline
        \end{tabular}}
      This highlights that diagnostics may interact with contextual requirements independently of at-issueness, and such interactions must be taken into account when interpreting the results.

      Turning to other ranking differences, Fig.~\ref{fig:pairwise} shows that \emph{know} was less at-issue than \emph{confess} in Exp.~2 (`asking whether'), but more at-issue than \emph{confess} in Exp.~4 (`yes but'). We can, again, ask whether this distinction can be attributed to different underlying theoretical notions of at-issueness, such as between question-based and assertion-based conceptions of at-issueness. This interpretation is not ruled out by our data -- Exps.~1 (QUD) and 3 (direct dissent) did not detect a difference between \emph{know} and \emph{confess}, but higher-powered studies might reveal that the question-based diagnostics on the one hand and the assertion-based diagnostics on the other come to the same results. However, it is not clear how the presumed theoretical distinction would predict why \emph{confess} and \emph{know} in particular should diverge in this way. jt{this feels weak and speculative to me, i don't think we should include this. i also don't think we should discuss these rank order differences at all, given that several of them are not significant, as per Fig 4}

      Ultimately, the by-content rank differences in Exps.~1--4 do not provide conclusive evidence about whether there are distinct underlying notions of at-issueness, while the different behaviors found for \emph{be right} show that diagnostics may interact differently with the contextual requirements of the target contents in ways that may be independent from at-issueness.

    \subsubsection{Positional effects for appositive NRRCs? \label{ssub:appositives}}
        As mentioned above, none of our experiments replicated the positional effect reported in \citeposs{syrett_experimental_2015} Exp.~2, which found that sentence-final appositive NRRCs were judged more at-issue than sentence-medial ones under a variant of the direct-dissent diagnostic. They used a forced-choice task asking participants to choose a directly dissenting response that dissented with either the main clause or the target NRRC content, illustrated in \Next.\jt{this should perhaps be in the intro?}

        \ex. \citealt{syrett_experimental_2015}: (20)
          \a.[A:] My friend Sophie, a classical violinist, performed a piece by Mozart.
          \b.[B1:] No, she's not. (target: appositive)
          \b.[B2:] No, she didn't. (target: main clause)
          \z. \z. 

        In our Exp.~3, which also used a version of the `direct dissent' diagnostic, no difference between medial and final appositive NRRCs was found, and Exp.~4 (`yes but') found the opposite effect to Syrett \& Koev: here, medial NRRCs were more at-issue than final ones. For comparison, consider again how the diagnostics were implemented in Exps.~3 and 4: 

        \ex.[\ref{dd}] Exp.~3 (`direct dissent' diagnostic)
          \a.[{\bf Nora: }] \emph{Greg, who bought a new car, is envied by his neighbor.}
          \b.[{\bf Leo: }] \emph{No, that's not true, he didn't buy a new car.}
        \z. \z.
      
        \ex.[\ref{yesbut}] Exp.~4 (`yes, but' diagnostic)
        \a.[{\bf Nora: }] \emph{Greg, who bought a new car, is envied by his neighbor.}
        \b.[{\bf Leo: }] \emph{Yes, but he didn't buy a new car.} /
        \b.[] \hspace*{0em} \emph{Yes, and he didn't buy a new car.} /
        \b.[] \hspace*{0em} \emph{No, he didn't buy a new car.}
        \z. \z.

        Although the diagnostics implemented in Exps.~3 and 4 were dissent/assent-based tasks, one notable difference between our experiments and the Syrett \& Koev study, aside from the stimuli, is the response task. Exp.~3 (direct-dissent) elicited naturalness ratings for a direct-dissent response rejecting the target content \ref{dd}, rather than asking whether it would be preferred over rejecting the main clause content. Exp.~4 (`yes but') collected forced-choice continuation judgments for direct-dissent responses, like Syrett \& Koev, but the alternative choices were different: For a response contradicting the target content, participants chose between expressing dissent (\emph{no}), expressing assent and contrast (\emph{yes, but}), or expressing assent and no contrast (\emph{yes, and}).

        Taken together, these findings suggest that positional effects for appositive NRRCs may not be robust across diagnostics, and even small changes in the response task used to operationalize a diagnostic, such as alternative choices in a forced-choice continuation study, might reverse the observed pattern, and different diagnostics vary in whether they detect any positional difference for appositive NRRCs at all. This suggests that previously reported effects may reflect task- or diagnostic-specific artifacts rather than stable properties of NRRC interpretation. A natural follow-up would be to test whether applying their particular forced-choice schema to our stimuli would reproduce their effect.
        
        \jt{i agree with you on this point but i don't think it warrants its own subsubsection, and it could be dramatically shorter, like a single paragraph, especially if (9) is in the intro}


    \subsubsection{Interim conclusion}
    
    \jt{i don't think we need interim conclusions: the results are really not that hard to keep in mind and this interrupts the flow from the point about the asking-whether diagnostic to motivating experiments 5-6}
    
      The findings from Exps.~1--4 show that the four diagnostics are not interchangeable: they differ in how strongly they differentiate among the tested contents, in the relative ranking between them, and in how they interact with discourse requirements imposed by particular expressions.

      One source of diagnostic differences arises from interactions between diagnostics and discourse requirements of particular expressions. As discussed in \Cref{ssub:be-right}, the low Q+A match ratings for the complement of \emph{be right} in Exp.~1 do not reflect low at-issueness, but rather a conflict between the QUD-diagnostic and a presupposition that the embedded proposition was already under discussion. Such presuppositional requirements can depress ratings independently of at-issueness and therefore mask the intended diagnostic signal.

      A second source of diagnostic differences may stem from differences in response tasks, even within dissent-based diagnostics. As discussed in \Cref{ssub:appositives}, we did not replicate Syrett \& Koev's positional effect for appositive NRRCs, and Exp.~4, using the assent/dissent-based yes-but diagnostic (Exp. 4), showed the a positional effect in the opposite direction. This suggests that even small response task differences may make a difference, such as different alternative choices in a dissent-based forced-choice continuation task. 

      Further, our data do not provide clear evidence for or against this possibility that diagnostic differences reflect different underlying notions of at-issueness. As discussed in \Cref{ssub:be-right}, Some by-predicate ranking differences emerged, but these were did in line with the distinctions suggested in the literature and remain inconclusive. 

      Finally, the largest source of diagnostic differences among Exps.~1--4 concerns the `asking whether' diagnostic (Exp.~2), which showed strikingly greater differentiation among contents than the other three diagnostics. As discussed in discussed in Section \ref{ssub:differentiation}, it yielded a wider range of mean ratings and a greater number of reliable contrasts than the other three diagnostics, and it was the only test that approached the fine-grained predicate-level differences reported in \citet{degen-tonhauser-glossa}. This raised the question of whether the increased sensitivity is due to interrogative embedding or to the specific response task.

      The next section addresses this question directly, reporting on two further experiments, which compare the asking-whether diagnostic to a diagnostic that also embeds the target content in a polar question but uses naturalness ratings for a direct response to assess at-issueness. Both experiments yielded similarly fine-grained distinctions among contents -- a finding we take as evidence that the greater variation observed in Exp.~2 is driven primarily by interrogative embedding rather than the response task.

         
\section{Experiments 5 and 6 \label{sec:3_more-experiments}}
  %
    Exps.~5 and 6 investigate whether the greater differentiation observed in Exp.~2 (`asking whether') was due to (i) embedding target contents in polar questions or (ii) the response task, testing two hypotheses:
    \begin{enumerate}
      \item \textbf{Question-embedding hypothesis:} Differentiation between contents (in terms of range of means and significant differences\jt{as i've mentioned above, these don't always go together; i'd focus on the 2nd}) is greater when contents are embedded in a polar question than in a declarative assertion.\jt{`polar question' is a sentence type; `declarative assertion' is both sentence type and speech act}

      \item \textbf{Response-task hypothesis:} Differentiation is greater when participants are asked directly what the utterance is about, compared to tasks such as acceptability judgments or forced-choice continuations.

    \end{enumerate}

    To test these hypotheses, we compared two diagnostics that both embed the target content in a polar question but differ in the response task. Exp.~5 used the `asking whether' diagnostic as in Exp.~2 \Next[a] and Exp.~6 uses a `direct response' diagnostic, shown in \Next[b], where participants read a dialogue between two named speakers, where the first utters a polar question, which contributed the target content.\jt{this sentence is too long} Like in the direct-assent/dissent diagnostic, the second speaker utters `yes' answer and affirms the target content.


  
    \ex. Implementation of the diagnostics in Exps.~  5--6 
      \a.\label{exp5} Exp.~5 (`asking whether' diagnostic )
      \\ {\bf Nora:} \emph{Is Tom right that Lucy broke the plate?}
      \\ Question to participants: Is Nora asking whether Lucy broke the plate?
      \b.\label{exp6} Exp.~6 (direct-response diagnostic)
      \\ {\bf Nora:} \emph{Is Tom right that Lucy broke the plate?}
      \\ {\bf Leo:} \emph{Yes, she didn't break the plate.}
      \\ Question to participants: How natural is Leo's response to Nora's question?

  

    Both experiments measured at-issueness for\jt{of?} the contents of the complements of the 20 clause-embedding predicates from \citealt{tonhauser_how_2018} and \citealt{degen-tonhauser-glossa}, listed in \Next.\jt{if they need to be repeated (which i don't think they do), then they should be ordered alphabetically}

    \ex. \label{ex:predicates}
        20 clause-embedding predicates from \citealt{tonhauser_how_2018,degen-tonhauser-glossa}:\smallskip\\ 
        \emph{be annoyed, know, pretend, inform, see, hear, discover, acknowledge, think, admit, announce, reveal, confess, demonstrate, suggest, prove, establish, say, confirm, be right}
        \z. 
      
    Both experiments also measured projection data\jt{measured the projection of?} for the embedded contents\jt{ccs?} of the 20 clause-embedding predicates, which were reported in \citealt{hofmann-etal2024}. Here we focus on the at-issueness data, which have not yet been reported.

    If the greater differentiation between contents found in Exp.~2 (compared to Exps.~1, 3,  and 4) was due to presenting the target content in a polar question, we expect that results from Exps.~5 and 6 both show a similar differentiation between contents -- namely comparable range of means and comparable sensitivity to differences between contents.\jt{what if only one of these came out? and how does one measure comparable range of means? we have no stats to back this up. i would omit the range considerations. also, the phrasing ``comparable sensitivity to differences between contents'' presupposes that the contents differ and we're just trying to find a diagnostic that shows these differences. but i don't think we should be conveying that presupposition} In contrast, if the `asking whether' diagnostic again shows greater differentiation between contents than the direct-response diagnostic, this would support the response-task hypothesis, suggesting that the task, rather the question embedding, drives the effect.

  \subsection{Methods}
    
    \subsubsection{Participants}

      We recruited 300 participants on Amazon's Mechanical Turk platform for Exp.~5 and 250 participants on Prolific for Exp.~6.\footnote{Exp.~5 was run in August 2019 and Exp.~6 in August 2021.} Participants recruited on Mechanical Turk had U.S.\ IP addresses and at least 99\% of previous HITs approved. Participants recruited on Prolific had registered as U.S.-born native speakers of English residing in the USA and had an approval rate of at least 99\%. Table~\ref{t:recruited2} summarizes the age and gender distributions of the recruited participants.

      \begin{table}[h!]
      \centering
      \begin{tabular}{l | c | r r r }
                  & recruited & ages (mean age) & f/m/nb/dnd \\ \hline
      Exp.~5 (asking whether) & 300 & 19-74 (38.2) & --/--/--/--  \\
      Exp.~6 (direct assent) & 250 & 18-58 (25.5)  & 201/43/6/0  \\
      \hline
      \end{tabular}

      \caption{Information about the participants recruited in Exps.~5-6 (f = female, m = male, nb = nonbinary, dnd = did not disclose; gender information was not collected in Exp.~5).}\label{t:recruited2}
      \end{table}

    \subsubsection{Materials and procedure}

      Each of the 20 clause-embedding predicates in \ref{ex:predicates} was combined with one of 20 embedded-clause items\jt{they were referred to differently above} (listed in Supplement \ref{supp:a-clauses}). The two experiments also included the same six control stimuli.\jt{the introduction of the target stimuli should be completed first: how many target stimuli in each experiment? what was their shape in each experiment? etc} The contents of these control stimuli (details in Supplement \ref{supp:control56}) were expected to be at-issue and were used to assess participants' attention. In both experiments, each participant's set of items was generated by randomly combining each of the 20 clause-embedding predicates in \ref{ex:predicates} with a unique item. Participants saw a total of 26 stimuli: one target stimulus for each of the 20 clause-embedding predicates and the same 6 control trials.\footnote{Each participant saw their set of 26 stimuli twice, once in the projection block and once in the at-issueness block. Block order was randomized. As mentioned above, we focus here on the at-issueness data.} Trial order was randomized for each participant.
  	
      Participants were asked to imagine that they are at a party and that, when walking into the kitchen, they overhear somebody say something to somebody else.\jt{this might be easier if you refer to Fig 5}

      As shown in Fig.~\ref{fig:trials56}, the response task differed between experiments. In Exp.~5 (`asking whether' diagnostic, panel (a)), participants judged whether the question was about the target content, using a slider marked `no' on one end (coded as 0) and `yes' on the other (coded as 1). In Exp.~6 (direct-response diagnostic, panel (b)), participants rated whether the response to the first speaker sounds good, on a slider marked `no' (coded as 0) on one end and `yes' on the other (coded as 1). Across both experiments, the responses were coded so that 1 meant that the content to be diagnosed was rated as at-issue and 0 as not-at-issue.\jt{would it be better to talk about higher ratings meaning higher not-at-issueness? how was this done in exps 1-4?}

      \begin{figure}[h!]
      \centering
      % Top row
      \subfigure[Exp.~5: `asking whether' diagnostic]{%
        \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp5}}%
        \label{fig:trialExp5}
      }
      \hfill
      \subfigure[Exp.~6: direct response diagnostic]{%
        \fbox{\includegraphics[width=0.47\textwidth]{figures/trialExp6}}%
        \label{fig:trialExp6}
      }

      \caption{Sample trials in (a) Exp.~5 and (b) Exp.~6.}
      \label{fig:trials56}
      \end{figure}
      
      \jt{something needs to be said about the projection ratings, the two blocks, the order of the two blocks, etc.}

      After completing the experiment, participants filled out a short optional demographic survey. To encourage truthful responses, participants were told that they would be paid no matter what answers they gave in the survey.

    \subsubsection{Data exclusion}
    
      We excluded the data of participants who did not self-identify as native speakers of American English, of participants whose responses to the projection or at-issueness controls were more than 2 sd away from the group mean, and of participants who always selected roughly the same point on the response scale for the target stimuli.\jt{did we do this latter one in exps 1-4 as well?} To identify such participants, we first identified participants whose mean variance on the target stimuli was more than 2 sd below the group mean variance and then manually inspecting their response patterns. Due to a programming error, 5 participants took Exp.~5 more than once. Since we were not able to identify which submission was their first submission, the data of these participants was also excluded. Table \ref{t:excluded2} shows how many participants were excluded in each experiment, the properties of the remaining participants, and the number of data points that entered into the analyses.

      % {\bf table should show final number of participants, exp 5: 242; exp 6: }
        
      \begin{table}[h!]
        \centering
        \resizebox{\linewidth}{!}{
        \begin{tabular}{l | r r r | r r r | r }
                     & \multicolumn{3}{c|}{\bf exclusion criterion} & \multicolumn{3}{c|}{\bf remaining participants} & data \\ 
                    & language & controls & variance & ages (mean age) & f/m/nb/dnd & total &  points \\ \hline
        Exp.~5 (asking whether)  & 7 &  35 & 0 &  21-74 (39.2) & --/--/--/-- & 242 & 6292 \\ 
        Exp.~6 (direct assent) &  5 &  24 & 1 & 18-58 (24.9) & 187/28/5/0 & 220 & 5720 \\ 
        \hline
        \end{tabular}}
        \caption{Information from Exps.~5-6 about the number of participants whose data was excluded based on their self-declared language and language variety (`language'), the controls, and the variance of their responses, about the remaining participants, and about the number of at-issueness data points that entered into the analysis.}\label{t:excluded2}
        \end{table}

  \subsection{Results}
    Fig.~\ref{fig:results2} plots the results of the two experiments by embedding predicate: panel (a) shows the mean `asking whether' ratings in Exp.~5 (`asking whether' diagnostic) and panel (b) shows the mean acceptability ratings in Exp.~6 (direct-response diagnostic).


\jt{can the two plots in Fig 6 go side by side?}

    \begin{figure}[h!]
      \centering
      
      \subfigure[Exp.~5 (`asking whether' diagnostic)]{%
        \includegraphics[width=0.7\linewidth]{../../results+analysis/exps5-6/exp5/graphs/mean-ratings.pdf}%
        \label{fig:results5}
      }

      \subfigure[Exp.~6 (`direct assent' diagnostic)]{%
        \includegraphics[width=0.7\linewidth]{../../results+analysis/exps5-6/exp6/graphs/mean-ratings.pdf}%
        \label{fig:results6}
      }

      \caption{Results of Exps.~5--6. The panels show the mean ratings by expression for (a) Exp.~5 (asking whether diagnostic) and (b) Exp.~2 (direct assent diagnostic). Error bars indicate 95\% bootstrapped confidence intervals. Violin plots show the kernel probability density of individual participants' ratings.}
      \label{fig:results2}
    \end{figure}


    \subsubsection{Range of by-content means} 

      We observe that the results of the four \jt{two?} experiments show a similar range of the mean ratings (again quantified as the difference between the largest and smallest by-content means). The range in Exp.~5 (`asking whether' diagnostic) is .75 (.07 to .82) and in Exp.~6 (direct-response diagnostic), it is .73 (.09 to .82). While results of Exps.~1--4 showed clear variation in the range of the by-content means, the same cannot be said about the results of Exps.~5 and 6.\jt{to me, this is not the most exciting point and it doesn't warrant its own subsubsection. if anything, i'd include it somewhere after the main result.}

    \subsubsection{Rank order and Spearman rank correlations} 
        
      We also find a high degree of consistency in the relative ratings across the 20 contents: predicates whose embedded content is rated relatively at-issue in Exp.~5 are also rated relatively at-issue in Exp.~6, and vice-versa.This correspondence is reflected in a Spearman rank correlation of $.93$ between the results of Exps.~5 and 6, suggesting a particularly strong rank correlation for the by-content means. This result suggests that the two diagnostics as implemented in Exps.~5 and 6 interact similarly with the 20 target expressions investigated, when those are presented in a question embedding.\jt{same comment as above}

    \subsubsection{Pairwise differences between expressions}  
      
      Fig.~\ref{fig:pairwise2} presents the results of post-hoc pairwise comparisons of the estimated means for each content. As in \Cref{sec:2_experiments}, these were done using the `emmeans' package (\citealt{emmeans}) in R (\citealt{r}), based on mixed-effects beta regression models, that were fit using the `brms' package (\citealt{buerkner2017}) using weakly informative priors.  The models predicted ratings from a fixed effect of expression (with treatment coding and `be right' as the reference level).\jt{need that footnote again about converting [0,1] to (0,1)}

      \begin{figure}[!h]
      \centering

      \subfigure[Exp.~5 (`asking whether' diagnostic)]{%
      \resizebox{.65\linewidth}{!}{
      \begin{tabular}{r | ccccc ccccc ccccc ccccc}
      & \rots{be right} & \rots{confirm} & \rots{say} & \rots{establish} & \rots{prove} & \rots{suggest} & \rots{demonstrate} & \rots{announce} & \rots{reveal} & \rots{admit} & \rots{confess} & \rots{think} & \rots{acknowledge} & \rots{pretend} & \rots{see} & \rots{discover} & \rots{hear} & \rots{inform} & \rots{know} & \rots{be annoyed} \\
      \hline
       be right & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  confirm & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  say & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  establish & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  prove & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  suggest & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  demonstrate & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  announce & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  reveal & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  admit & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  confess & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  think & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  acknowledge & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  pretend & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  see & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  discover & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  hear & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} \\ 
  inform & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} \\ 
  know & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} \\ 
      \hline
      \end{tabular}}}

      \subfigure[Exp.~6 (`direct assent' diagnostic)]{%
      \resizebox{.65\linewidth}{!}{
      \begin{tabular}{r | ccccc ccccc ccccc ccccc}
      & \rots{be right} & \rots{confirm} & \rots{say} & \rots{establish} & \rots{prove} & \rots{suggest} & \rots{demonstrate} & \rots{announce} & \rots{reveal} & \rots{admit} & \rots{confess} & \rots{think} & \rots{acknowledge} & \rots{pretend} & \rots{see} & \rots{discover} & \rots{hear} & \rots{inform} & \rots{know} & \rots{be annoyed} \\
      \hline
       be right & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  confirm & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  say & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  establish & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  prove & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  suggest & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  demonstrate & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{red} & \cellcolor{red} & \cellcolor{white} & \cellcolor{red} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  announce & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  reveal & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  admit & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  confess & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  think & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  acknowledge & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  pretend & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{red} & \cellcolor{red} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} \\ 
  see & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{red} & \cellcolor{white} & \cellcolor{white} & \cellcolor{white} & \cellcolor{blue} \\ 
  discover & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  hear & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} & \cellcolor{blue} & \cellcolor{blue} \\ 
  inform & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{white} & \cellcolor{blue} \\ 
  know & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{black} & \cellcolor{blue} \\ 
      \hline
      \end{tabular}}}

      \caption{Pairwise differences between expressions, ordered from by increasing mean in Exp.~5 (`asking whether'). White cells indicate that the 95\% HDI of the difference includes 0. Red cells indicate a positive difference (the row expression received a higher rating than the column expression), and blue cells indicate a negative difference.}\label{fig:pairwise2}
      \end{figure}

      Overall, the two experiments show broadly similar results: both reveal reliable pairwise distinctions among many of the expressions and \jt{yield comparable rank orderings -- isn't this a repetition?}. The ordering among the clause-embedding predicates found in \citealt{degen-tonhauser-glossa}—\emph{know} < \emph{discover} < \emph{confess} < \emph{confirm} < \emph{be right} (which were largely replicated in Exp.~2) is found in both Exps.~5 and~6.\jt{this too?, this isn't about the results shown in Fig 7 but about the rank orderings?}

      There are some differences between the two experiments: In Exp.~5, the complement predicate \emph{demonstrate} is more at issue than the complement of a range of predicates, including \emph{announce, reveal,} and \emph{confess}, but in Exp.~6, the embedded content of \emph{demonstrate} is comes out as less at issue than the content of those three predicates.

        Other differences between the two experiments include that in Exp.~5 \emph{prove} and \emph{suggest} are more at-issue than \emph{reveal} and \emph{confess}, \emph{think} and \emph{acknowledge} are more at-issue than \emph{discover} and \emph{hear}, \emph{pretend} and \emph{see} are more at issue than \emph{inform} and \emph{know}, where Exp.~6 finds no differences. Conversely, in Exp.~6 \emph{confirm} and \emph{say} are more at-issue than \emph{establish}, \emph{pretend} is less at issue than \emph{discover} and \emph{hear}, \emph{see} is less at issue than \emph{discover}, where Exp.~5 finds no difference.

      There are, however, some minor differences between the two experiments.\jt{didn't the text above also point out differences?} In Exp.~5, the complement of \emph{demonstrate} is rated as more at-issue than those of \emph{announce}, \emph{reveal}, and \emph{confess}, whereas in Exp.~6 it is rated as less at-issue than the complement of those same predicates.

      In the results of Exp.~5, several differences also come out as reliable,\jt{what does `reliable' mean?} where no difference is observed in Exp.~6: (i) \emph{prove} and \emph{suggest} are more at-issue than \emph{reveal}; (ii) \emph{confess}, \emph{think}, and \emph{acknowledge} are more at-issue than \emph{discover} and \emph{hear}; and (iii) \emph{pretend} and \emph{see} are more at-issue than \emph{inform} and \emph{know}. Conversely, Exp.~6 reveals differences not found in Exp.~5, including that: (i) \emph{confirm} and \emph{say} are more at-issue than \emph{establish}; (ii) \emph{pretend} is less at-issue than \emph{discover} and \emph{hear}; and (iii) \emph{see} is less at-issue than \emph{discover}.
      
      \jt{I don't think all the differences need to be spelled out here; the reader can look for themselves. we should hit the highlights.}

      Taken together, these results suggest that while the diagnostics as implemented in Exps.~5 and 6, may differ slightly in which distinctions they detect, their overall patterns of at-issueness judgments\jt{no at-issueness judgments were given} are highly similar.

  % \addtolength{\tabcolsep}{-.19em}

    

  \subsection{Discussion \label{ssec:5-6-discussion}}

    Our results suggest that the `asking whether' and direct response diagnostic, as implemented in Exps.~5 and 6 yielded highly similar results for the 20 contents investigated: both showed comparable ranges of by-content means, a particularly strong Spearman rank correlation ($r_s = .93$), and fine-grained differentiation among the 20 contents tested. This supports the idea that their shared feature of presenting the target content embedded in a question is what drives the high by-content differentiation observed in Exps.~2, 5, and 6 compared to Exps.~1, 3, and 4.

    Nonetheless, small differences remain, for example in which by-content contrasts reached significance and in the precise rank ordering of contents. Since both tests used identical embedding contexts and both reflect a QUD-based conception of at-issueness, these differences may stem from the distinct response tasks used: judging what a question is about versus (Exp.~5) evaluating the naturalness of a response (Exp.~6). This suggests that differences in response task affect at-issueness judgments in subtle ways.

\jt{this is not a discussion but a summary of the results, plus very brief discussion statements. perhaps fold them into the results subsection, which one could rename `results and discussion'?}

\section{General discussion \label{sec:4_discussion}}
  %
    Different diagnostics of at-issueness yield different results. Some of the differences between the diagnostics as implemented here appear to be due to presenting the target expressions embedded in \jt{polar} questions, some of them have to do with how the diagnostics interact differently with the discourse requirements imposed by the tested expressions,\jt{is this about ``be right''? if so, that's a super tiny point compared the point about interrogative vs.\ declarative -- should it really be mentioned here on the same level?} and others may have to do with response task differences,\jt{which of our results support this?} or different underlying notions of at-issueness.\jt{very little has been said about notions of at-issueness; i don't see this as a point on par with the interrogative vs.\ declarative one} In our investigation, the factor leading to the most striking differences was whether or not the tested target content is embedded in a question, so the speech act in which it appears\jt{do contents appear in speech acts? also, the particular speech act was not mentioned yet, unless ``question'' for you is both a sentence type and a speech act?} needs to be taken into consideration when considering what at-issueness is\jt{this is a very big claim, not one that should appear in this summary of results. perhaps you mean ``when considering how at-issueness is diagnosed?''} and how it is diagnosed.\jt{oh, i guess you really meant ``what at-issueness is''.} In the following, we discuss in some more detail the questions of why question embeddings matter for diagnosing at-issueness (\Cref{ssec:discussion-questions}); what are factors that may affect the diagnostic differences, and what this can tell us about different underlying notions of at-issueness (\Cref{ssec:discussion-differences}); then we discuss methodological implications of our findings (\Cref{ssec:discussion-methodological}).
  
  \subsection{Speech act, at-issueness, and projection \label{ssec:discussion-questions}}
  
    We found that the speech act in which the tested content appears makes a difference:\jt{did we? or is that a hypothesis for which we found support? i also think that the reader needs to be guided more towards the declarative/assertion vs.\ polar interrogative/question (or info-seeking?) connection} presenting the target expression in a question leads to greater by-content differentiation than presenting it in an assertion. As discussed briefly in \Cref{ssub:differentiation}, this contrast may seem to reflect the contrast highlighted in previous literature between question-based and assertion-based diagnostics for at-issueness.\jt{isn't the contrast described in prior literature as qud- vs proposal-based?} Recall that question-based diagnostics (such as the QUD-diagnostic and `asking whether' test) have been taken to assess whether a proposition is at issue relative to a question under discussion (\citealt{amaral_review_2007,simons_what_2010,tonhauser_diagnosing_2012,tonhauser_how_2018}). In contrast, assertion-based diagnostics (such as the direct-dissent and `yes, but' tests) have been suggested to target a different notion of at-issueness, tied to the speech act of assertion (\citealt{koev_notions_2018,faller_discourse_2019,korotkova_evidential_2020}).\jt{i disagree with this characterization of the literature. i think you're going too far away from the literature too quickly} Here, the assumption is that only at-issue content can contribute an assertive proposal that may be accepted or rejected, while not-at-issue content is presupposed or automatically added to the common ground (\citealt{potts_logic_2005,murray_varieties_2014,anderbois_at-issue_2015}).

    Our generalization, however, is not about whether the target content can be understood as at-issue relative to a QUD versus an assertion made by the utterance.\jt{I don't understand this sentence} Rather, it concerns the speech act in which the content is presented.\jt{again, are contents presented in speech acts?} When target contents were presented in questions, as in the `asking whether' diagnostic (Exps.~2, 5) and the direct-response diagnostic used in Exp.~6, we observed high by-content differentiation. In contrast, when the same contents were presented in declarative assertions, as in the QUD diagnostic (Exps.~1), and the assertion-based diagnostics (Exps.~3, 4), the resulting ratings showed less differentiation. This pattern suggests that at-issueness diagnostics which embed target content in questions are suited to reveal more differentiated by-content differences than those embedding content in assertions.
    
This finding can be understood if we assume that participants are better able to distinguish at-issue from not-at-issue content when these two contents have more distinct pragmatic roles,\jt{`pragmatic roles' is not a term i am familiar with} and questions provide an environment where that is the case. We hypothesize the relevant contrast\jt{between what?} lies in how at-issue and not-at-issue content relate to speaker commitments: In assertions, but not in questions, the speaker commits to the truth of the at-issue proposition. Not-at-issue content, in contrast, projects\jt{not from positive assertions} and thus contributes to speaker commitment regardless of speech act (see \citealt{potts_logic_2005,abusch_presupposition_2010,simons_what_2010,abrusan_predicting_2011,tonhauser_how_2018,degen-tonhauser-glossa}). As a result, at-issue and not-at-issue content are pragmatically more distinct in questions,\jt{``pragmatically more distinct'' is very vague} making it easier for participants to distinguish the two levels of meaning.\jt{`level' implies that at-issue and not-at-issue content live on distinct dimensions?} Embedding target content in questions therefore allows for detection of more fine-grained differences in at-issueness associated with the conventional meaning of particular expressions, whereas assertions introduce a confounding factor: the speaker commits to both levels of content, reducing differentiation in at-issueness judgments.\jt{what's missing here is something on why embedding in questions differentiates better between different not-at-issue contents; so far, this has all been about differentiating at-issue and not-at-issue content (which our experiments did not investigate)}

    For concreteness, \Next illustrates how the at-issue content of a polar question introduces a set of question alternatives and partitions the context set without committing the speaker to any particular alternative (\citealt{groenendijk_studies_1984,ginzburg_interrogatives_1996,roberts_information_1996}). In contrast, the not-at-issue content expressed by the appositive NRRC (\emph{Greg bought a car}) is assumed to be true across all question alternatives, and thus throughout the entire context set, giving rise to projection \citep{abusch_presupposition_2010,simons_what_2010,abrusan_predicting_2011,tonhauser_how_2018}.

    \ex. $\llbracket\textit{Is Greg, who bought a car, envied by his neighbor?}\rrbracket =$\\
      \phantom. \hfill$\{\textnormal{Greg, who bought a car, is envied by his neighbor},$\\
      \phantom. \hfill$\textnormal{Greg, who bought a car, is not envied by his neighbor}\}$
    \z.

    Because the not-at-issue proposition projects, it is treated as part of the speaker's commitments, while the at-issue proposition is not. We suggest that this sharp epistemic contrast between the two contents may make it easier for listeners to distinguish between levels of meaning. Questions therefore provide a particularly a good environment for detecting fine-grained differences in at-issueness associated with the conventional meaning of particular expressions.\jt{this repeats what was said above, almost verbatim}

\jt{the paragraph around 12 is about a sentence-medial NRRC, which is maximally different in terms of at-issueness and speaker commitment from the at-issue content, which is at-issue and the speaker is not committed. you suggested above that speaker commitment is relevant. so when we have content that is not as clearly not-at-issue as sentence-medial NRRCs, like the CC of ``discover'' or of ``reveal'', why does embedding in questions help bring out differences between them? i don't see how the example in 12 helps explain this, or something is missing}
    
\jt{does this imply that embedding under negation should also not work so well (commitment to negated at-issue content) but embedding under ``perhaps'' (or another epistemic modal) should? don't we have experiments like Exp 6 but with embedding under ``perhaps'' and with embedding under negation?}

    This reasoning helps explain why the two question-based diagnostics yielded highly similar results. Both the asking whether diagnostic used in Exps.~2 and 5 and the direct-response diagnostic used in Exp.~6 embed the target content $p$ in a polar question, as in \Next, where $p$ is the proposition that \emph{Tony had a drink last night} introduced by the complement of \emph{discover}.
  
    \ex. \emph{Did Helen confirm that Tony had a drink last night?} \z. 
  
  In the `asking whether' diagnostic, ratings of how much participants take the question to be about \emph{whether} $p$ (in this case: about whether \emph{Tony had a drink last night}) are taken to reflect whether $p$ is delineates the question partition introduced by the at-issue content of \Last, and thus how readily $p$ is interpreted as at-issue. Similarly, Exp.~6 assessed how naturally a direct response to \Last with \emph{yes} $p$ or \emph{no, not} $p$ is taken as an answer to the question, that is, how naturally they are construed as selecting among the question alternatives. Both diagnostics therefore probe how central $p$ is to the question raised by the utterance.\jt{i don't understand how this paragraph around (13) relates to the hypothesis about question embedding; is it supposed to further support it? it seems to merely explain the two diagnostics?}
  
  Thus, if certain constructions or expressions bias their associated content toward being interpreted as at-issue or not-at-issue\jt{this sounds very categorical, which is not consistent with our results}, interrogatives provide a clear window onto these by-content differences.\jt{this does not follow from what has been said above} For instance, since the complement of \emph{confirm} received higher asking-whether ratings in Exp.~2 than the content of appositive NRRCs, we can say that the complement of \emph{confirm} is more at-issue than the content of appositive NRRCs (or more likely to be interpreted as at-issue under a categorical conception of at-issueness). An important question for research on at-issueness is why certain expressions lead to their associated content being interpreted as more or less at-issue, which lexical properties can affect this and how (e.g., \citealt{abrusan_predicting_2011,anand_factivity_2014,schlenker_triggering_2021,anand_facts_2024,bade_new_2024,bade_word_2024}).

    In contrast, when the same contents are presented in declarative assertions, shown \Next and \NNext, as in the QUD diagnostic (Exp.~1) and the assertion-based diagnostics (Exps.~3 and 4), the utterance signals that speaker is committed to the main clause at-issue content. 

    \ex. \emph{Greg, who bought a car, is envied by his neighbor.}
      \a. $\rightarrow$ \emph{Greg bought a car.} (target content)
      \b. $\rightarrow$ \emph{Greg is envied by his neighbor.} (main clause content)
    \z.\z.

    \ex. \emph{Helen confirmed that Tony had a drink last night.} 
      \a. $\rightarrow$ \emph{Tony had a drink last night.} (target content)
      \b. $\rightarrow$ \emph{Helen confirmed that Tony had a drink last night.} (main clause content) 
    \z.\z.

  At the same time, not-at-issue content, like that expressed by appositive NRRCs or certain embedded propositions, projects\jt{there is no entailment-canceling operator, at least in 14,  and therefore no projection. and i'm not comfortable saying that the CC projects in 15 from under ``confirmed'' -- this is very far away from how people talk about projection; speaker commitment is fine, of course} and thus also becomes part of the speaker's commitments. In assertions, the speaker is thus committed to both the main at-issue and the not-at-issue content.\jt{i'm not following at all. are you saying that the speaker of 15 is committed to the CC? and the same with all the other clause-embedding predicates?} As a result, at-issue and not-at-issue content are pragmatically more similar\jt{``pragmatically more similar'' is too vague} in assertions, and we suggest that this makes it harder for participants to distinguish the two levels of meaning. This assumption could helps explain why these diagnostics yielded less by-content differentiation than the question-based diagnostics: they might be overall less sensitive to the difference between at-issue and not-at-issue content, essentially creating a ceiling effect.

  To our knowledge, no previous literature has proposed that the speech act in which target content is presented can itself be a major driver of differentiation. Here, we saw that questions more transparently reveal how different contents can be interpreted as at-issue or not-at-issue, and suggested that this may be because the two contents differ in their commitment status. Assertions, in contrast, commit the speaker both to the at-issue assertion as well as the projected not-at-issue content, thereby obscuring the distinction. Consequently, diagnostics that embed the target content in questions provide a particularly sensitive test of at-issueness.



  \subsection{Diagnostic differences and notions of at-issueness \label{ssec:discussion-differences}}
  
    Our study addressed two related questions about at-issueness diagnostics: First, we asked to what extent different diagnostics yield consistent results when applied to the same linguistic stimuli. Second, by examining the convergence and divergence across diagnostics, we aimed to assess whether these differences reflect distinct theoretical notions of at-issueness or instead arise from methodological differences in how a single underlying phenomenon is operationalized.\jt{as far as i'm concerned, the second question has not yet been addressed. i think it may be better to make the paper just about the first one, and bring the second one up in the General Discussion only. of course, the business about some diagnostics being about q-at-issueness and some about p-at-issueness needs to stay in section 1}

    Across Exps.~1--4, we found clear evidence that the four diagnostics implemented there are not interchangeable: they interact differently with the seven tested contents, and the relative rank orderings of content means do not align uniformly across experiments. Aside from the robust ordering \emph{confess} $\leq$ \emph{discover}, no pairwise difference between contents goes in the same direction across all diagnostics. At the same time, the most striking differences between diagnostics appear to be explainable by factors other than distinct underlying notions of at-issueness.\jt{this paragraph just repeats the results but it's not clear why -- what's the question being addressed?}
    
    First,\jt{what are we counting? rhetorical structure is unclear} as discussed in detail in \Cref{ssec:discussion-questions}, the speech act in which the target content is presented plays a major role. Diagnostics that embed the target content in questions consistently yielded greater differentiation than those that embed it in declarative assertions. This finding, however, is orthogonal to the question whether there are distinct underlying notion of at-issueness:\jt{so why start with that?} it is compatible both with the view that all diagnostics target a single underlying notion and with the view that there are fundamentally different concepts of what the main point of an utterance is given a question or QUD versus given an assertive proposal.\jt{i think it's worthwhile repeating the q- and p-based definitions of at-issueness here from section 1 and starting from them} We argued here that the effect arises because questions and assertions differ in how at-issue and not-at-issue content interact with speaker commitment. Questions sharpen this contrast, whereas assertions collapse it, thereby reducing differentiation. The influence of speech act thus offers an explanation for a substantial portion of the observed divergence between diagnostics.\jt{what is this paragraph doing? it seems to be repeating what was said in 4.1 while also saying that this doesn't mean that there's different underlying notions of at-issueness. is this the best way to get into the discussion?}

    Second, the diagnostics differ in how they interact with contextual requirements imposed by particular expressions. A clear example is the behavior of \emph{be right} under the QUD diagnostic, where low QUD-match ratings do not plausibly reflect not-at-issueness, but instead arise from a pragmatic incompatibility: \emph{be right} presupposes a discourse structure that conflicts with the assumptions made by the diagnostic (see Section~\ref{ssub:be-right}). A related concern is raised by \citet{snider_at-issueness_2017,snider_distinguishing_2018}, who emphasized that the direct-dissent and `yes but' diagnostic involve propositional anaphora in the interpretation in the response particles \emph{yes/no} (as does the direct-response diagnostic in Exp.~6). Ratings under these diagnostics may therefore reflect constraints on anaphoric availability that are independent of at-issueness. Although our data show no clear split between diagnostics that involve response particles (Exps.~3, 4, and 6) and those that do not, the broader point remains: different diagnostics impose different requirements on discourse structure, common ground, and anaphoric accessibility, all of which can independently affect acceptability judgments. This supports the conclusion that some differences between diagnostics arise from interactions with expression-specific contextual requirements rather than from differences in at-issueness per se.\jt{i see, i guess you're going through the differences in our results between the diagnostics and discussing, for each one, whether that means that there are different underlying notions of at-issueness? if yes, this rhetorical structure needs to be made clearer. i didn't get that from the above ``...we aimed to assess
whether these differences reflect distinct theoretical notions of at-issueness or instead arise from methodological differences in how a single underlying phenomenon is operationalized'' because that was in the past tense (at least ``aimed'') and to me that sounded like we had already done it (which we hadn't; see my comment above).}

    Third, some small differences between diagnostics can be attributed to response-task effects. This is evident in the subtle differences between Exps.~5 and 6 (see \cref{ssec:5-6-discussion}), which differed only in response format, and in our failure to replicate \citeposs{syrett_experimental_2015} \citeyear{syrett_experimental_2015} reported positional effect for appositive NRRCs (see \cref{ssub:appositives}). While they found sentence-final appositives to be more at-issue than sentence-medial ones under a version of the direct-dissent diagnostic, our assent/dissent-based \emph{yes, but} diagnostic in Exp.~4 showed a difference in the opposite direction, while the other experiments found no difference between them (Exp.1--3). Taken together, these results provide no evidence for a stable notion of at-issueness under which sentence-final appositives are systematically more at-issue than medial ones (or the other way round), and they highlight how even small task differences can affect outcomes.\jt{does this paragraph argue that response task effects don't point to different underlying notions of at-issueness? or does it go off track and argue that sentence-medial vs -final NRRCs may not differ in at-issueness?}

    While many differences between our experimental results find plausible explanations in factors that are independent of whether there are separate underlying notions of at-issueness, our data showed no obvious distinction between QUD-at-issueness and proposal at-issueness.\jt{this was said many times already and should not need to be repeated here; if anything, the reader could be reminded at the beginning of the subsection, when the two notions are repeated.} This could be due to artifacts of the items or the instructions that may have led to obscuring an underlying distinctions. At the same time, among most pairs from Exps.~1--4, the Spearman rank correlation was at least moderate (when excluding \emph{be right}, see \cref{fn:w-o-be-right}), suggesting that the diagnostics, as implemented there, are at least partially sensitive to a shared underlying property.

    Our data does not provide conclusive evidence about whether or not the diagnostics track fundamentally different underlying notions of at-issueness. However, the fact that many of the differences find explanations outside of this question, seems more compatible with assuming that the diagnostics offer different, partially overlapping windows onto a single discourse phenomenon, that interacts with multiple discourse factors (speaker commitments, speech acts, contextual requirements, and the given alternatives) in complex and sometimes subtle ways, so that even small differences in task design can make a difference.

      

   
  \subsection{Methodological implications  \label{ssec:discussion-methodological}}

\jt{this is too short for its own subsection. it's also one of our major results, so it should be at the beginning of the General Discussion section.}

    Our findings also have methodological implications for future empirical research on at-issueness. The diverging results suggest that the diagnostics cannot be applied  interchangeably, and theoretical claims made on their basis should be relativized to the diagnostic used (see also \citealt{snider_anaphoric_2017,snider_at-issueness_2017,snider_distinguishing_2018,koev_notions_2018,korotkova_evidential_2020}). For instance, if a study finds that a particular construction is more at-issue than another using one diagnostic, this conclusion may not hold if a different diagnostic is employed. Therefore, empirical investigations should continue path of using multiple diagnostics\jt{see above} and future research on at-issueness should carefully consider that results may be specific to the speech act context,\jt{what is a speech act context?} contextual requirements of the expressions used, or the particular response task design.\jt{response task?} In particular, our findings underscore the importance of considering the speech act context in which target contents are presented. As we have shown, embedding target contents in questions versus assertions can greatly impact the results of at-issueness diagnostics.\jt{this is too repetitive.}
      
  

\section{Conclusion \label{sec:5_conclusion}}

\jt{for me, this is too long and rehashes too many of the not-so-major results that we found empirical support for. i would just write one paragraph that repeats the main research question, the main result, the main implication and the main big question that remains (at-issueness definitions)}

  In a series of six experiments, this study investigated how different diagnostics for at-issueness behave when applied to the same linguistic stimuli, using two sets of stimuli,\jt{is it critical that we used two sets of stimuli?} and five\jt{right} different diagnostics: the QUD diagnostic, the `asking whether' diagnostic, the direct-dissent diagnostic, the `yes, but' diagnostic, and the `direct response' diagnostic. Our findings provide experimental confirmation for claims that there are empirical differences between at-issueness diagnostics (\citealt{snider_anaphoric_2017,snider_at-issueness_2017,snider_distinguishing_2018,koev_notions_2018,faller_discourse_2019,korotkova_evidential_2020}). The diagnostics yielded different results, with some diagnostics showing greater differentiation among contents than others.
  
  We identified several factors contributing to these differences, including the speech act in which the target content is presented, interactions with contextual requirements imposed by specific expressions, and properties of the response task. Although our results suggest that the choice and implementation a diagnostic matter for empirical generalizations about at-issueness, the theoretical divide between QUD-based and assertion-based diagnostics assumed in previous literature does not appear to be the primary source of divergence. Instead, the speech act context plays a central role: embedding the target content in questions leads to greater differentiation among contents than embedding it in assertions. This finding highlights the need to consider the speech act context when interpreting results from at-issueness diagnostics.
  
  Additional factors, such as contextual requirements of the particular expressions used, and the response task design can also influence at-issueness judgments in complex ways. The diversity of discourse factors influencing at-issueness judgments highlights the need for careful consideration of diagnostic methods in empirical research on at-issueness. Future work should take into account interactions between diagnostics, speech acts, contextual requirements, and response tasks when selecting diagnostics and items for their studies. Having identified some factors that can influence results, there remains an important question for future work: what the results of different diagnostics might reveal about whether or not they reflect a shared underlying notion of at-issueness.

\pagebreak
\section*{Abbreviations (if applicable)}\label{abbrev}

  NRRC = non-restrictive relative clause, QUD = question under discussion \jt{these should be explained in the text and then this bit can be deleted}

\section*{Data accessibility statement}
      The experiments, data and R code for generating the figures and analyses of the experiments reported in this paper are available at \url{https://anonymous.4open.science/r/at-issueness-diagnostics-232C/}.

\section*{Ethics and consent}
      All experiments were conducted with approval from the ethics review committee of [university name redacted for review].


% \section*{Funding information (if applicable)}
%   We gratefully acknowledge the National Science Foundation grant BCS #1452674 (to Marie-Catherine de Marneffe,
% Craige Roberts, and Judith Tonhauser), which provided financial support for the data collection in Exps.~5 and 6.

% \section*{Acknowledgements (optional)}
%   We thank Taylor Mahler for assistance in collecting the data in Exps.~5 and 6 as well as valuable comments. 

% \section*{Competing interests}
%   The authors declare that they have no competing interests.



% \nocite{*} %this is to get all the entries of the sample bibliography; delete this line for an actual Glossa submission
%\printbibliography %for use with biblatex; comment out if you use natbib
\bibliography{at-issueness} %for use with natbib; comment out if you use biblatex, and change 'sample' by the name of your bib-file

%TC:ignore
\appendix

\setcounter{table}{0}
\renewcommand{\thetable}{A\arabic{table}}

\setcounter{figure}{0}
\renewcommand{\thefigure}{A\arabic{figure}}

\setcounter{ExNo}{0}


\section*{Supplements}

\section{Control stimuli in Exps.~1--4}\label{supp:stims}

  The examples in \ref{control1}-\ref{control4} provide the two control stimuli used in each of Exps.~1-4. For the a.-examples, participants were expected to give a `totally fits' response (Exp.~1), a `yes' response (Exp.~2), a `totally natural' response (Exp.~3), and a `no' response (Exp.~4); for the b.-examples, the opposite response was expected. The numbers  after each example identify the mean ratings (Exps.~1-3) or the proportion of `no' responses (Exp.~4) after excluding participants who did not self-identify as native speakers of American English (but before excluding participants on the basis of these controls), showing that the control stimuli worked as intended.

  \ex.\label{control1} Control stimuli in Exp.~1 (QUD diagnostic)
  \a. Mary: Which course did Ava take?
  \\ John: She took the French course. (.97)
  \b. Jennifer: What does Betsy have?
  \\ Robert: She loves dancing salsa. (.07)

  \ex.\label{control2} Control stimuli in Exp.~2 (`asking whether' diagnostic)
  \a. Mary: Did Arthur take a French course?
  \\ Question to participants: Is Mary asking whether Arthur took a French course? (.96)
  \b. Robert: Does Betsy have a cat?
  \\ Question to participants: Is Robert asking whether Betsy loves apples? (.02)

  \ex.\label{control3} Control stimuli in Exp.~3 (`direct dissent' diagnostic)
  \a. Mary: Arthur took a French course.
  \\ Lily: No, he took a Spanish course. (.87)
  \b. Robert: Betsy has a cat.
  \\ Maximilian: No, she doesn't like apples. (.05)

  \ex.\label{control4} Control stimuli in Exp.~4 (`yes, but' diagnostic)
  \a. Mary: Arthur took a French course.
  \\ Lily: Yes, but Lisa loves cats. / Yes, and he didn't take a French course. / No, he didn't take a French course. (.95)
  \b. Robert: Betsy has a cat.
  \\ Maximilian: Yes, but she is good at math. / Yes, and she loves it so much. / No, she doesn't like apples. (0)

\section{20 clauses}\label{supp:a-clauses}
  The contents of the following 20 clauses, which realized the complements of the 20 clause-embedding predicates, were investigated in Exps.~5--6:

  \begin{multicols}{2}
  \begin{enumerate}%[leftmargin=3ex,itemsep=-2pt]
      \item Mary is pregnant.
      \item Josie went on vacation to France.
      \item Emma studied on Saturday morning.
      \item Olivia sleeps until noon.
      \item Sophia got a tattoo.
      \item Mia drank 2 cocktails last night.
      \item Isabella ate a steak on Sunday.
      \item Emily bought a car yesterday.
      \item Grace visited her sister.
      \item Zoe calculated the tip.

  %\columnbrea      
      \item  Danny ate the last cupcake.
      \item  Frank got a cat.
      \item  Jackson ran 10 miles.
      \item  Jayden rented a car.
      \item  Tony had a drink last night.
      \item  Josh learned to ride a bike yesterday.
      \item  Owen shoveled snow last winter.
      \item  Julian dances salsa.
      \item  Jon walks to work.
      \item  Charley speaks Spanish.
          
  \end{enumerate}
  \end{multicols}

\section{Control stimuli in Exps.~5--6}\label{supp:control56}
  The control stimuli in Exps.~5--6 were the contents of the main clause polar questions in \Next. The non-restrictive relative clauses (NRRCs), given in parentheses in \Next, were included in Exp.~6, where at-issueness was measured with an assent diagnostic. The control stimuli here consisted of two clauses (like the target stimuli), to allow the relevant speaker to assent with one of two clauses.

  \ex. Sentences for control stimuli in in question embedding experiments (Exps.~5--6)
    \a. Do these muffins (, which are really delicious,) have blueberries in them?
    \b. Does this pizza (, which I just made from scratch,) have mushrooms on it? 
    \b. Was Jack (, who is my long-time neighbor,) playing outside with the kids? 
    \b. Does Ann (, who is a local performer,) dance ballet?
    \b. Were John's kids (, who are very well-behaved,) in the garage?
    \b. Does Samantha (, who is really into fashion,) have a new hat?
    \z.
  \z.

  We expected participants to give low responses on the at-issueness diagnostics for the control stimuli in \Last, indicating that the main clause content is at-issue.

%TC:endignore
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% TeX-engine: luatex
%%% End:
